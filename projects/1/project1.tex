\documentclass{article}

\usepackage{fullpage}
\usepackage{hyperref}
\hypersetup{
  colorlinks = true
}
\usepackage{listings}
\lstset{basicstyle=\ttfamily\footnotesize,breaklines=true}


\title{Project 1---Journal Club for Policy Gradients---ECE590--001}
\date{1/15/2020}
\begin{document}
\maketitle

{\bf Description:} You will be assigned to a group to adequately mix up
interactions and experiences. You will present one of the named algorithms
below. You will provide a beamer presentation deck as an artifact for your
group. {\em the goal of the presentations is ``journal club'' some of the
relevant policy gradient papers.} Successful presentations will start with the
nice summaries written in spinning up, but expand along axes of inquiry like: in
the original paper what were the key points and takeaways and what was novel.
You should include some demonstrations/explorations of these algorithms running
for gym environments (key feature of spinning up is you have access to these
algorithms and you can play with them).

{\bf Other requirements/goals:} {\bf EVERYONE} should read spinning up
descriptions (links below) so you can ask good questions. Goal of this activity
is ultimately to get a feel for these works.

{\bf Guidance:} I will interact with the groups during the preparation of the
presentation to insure that the beamer artifact covers all it needs to. I will
also help outline and troubleshoot them as necessary. {\em Checkpoints:}
\begin{enumerate}
\item 31 January 2020 during discussion section: form a plan to explain.
\item 7 February 2020 during discussion section: draft of presentation, Q\&A
with instructor.
\end{enumerate}

{\bf Timing:} Presentations will be 12 Feb 2020 and 14 Feb 2020 (during
discussion section). They should last about 20 minutes.

{\bf Version Control:} Please make public fork of this repo and develop your
materials in the appropriate directory.

\begin{itemize}
\item Group 1: Present Vanilla Policy Gradient with generalized advantage estimation. Start here: \url{https://spinningup.openai.com/en/latest/algorithms/vpg.html}.
\item Group 2: Present Trust Region Policy Optimization. Start here: \url{https://spinningup.openai.com/en/latest/algorithms/trpo.html}
\item Group 3: Present Proximal Policy Optimization. Start here: \url{https://spinningup.openai.com/en/latest/algorithms/ppo.html}
\item Group 4: Present Deep Deterministic Policy Gradient. Start here: \url{https://spinningup.openai.com/en/latest/algorithms/ddpg.html}
\end{itemize}
\end{document}
