{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Ray\n",
    "\n",
    "## References\n",
    "* Walkthrough of material from: https://github.com/ray-project/tutorial/blob/master/rllib_exercises/rllib_exercise02_ppo.ipynb\n",
    "\n",
    "## Pre install steps\n",
    "* Start a jupyter notebook on linux/mac. I will pip packages into a fresh conda environment. Preferred method:\n",
    "```conda create --name ray_ece python=3.7 pip jupyter```\n",
    "\n",
    "* Use docker with the same sort of environment.\n",
    "* **SOON**: jupyterhub environment!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install Ray and RLlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install ray using ipynb/jupyter **magic** `!`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Be sure to install the latest version of RLlib and sundry requirements\n",
    "# ! pip install -U ray[rllib]\n",
    "# ! pip install requests pandas aiohttp psutil setproctitle grpcio tensorflow-gpu==1.14.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow             1.14.0             \r\n",
      "tensorflow-estimator   1.14.0             \r\n",
      "tensorflow-gpu         1.14.0             \r\n"
     ]
    }
   ],
   "source": [
    "# view dependencies\n",
    "! pip list | grep tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the basic pieces for ray/rllib. We will look at PPO applied to a gym environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qian/anaconda3/envs/ray/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/qian/anaconda3/envs/ray/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/qian/anaconda3/envs/ray/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/qian/anaconda3/envs/ray/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/qian/anaconda3/envs/ray/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/qian/anaconda3/envs/ray/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/qian/anaconda3/envs/ray/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/qian/anaconda3/envs/ray/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/qian/anaconda3/envs/ray/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/qian/anaconda3/envs/ray/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/qian/anaconda3/envs/ray/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/qian/anaconda3/envs/ray/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import gym\n",
    "import ray\n",
    "from ray.rllib.agents.ppo import PPOTrainer, DEFAULT_CONFIG\n",
    "from ray.tune.logger import pretty_print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize ray\n",
    "* We explore a simple local configuration\n",
    "* Many configurations for distributed computation available: https://ray.readthedocs.io/en/latest/package-ref.html#ray.init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-11 16:22:03,757\tWARNING services.py:586 -- setpgrp failed, processes may not be cleaned up properly: [Errno 1] Operation not permitted.\n",
      "2020-03-11 16:22:03,758\tINFO resource_spec.py:212 -- Starting Ray with 7.76 GiB memory available for workers and up to 3.9 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n",
      "2020-03-11 16:22:04,125\tINFO services.py:1078 -- View the Ray dashboard at \u001b[1m\u001b[32mlocalhost:8265\u001b[39m\u001b[22m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'node_ip_address': '10.236.176.76',\n",
       " 'redis_address': '10.236.176.76:55026',\n",
       " 'object_store_address': '/tmp/ray/session_2020-03-11_16-22-03_752911_12897/sockets/plasma_store',\n",
       " 'raylet_socket_name': '/tmp/ray/session_2020-03-11_16-22-03_752911_12897/sockets/raylet',\n",
       " 'webui_url': 'localhost:8265',\n",
       " 'session_dir': '/tmp/ray/session_2020-03-11_16-22-03_752911_12897'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start ray locally (there are lots of configurations)\n",
    "# to remote access ray dashboard, use ssh -L 8888:localhost:8265 local_host@xxx.xxx.xxx.xx\n",
    "# on local: http://localhost:8888\n",
    "ray.init(num_cpus=8, num_gpus=1, ignore_reinit_error=True, log_to_driver=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running RLlib PPO on cartpole\n",
    "\n",
    "### Config and patterns used in RLlib\n",
    "* RLlib uses a functional pattern where as much of configuration as possible is pushed to data (possibly data gathered at runtime).\n",
    "* Read more about this approach: https://bair.berkeley.edu/blog/2019/10/14/functional-rl/\n",
    "* Here we explore the base configuration some"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_workers': 2, 'num_envs_per_worker': 1, 'sample_batch_size': 200, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_preprocessor': None, 'custom_model': None, 'custom_action_dist': None, 'custom_options': {}}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {}, 'env': None, 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 5e-05, 'monitor': False, 'log_level': 'WARN', 'callbacks': {'on_episode_start': None, 'on_episode_step': None, 'on_episode_end': None, 'on_sample_end': None, 'on_train_result': None, 'on_postprocess_traj': None}, 'ignore_worker_failures': False, 'log_sys_usage': True, 'eager': False, 'eager_tracing': False, 'no_eager_on_workers': False, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'evaluation_config': {}, 'sample_async': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {}, 'policy_mapping_fn': None, 'policies_to_train': None}, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': False}\n"
     ]
    }
   ],
   "source": [
    "config = DEFAULT_CONFIG.copy() # just a dictionary that has been imported and copied\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-10 17:31:16,624\tINFO trainer.py:370 -- Tip: set 'eager': true or the --eager flag to enable TensorFlow eager execution\n",
      "2020-03-10 17:31:16,627\tINFO trainer.py:517 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "/home/qian/anaconda3/envs/ray_ece/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    }
   ],
   "source": [
    "# change values at particular keys (note this could all come from yaml or json)\n",
    "config['num_workers'] = 1\n",
    "config['num_sgd_iter'] = 30\n",
    "config['sgd_minibatch_size'] = 128\n",
    "config['model']['fcnet_hiddens'] = [100, 100]\n",
    "config['num_cpus_per_worker'] = 0  # This avoids running out of resources in the notebook environment when this cell is re-executed\n",
    "\n",
    "agent = PPOTrainer(config, 'Pong-ram-v0')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "custom_metrics: {}\n",
      "date: 2020-03-10_17-31-24\n",
      "done: false\n",
      "episode_len_mean: 1248.0\n",
      "episode_reward_max: -20.0\n",
      "episode_reward_mean: -20.333333333333332\n",
      "episode_reward_min: -21.0\n",
      "episodes_this_iter: 3\n",
      "episodes_total: 3\n",
      "experiment_id: 6507435c45c14468bd2b319ebfaaf302\n",
      "hostname: qian-XPS-8920\n",
      "info:\n",
      "  grad_time_ms: 1305.772\n",
      "  learner:\n",
      "    default_policy:\n",
      "      cur_kl_coeff: 0.20000000298023224\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.7822446823120117\n",
      "      entropy_coeff: 0.0\n",
      "      kl: 0.009407696314156055\n",
      "      policy_loss: -0.0038971842732280493\n",
      "      total_loss: 0.4376855790615082\n",
      "      vf_explained_var: 0.0065327961929142475\n",
      "      vf_loss: 0.43970122933387756\n",
      "  load_time_ms: 52.684\n",
      "  num_steps_sampled: 4000\n",
      "  num_steps_trained: 3968\n",
      "  sample_time_ms: 4162.778\n",
      "  update_time_ms: 357.342\n",
      "iterations_since_restore: 1\n",
      "node_ip: 10.236.176.76\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 32.37777777777777\n",
      "  gpu_util_percent0: 0.030000000000000002\n",
      "  ram_util_percent: 57.36666666666666\n",
      "  vram_util_percent0: 0.1555445298933267\n",
      "pid: 24862\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_env_wait_ms: 0.37641425157779157\n",
      "  mean_inference_ms: 0.38623994542669876\n",
      "  mean_processing_ms: 0.09359642434972311\n",
      "time_since_restore: 5.91564154624939\n",
      "time_this_iter_s: 5.91564154624939\n",
      "time_total_s: 5.91564154624939\n",
      "timestamp: 1583875884\n",
      "timesteps_since_restore: 4000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 4000\n",
      "training_iteration: 1\n",
      "\n",
      "custom_metrics: {}\n",
      "date: 2020-03-10_17-31-29\n",
      "done: false\n",
      "episode_len_mean: 1227.0\n",
      "episode_reward_max: -20.0\n",
      "episode_reward_mean: -20.333333333333332\n",
      "episode_reward_min: -21.0\n",
      "episodes_this_iter: 3\n",
      "episodes_total: 6\n",
      "experiment_id: 6507435c45c14468bd2b319ebfaaf302\n",
      "hostname: qian-XPS-8920\n",
      "info:\n",
      "  grad_time_ms: 1151.352\n",
      "  learner:\n",
      "    default_policy:\n",
      "      cur_kl_coeff: 0.20000000298023224\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.7629125118255615\n",
      "      entropy_coeff: 0.0\n",
      "      kl: 0.01816527359187603\n",
      "      policy_loss: -0.014245090074837208\n",
      "      total_loss: 0.2954100966453552\n",
      "      vf_explained_var: 0.10428353399038315\n",
      "      vf_loss: 0.30602219700813293\n",
      "  load_time_ms: 27.716\n",
      "  num_steps_sampled: 8000\n",
      "  num_steps_trained: 7936\n",
      "  sample_time_ms: 3715.516\n",
      "  update_time_ms: 179.524\n",
      "iterations_since_restore: 2\n",
      "node_ip: 10.236.176.76\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 23.516666666666666\n",
      "  gpu_util_percent0: 0.03166666666666667\n",
      "  ram_util_percent: 57.53333333333334\n",
      "  vram_util_percent0: 0.1555445298933267\n",
      "pid: 24862\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_env_wait_ms: 0.3701086716001554\n",
      "  mean_inference_ms: 0.38124508971933063\n",
      "  mean_processing_ms: 0.0923418821139921\n",
      "time_since_restore: 10.188188076019287\n",
      "time_this_iter_s: 4.2725465297698975\n",
      "time_total_s: 10.188188076019287\n",
      "timestamp: 1583875889\n",
      "timesteps_since_restore: 8000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 8000\n",
      "training_iteration: 2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(2):\n",
    "    result = agent.train()\n",
    "    print(pretty_print(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function ray.rllib.agents.trainer.Trainer._setup.<locals>.<lambda>(env_config)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the builder pattern is everywhere ...\n",
    "agent.env_creator # environment is not stored, a function that creates an environment is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<TimeLimit<CartPoleEnv<CartPole-v0>>>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qian/anaconda3/envs/ray_ece/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    }
   ],
   "source": [
    "env = agent.env_creator({}) # we can sometimes still get what we want ..\n",
    "print(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Box(4,)\n",
      "Discrete(2)\n",
      "[-4.0115070e-02 -2.7820475e+38 -3.5773429e-01  2.6301286e+37]\n"
     ]
    }
   ],
   "source": [
    "print(env.observation_space)\n",
    "print(env.action_space)\n",
    "print(env.observation_space.sample())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute some observation, then ask the agent to compute an action\n",
    "obs = env.observation_space.sample()\n",
    "agent.compute_action(obs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXERCISE:\n",
    "Train the agent and try to get a reward of 200. If it's training too slowly you may need to modify the config above to use fewer hidden units, a larger sgd_minibatch_size, a smaller num_sgd_iter, or a larger num_workers.\n",
    "\n",
    "This should take around 20 or 30 training iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-23 17:48:03,561\tWARNING util.py:41 -- Install gputil for GPU system monitoring.\n"
     ]
    }
   ],
   "source": [
    "# build out a new config and trainer\n",
    "config = DEFAULT_CONFIG.copy()\n",
    "config['num_workers'] = 3\n",
    "config['num_sgd_iter'] = 30\n",
    "config['sgd_minibatch_size'] = 128\n",
    "config['model']['fcnet_hiddens'] = [100, 100]\n",
    "config['num_cpus_per_worker'] = 0\n",
    "\n",
    "agent = PPOTrainer(config, 'CartPole-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "custom_metrics: {}\n",
      "date: 2020-02-23_17-48-20\n",
      "done: false\n",
      "episode_len_mean: 22.885057471264368\n",
      "episode_reward_max: 83.0\n",
      "episode_reward_mean: 22.885057471264368\n",
      "episode_reward_min: 8.0\n",
      "episodes_this_iter: 174\n",
      "episodes_total: 174\n",
      "experiment_id: b49f04e1c97a41198d541c5d618813f0\n",
      "hostname: qian-XPS-8920\n",
      "info:\n",
      "  grad_time_ms: 1035.934\n",
      "  learner:\n",
      "    default_policy:\n",
      "      cur_kl_coeff: 0.20000000298023224\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6627660393714905\n",
      "      entropy_coeff: 0.0\n",
      "      kl: 0.030408170074224472\n",
      "      policy_loss: -0.04281337186694145\n",
      "      total_loss: 190.5047607421875\n",
      "      vf_explained_var: 0.018993224948644638\n",
      "      vf_loss: 190.54150390625\n",
      "  load_time_ms: 37.091\n",
      "  num_steps_sampled: 4000\n",
      "  num_steps_trained: 3968\n",
      "  sample_time_ms: 821.954\n",
      "  update_time_ms: 308.361\n",
      "iterations_since_restore: 1\n",
      "node_ip: 10.236.176.76\n",
      "num_healthy_workers: 3\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 10.908333333333333\n",
      "  ram_util_percent: 72.46666666666668\n",
      "pid: 30552\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_env_wait_ms: 0.03869171488588203\n",
      "  mean_inference_ms: 0.4229921122439443\n",
      "  mean_processing_ms: 0.104386043830199\n",
      "time_since_restore: 2.2333943843841553\n",
      "time_this_iter_s: 2.2333943843841553\n",
      "time_total_s: 2.2333943843841553\n",
      "timestamp: 1582498100\n",
      "timesteps_since_restore: 4000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 4000\n",
      "training_iteration: 1\n",
      "\n",
      "custom_metrics: {}\n",
      "date: 2020-02-23_17-48-21\n",
      "done: false\n",
      "episode_len_mean: 39.05882352941177\n",
      "episode_reward_max: 146.0\n",
      "episode_reward_mean: 39.05882352941177\n",
      "episode_reward_min: 10.0\n",
      "episodes_this_iter: 102\n",
      "episodes_total: 276\n",
      "experiment_id: b49f04e1c97a41198d541c5d618813f0\n",
      "hostname: qian-XPS-8920\n",
      "info:\n",
      "  grad_time_ms: 928.379\n",
      "  learner:\n",
      "    default_policy:\n",
      "      cur_kl_coeff: 0.30000001192092896\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6128237247467041\n",
      "      entropy_coeff: 0.0\n",
      "      kl: 0.01745547726750374\n",
      "      policy_loss: -0.0334165059030056\n",
      "      total_loss: 258.5480041503906\n",
      "      vf_explained_var: 0.03195696696639061\n",
      "      vf_loss: 258.5762023925781\n",
      "  load_time_ms: 18.985\n",
      "  num_steps_sampled: 8000\n",
      "  num_steps_trained: 7936\n",
      "  sample_time_ms: 821.782\n",
      "  update_time_ms: 155.277\n",
      "iterations_since_restore: 2\n",
      "node_ip: 10.236.176.76\n",
      "num_healthy_workers: 3\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 41.4\n",
      "  ram_util_percent: 72.4\n",
      "pid: 30552\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_env_wait_ms: 0.03880394780368805\n",
      "  mean_inference_ms: 0.43823799325396345\n",
      "  mean_processing_ms: 0.10082760305896517\n",
      "time_since_restore: 3.882070302963257\n",
      "time_this_iter_s: 1.6486759185791016\n",
      "time_total_s: 3.882070302963257\n",
      "timestamp: 1582498101\n",
      "timesteps_since_restore: 8000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 8000\n",
      "training_iteration: 2\n",
      "\n",
      "custom_metrics: {}\n",
      "date: 2020-02-23_17-48-23\n",
      "done: false\n",
      "episode_len_mean: 59.31\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 59.31\n",
      "episode_reward_min: 10.0\n",
      "episodes_this_iter: 45\n",
      "episodes_total: 321\n",
      "experiment_id: b49f04e1c97a41198d541c5d618813f0\n",
      "hostname: qian-XPS-8920\n",
      "info:\n",
      "  grad_time_ms: 892.796\n",
      "  learner:\n",
      "    default_policy:\n",
      "      cur_kl_coeff: 0.30000001192092896\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5807034373283386\n",
      "      entropy_coeff: 0.0\n",
      "      kl: 0.010151193477213383\n",
      "      policy_loss: -0.016438987106084824\n",
      "      total_loss: 656.8145141601562\n",
      "      vf_explained_var: 0.03439662978053093\n",
      "      vf_loss: 656.8280029296875\n",
      "  load_time_ms: 12.943\n",
      "  num_steps_sampled: 12000\n",
      "  num_steps_trained: 11904\n",
      "  sample_time_ms: 794.844\n",
      "  update_time_ms: 104.182\n",
      "iterations_since_restore: 3\n",
      "node_ip: 10.236.176.76\n",
      "num_healthy_workers: 3\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 41.85\n",
      "  ram_util_percent: 72.4\n",
      "pid: 30552\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_env_wait_ms: 0.03879155448455826\n",
      "  mean_inference_ms: 0.4325928164145424\n",
      "  mean_processing_ms: 0.09879542084129517\n",
      "time_since_restore: 5.450745105743408\n",
      "time_this_iter_s: 1.5686748027801514\n",
      "time_total_s: 5.450745105743408\n",
      "timestamp: 1582498103\n",
      "timesteps_since_restore: 12000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 12000\n",
      "training_iteration: 3\n",
      "\n",
      "custom_metrics: {}\n",
      "date: 2020-02-23_17-48-24\n",
      "done: false\n",
      "episode_len_mean: 88.54\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 88.54\n",
      "episode_reward_min: 11.0\n",
      "episodes_this_iter: 27\n",
      "episodes_total: 348\n",
      "experiment_id: b49f04e1c97a41198d541c5d618813f0\n",
      "hostname: qian-XPS-8920\n",
      "info:\n",
      "  grad_time_ms: 874.674\n",
      "  learner:\n",
      "    default_policy:\n",
      "      cur_kl_coeff: 0.30000001192092896\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5683166980743408\n",
      "      entropy_coeff: 0.0\n",
      "      kl: 0.006189932581037283\n",
      "      policy_loss: -0.007425015792250633\n",
      "      total_loss: 950.726806640625\n",
      "      vf_explained_var: 0.018599262461066246\n",
      "      vf_loss: 950.7324829101562\n",
      "  load_time_ms: 9.934\n",
      "  num_steps_sampled: 16000\n",
      "  num_steps_trained: 15872\n",
      "  sample_time_ms: 784.471\n",
      "  update_time_ms: 78.634\n",
      "iterations_since_restore: 4\n",
      "node_ip: 10.236.176.76\n",
      "num_healthy_workers: 3\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 42.3\n",
      "  ram_util_percent: 72.4\n",
      "pid: 30552\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_env_wait_ms: 0.0384576515998075\n",
      "  mean_inference_ms: 0.4245125056587129\n",
      "  mean_processing_ms: 0.09658640982772472\n",
      "time_since_restore: 7.030225992202759\n",
      "time_this_iter_s: 1.5794808864593506\n",
      "time_total_s: 7.030225992202759\n",
      "timestamp: 1582498104\n",
      "timesteps_since_restore: 16000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 16000\n",
      "training_iteration: 4\n",
      "\n",
      "custom_metrics: {}\n",
      "date: 2020-02-23_17-48-26\n",
      "done: false\n",
      "episode_len_mean: 119.26\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 119.26\n",
      "episode_reward_min: 15.0\n",
      "episodes_this_iter: 22\n",
      "episodes_total: 370\n",
      "experiment_id: b49f04e1c97a41198d541c5d618813f0\n",
      "hostname: qian-XPS-8920\n",
      "info:\n",
      "  grad_time_ms: 864.895\n",
      "  learner:\n",
      "    default_policy:\n",
      "      cur_kl_coeff: 0.30000001192092896\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5535798668861389\n",
      "      entropy_coeff: 0.0\n",
      "      kl: 0.004226348828524351\n",
      "      policy_loss: -0.00742779765278101\n",
      "      total_loss: 677.9777221679688\n",
      "      vf_explained_var: 0.06201700121164322\n",
      "      vf_loss: 677.9839477539062\n",
      "  load_time_ms: 8.119\n",
      "  num_steps_sampled: 20000\n",
      "  num_steps_trained: 19840\n",
      "  sample_time_ms: 778.055\n",
      "  update_time_ms: 63.276\n",
      "iterations_since_restore: 5\n",
      "node_ip: 10.236.176.76\n",
      "num_healthy_workers: 3\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 43.3\n",
      "  ram_util_percent: 72.5\n",
      "pid: 30552\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_env_wait_ms: 0.03848654981051873\n",
      "  mean_inference_ms: 0.4208892170861547\n",
      "  mean_processing_ms: 0.09578705756820001\n",
      "time_since_restore: 8.614022970199585\n",
      "time_this_iter_s: 1.5837969779968262\n",
      "time_total_s: 8.614022970199585\n",
      "timestamp: 1582498106\n",
      "timesteps_since_restore: 20000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 20000\n",
      "training_iteration: 5\n",
      "\n",
      "custom_metrics: {}\n",
      "date: 2020-02-23_17-48-28\n",
      "done: false\n",
      "episode_len_mean: 144.07\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 144.07\n",
      "episode_reward_min: 15.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 391\n",
      "experiment_id: b49f04e1c97a41198d541c5d618813f0\n",
      "hostname: qian-XPS-8920\n",
      "info:\n",
      "  grad_time_ms: 857.719\n",
      "  learner:\n",
      "    default_policy:\n",
      "      cur_kl_coeff: 0.15000000596046448\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5658000707626343\n",
      "      entropy_coeff: 0.0\n",
      "      kl: 0.003819228382781148\n",
      "      policy_loss: -0.0009329295135103166\n",
      "      total_loss: 749.8256225585938\n",
      "      vf_explained_var: 0.22188934683799744\n",
      "      vf_loss: 749.8259887695312\n",
      "  load_time_ms: 6.922\n",
      "  num_steps_sampled: 24000\n",
      "  num_steps_trained: 23808\n",
      "  sample_time_ms: 771.351\n",
      "  update_time_ms: 53.061\n",
      "iterations_since_restore: 6\n",
      "node_ip: 10.236.176.76\n",
      "num_healthy_workers: 3\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 40.3\n",
      "  ram_util_percent: 72.5\n",
      "pid: 30552\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_env_wait_ms: 0.03862107536093135\n",
      "  mean_inference_ms: 0.4192082252578174\n",
      "  mean_processing_ms: 0.09523657127127955\n",
      "time_since_restore: 10.179673194885254\n",
      "time_this_iter_s: 1.565650224685669\n",
      "time_total_s: 10.179673194885254\n",
      "timestamp: 1582498108\n",
      "timesteps_since_restore: 24000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 24000\n",
      "training_iteration: 6\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "custom_metrics: {}\n",
      "date: 2020-02-23_17-48-29\n",
      "done: false\n",
      "episode_len_mean: 162.28\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 162.28\n",
      "episode_reward_min: 15.0\n",
      "episodes_this_iter: 22\n",
      "episodes_total: 413\n",
      "experiment_id: b49f04e1c97a41198d541c5d618813f0\n",
      "hostname: qian-XPS-8920\n",
      "info:\n",
      "  grad_time_ms: 852.671\n",
      "  learner:\n",
      "    default_policy:\n",
      "      cur_kl_coeff: 0.07500000298023224\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5493625402450562\n",
      "      entropy_coeff: 0.0\n",
      "      kl: 0.0024292394518852234\n",
      "      policy_loss: -0.004398831631988287\n",
      "      total_loss: 595.1405029296875\n",
      "      vf_explained_var: 0.3493116796016693\n",
      "      vf_loss: 595.1447143554688\n",
      "  load_time_ms: 6.063\n",
      "  num_steps_sampled: 28000\n",
      "  num_steps_trained: 27776\n",
      "  sample_time_ms: 766.55\n",
      "  update_time_ms: 45.766\n",
      "iterations_since_restore: 7\n",
      "node_ip: 10.236.176.76\n",
      "num_healthy_workers: 3\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 40.7\n",
      "  ram_util_percent: 72.5\n",
      "pid: 30552\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_env_wait_ms: 0.03843168523896198\n",
      "  mean_inference_ms: 0.4144664648841678\n",
      "  mean_processing_ms: 0.09411105293929445\n",
      "time_since_restore: 11.745665788650513\n",
      "time_this_iter_s: 1.5659925937652588\n",
      "time_total_s: 11.745665788650513\n",
      "timestamp: 1582498109\n",
      "timesteps_since_restore: 28000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 28000\n",
      "training_iteration: 7\n",
      "\n",
      "custom_metrics: {}\n",
      "date: 2020-02-23_17-48-31\n",
      "done: false\n",
      "episode_len_mean: 179.01\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 179.01\n",
      "episode_reward_min: 17.0\n",
      "episodes_this_iter: 23\n",
      "episodes_total: 436\n",
      "experiment_id: b49f04e1c97a41198d541c5d618813f0\n",
      "hostname: qian-XPS-8920\n",
      "info:\n",
      "  grad_time_ms: 850.306\n",
      "  learner:\n",
      "    default_policy:\n",
      "      cur_kl_coeff: 0.03750000149011612\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5032016038894653\n",
      "      entropy_coeff: 0.0\n",
      "      kl: 0.0066197519190609455\n",
      "      policy_loss: -0.006931150332093239\n",
      "      total_loss: 617.3284301757812\n",
      "      vf_explained_var: 0.25372475385665894\n",
      "      vf_loss: 617.3351440429688\n",
      "  load_time_ms: 5.409\n",
      "  num_steps_sampled: 32000\n",
      "  num_steps_trained: 31744\n",
      "  sample_time_ms: 761.957\n",
      "  update_time_ms: 40.294\n",
      "iterations_since_restore: 8\n",
      "node_ip: 10.236.176.76\n",
      "num_healthy_workers: 3\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 44.1\n",
      "  ram_util_percent: 72.5\n",
      "pid: 30552\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_env_wait_ms: 0.038369894553756716\n",
      "  mean_inference_ms: 0.41141758311190413\n",
      "  mean_processing_ms: 0.09327035737523282\n",
      "time_since_restore: 13.315141439437866\n",
      "time_this_iter_s: 1.5694756507873535\n",
      "time_total_s: 13.315141439437866\n",
      "timestamp: 1582498111\n",
      "timesteps_since_restore: 32000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 32000\n",
      "training_iteration: 8\n",
      "\n",
      "custom_metrics: {}\n",
      "date: 2020-02-23_17-48-32\n",
      "done: false\n",
      "episode_len_mean: 188.09\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 188.09\n",
      "episode_reward_min: 123.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 456\n",
      "experiment_id: b49f04e1c97a41198d541c5d618813f0\n",
      "hostname: qian-XPS-8920\n",
      "info:\n",
      "  grad_time_ms: 846.716\n",
      "  learner:\n",
      "    default_policy:\n",
      "      cur_kl_coeff: 0.03750000149011612\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.533814549446106\n",
      "      entropy_coeff: 0.0\n",
      "      kl: 0.0048361774533987045\n",
      "      policy_loss: -0.003745220834389329\n",
      "      total_loss: 432.7081298828125\n",
      "      vf_explained_var: 0.2607533037662506\n",
      "      vf_loss: 432.71173095703125\n",
      "  load_time_ms: 4.901\n",
      "  num_steps_sampled: 36000\n",
      "  num_steps_trained: 35712\n",
      "  sample_time_ms: 758.867\n",
      "  update_time_ms: 36.032\n",
      "iterations_since_restore: 9\n",
      "node_ip: 10.236.176.76\n",
      "num_healthy_workers: 3\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 41.45\n",
      "  ram_util_percent: 72.5\n",
      "pid: 30552\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_env_wait_ms: 0.0383640825878887\n",
      "  mean_inference_ms: 0.40970658788815245\n",
      "  mean_processing_ms: 0.09258914303949052\n",
      "time_since_restore: 14.873049020767212\n",
      "time_this_iter_s: 1.5579075813293457\n",
      "time_total_s: 14.873049020767212\n",
      "timestamp: 1582498112\n",
      "timesteps_since_restore: 36000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 36000\n",
      "training_iteration: 9\n",
      "\n",
      "custom_metrics: {}\n",
      "date: 2020-02-23_17-48-34\n",
      "done: false\n",
      "episode_len_mean: 186.53\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 186.53\n",
      "episode_reward_min: 22.0\n",
      "episodes_this_iter: 22\n",
      "episodes_total: 478\n",
      "experiment_id: b49f04e1c97a41198d541c5d618813f0\n",
      "hostname: qian-XPS-8920\n",
      "info:\n",
      "  grad_time_ms: 844.488\n",
      "  learner:\n",
      "    default_policy:\n",
      "      cur_kl_coeff: 0.01875000074505806\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5134854912757874\n",
      "      entropy_coeff: 0.0\n",
      "      kl: 0.00472125131636858\n",
      "      policy_loss: -0.0031840261071920395\n",
      "      total_loss: 244.96884155273438\n",
      "      vf_explained_var: 0.5563542246818542\n",
      "      vf_loss: 244.97190856933594\n",
      "  load_time_ms: 4.5\n",
      "  num_steps_sampled: 40000\n",
      "  num_steps_trained: 39680\n",
      "  sample_time_ms: 757.329\n",
      "  update_time_ms: 32.618\n",
      "iterations_since_restore: 10\n",
      "node_ip: 10.236.176.76\n",
      "num_healthy_workers: 3\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 38.6\n",
      "  ram_util_percent: 72.5\n",
      "pid: 30552\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_env_wait_ms: 0.03828886266020858\n",
      "  mean_inference_ms: 0.407685707760498\n",
      "  mean_processing_ms: 0.09188056324039398\n",
      "time_since_restore: 16.446776390075684\n",
      "time_this_iter_s: 1.5737273693084717\n",
      "time_total_s: 16.446776390075684\n",
      "timestamp: 1582498114\n",
      "timesteps_since_restore: 40000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 40000\n",
      "training_iteration: 10\n",
      "\n",
      "custom_metrics: {}\n",
      "date: 2020-02-23_17-48-35\n",
      "done: false\n",
      "episode_len_mean: 185.96\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 185.96\n",
      "episode_reward_min: 22.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 499\n",
      "experiment_id: b49f04e1c97a41198d541c5d618813f0\n",
      "hostname: qian-XPS-8920\n",
      "info:\n",
      "  grad_time_ms: 823.251\n",
      "  learner:\n",
      "    default_policy:\n",
      "      cur_kl_coeff: 0.00937500037252903\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5236242413520813\n",
      "      entropy_coeff: 0.0\n",
      "      kl: 0.012139517813920975\n",
      "      policy_loss: -0.006283911876380444\n",
      "      total_loss: 230.92575073242188\n",
      "      vf_explained_var: 0.6132601499557495\n",
      "      vf_loss: 230.9319305419922\n",
      "  load_time_ms: 0.881\n",
      "  num_steps_sampled: 44000\n",
      "  num_steps_trained: 43648\n",
      "  sample_time_ms: 749.213\n",
      "  update_time_ms: 1.979\n",
      "iterations_since_restore: 11\n",
      "node_ip: 10.236.176.76\n",
      "num_healthy_workers: 3\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 39.6\n",
      "  ram_util_percent: 72.5\n",
      "pid: 30552\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_env_wait_ms: 0.03822187892680364\n",
      "  mean_inference_ms: 0.4061934976053038\n",
      "  mean_processing_ms: 0.09130650339803058\n",
      "time_since_restore: 18.01696467399597\n",
      "time_this_iter_s: 1.570188283920288\n",
      "time_total_s: 18.01696467399597\n",
      "timestamp: 1582498115\n",
      "timesteps_since_restore: 44000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 44000\n",
      "training_iteration: 11\n",
      "\n",
      "custom_metrics: {}\n",
      "date: 2020-02-23_17-48-37\n",
      "done: false\n",
      "episode_len_mean: 187.84\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 187.84\n",
      "episode_reward_min: 22.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 519\n",
      "experiment_id: b49f04e1c97a41198d541c5d618813f0\n",
      "hostname: qian-XPS-8920\n",
      "info:\n",
      "  grad_time_ms: 823.301\n",
      "  learner:\n",
      "    default_policy:\n",
      "      cur_kl_coeff: 0.00937500037252903\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5611987113952637\n",
      "      entropy_coeff: 0.0\n",
      "      kl: 0.003279987955465913\n",
      "      policy_loss: -0.0016631680773571134\n",
      "      total_loss: 334.46307373046875\n",
      "      vf_explained_var: 0.5354102253913879\n",
      "      vf_loss: 334.4646911621094\n",
      "  load_time_ms: 0.879\n",
      "  num_steps_sampled: 48000\n",
      "  num_steps_trained: 47616\n",
      "  sample_time_ms: 741.939\n",
      "  update_time_ms: 1.95\n",
      "iterations_since_restore: 12\n",
      "node_ip: 10.236.176.76\n",
      "num_healthy_workers: 3\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 41.75\n",
      "  ram_util_percent: 72.5\n",
      "pid: 30552\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_env_wait_ms: 0.03817910817256575\n",
      "  mean_inference_ms: 0.4052993348026304\n",
      "  mean_processing_ms: 0.09101123247780155\n",
      "time_since_restore: 19.592872142791748\n",
      "time_this_iter_s: 1.5759074687957764\n",
      "time_total_s: 19.592872142791748\n",
      "timestamp: 1582498117\n",
      "timesteps_since_restore: 48000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 48000\n",
      "training_iteration: 12\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "custom_metrics: {}\n",
      "date: 2020-02-23_17-48-39\n",
      "done: false\n",
      "episode_len_mean: 187.5\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 187.5\n",
      "episode_reward_min: 22.0\n",
      "episodes_this_iter: 23\n",
      "episodes_total: 542\n",
      "experiment_id: b49f04e1c97a41198d541c5d618813f0\n",
      "hostname: qian-XPS-8920\n",
      "info:\n",
      "  grad_time_ms: 823.776\n",
      "  learner:\n",
      "    default_policy:\n",
      "      cur_kl_coeff: 0.004687500186264515\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5304279923439026\n",
      "      entropy_coeff: 0.0\n",
      "      kl: 0.007987464778125286\n",
      "      policy_loss: -0.0023089575115591288\n",
      "      total_loss: 292.8392028808594\n",
      "      vf_explained_var: 0.5363507270812988\n",
      "      vf_loss: 292.8414611816406\n",
      "  load_time_ms: 0.891\n",
      "  num_steps_sampled: 52000\n",
      "  num_steps_trained: 51584\n",
      "  sample_time_ms: 742.016\n",
      "  update_time_ms: 1.954\n",
      "iterations_since_restore: 13\n",
      "node_ip: 10.236.176.76\n",
      "num_healthy_workers: 3\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 43.65\n",
      "  ram_util_percent: 72.5\n",
      "pid: 30552\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_env_wait_ms: 0.03813418293607642\n",
      "  mean_inference_ms: 0.40446417857124045\n",
      "  mean_processing_ms: 0.09071973761259099\n",
      "time_since_restore: 21.16723895072937\n",
      "time_this_iter_s: 1.574366807937622\n",
      "time_total_s: 21.16723895072937\n",
      "timestamp: 1582498119\n",
      "timesteps_since_restore: 52000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 52000\n",
      "training_iteration: 13\n",
      "\n",
      "custom_metrics: {}\n",
      "date: 2020-02-23_17-48-40\n",
      "done: false\n",
      "episode_len_mean: 188.57\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 188.57\n",
      "episode_reward_min: 22.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 562\n",
      "experiment_id: b49f04e1c97a41198d541c5d618813f0\n",
      "hostname: qian-XPS-8920\n",
      "info:\n",
      "  grad_time_ms: 824.084\n",
      "  learner:\n",
      "    default_policy:\n",
      "      cur_kl_coeff: 0.004687500186264515\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5128360390663147\n",
      "      entropy_coeff: 0.0\n",
      "      kl: 0.0064096334390342236\n",
      "      policy_loss: -0.00689412048086524\n",
      "      total_loss: 338.7287292480469\n",
      "      vf_explained_var: 0.3408118188381195\n",
      "      vf_loss: 338.7356872558594\n",
      "  load_time_ms: 0.885\n",
      "  num_steps_sampled: 56000\n",
      "  num_steps_trained: 55552\n",
      "  sample_time_ms: 742.41\n",
      "  update_time_ms: 1.949\n",
      "iterations_since_restore: 14\n",
      "node_ip: 10.236.176.76\n",
      "num_healthy_workers: 3\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 39.0\n",
      "  ram_util_percent: 72.5\n",
      "pid: 30552\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_env_wait_ms: 0.038120953620722736\n",
      "  mean_inference_ms: 0.404047435171793\n",
      "  mean_processing_ms: 0.0905564726261764\n",
      "time_since_restore: 22.753764867782593\n",
      "time_this_iter_s: 1.5865259170532227\n",
      "time_total_s: 22.753764867782593\n",
      "timestamp: 1582498120\n",
      "timesteps_since_restore: 56000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 56000\n",
      "training_iteration: 14\n",
      "\n",
      "custom_metrics: {}\n",
      "date: 2020-02-23_17-48-42\n",
      "done: false\n",
      "episode_len_mean: 193.21\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 193.21\n",
      "episode_reward_min: 124.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 582\n",
      "experiment_id: b49f04e1c97a41198d541c5d618813f0\n",
      "hostname: qian-XPS-8920\n",
      "info:\n",
      "  grad_time_ms: 832.818\n",
      "  learner:\n",
      "    default_policy:\n",
      "      cur_kl_coeff: 0.004687500186264515\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5273428559303284\n",
      "      entropy_coeff: 0.0\n",
      "      kl: 0.005865373183041811\n",
      "      policy_loss: -0.003943346906453371\n",
      "      total_loss: 291.2187194824219\n",
      "      vf_explained_var: 0.4322074353694916\n",
      "      vf_loss: 291.22265625\n",
      "  load_time_ms: 0.902\n",
      "  num_steps_sampled: 60000\n",
      "  num_steps_trained: 59520\n",
      "  sample_time_ms: 745.396\n",
      "  update_time_ms: 1.968\n",
      "iterations_since_restore: 15\n",
      "node_ip: 10.236.176.76\n",
      "num_healthy_workers: 3\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 53.150000000000006\n",
      "  ram_util_percent: 72.5\n",
      "pid: 30552\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_env_wait_ms: 0.038135892209624524\n",
      "  mean_inference_ms: 0.4039794510447738\n",
      "  mean_processing_ms: 0.09047314484750478\n",
      "time_since_restore: 24.4553542137146\n",
      "time_this_iter_s: 1.7015893459320068\n",
      "time_total_s: 24.4553542137146\n",
      "timestamp: 1582498122\n",
      "timesteps_since_restore: 60000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 60000\n",
      "training_iteration: 15\n",
      "\n",
      "custom_metrics: {}\n",
      "date: 2020-02-23_17-48-44\n",
      "done: false\n",
      "episode_len_mean: 196.68\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 196.68\n",
      "episode_reward_min: 124.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 602\n",
      "experiment_id: b49f04e1c97a41198d541c5d618813f0\n",
      "hostname: qian-XPS-8920\n",
      "info:\n",
      "  grad_time_ms: 842.04\n",
      "  learner:\n",
      "    default_policy:\n",
      "      cur_kl_coeff: 0.004687500186264515\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5500495433807373\n",
      "      entropy_coeff: 0.0\n",
      "      kl: 0.006091979332268238\n",
      "      policy_loss: -0.00657645845785737\n",
      "      total_loss: 357.80010986328125\n",
      "      vf_explained_var: 0.3007657527923584\n",
      "      vf_loss: 357.806640625\n",
      "  load_time_ms: 0.906\n",
      "  num_steps_sampled: 64000\n",
      "  num_steps_trained: 63488\n",
      "  sample_time_ms: 757.207\n",
      "  update_time_ms: 2.062\n",
      "iterations_since_restore: 16\n",
      "node_ip: 10.236.176.76\n",
      "num_healthy_workers: 3\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 53.400000000000006\n",
      "  ram_util_percent: 72.5\n",
      "pid: 30552\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_env_wait_ms: 0.038227206624776834\n",
      "  mean_inference_ms: 0.40464891815148435\n",
      "  mean_processing_ms: 0.09050524469116293\n",
      "time_since_restore: 26.23279571533203\n",
      "time_this_iter_s: 1.7774415016174316\n",
      "time_total_s: 26.23279571533203\n",
      "timestamp: 1582498124\n",
      "timesteps_since_restore: 64000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 64000\n",
      "training_iteration: 16\n",
      "\n",
      "custom_metrics: {}\n",
      "date: 2020-02-23_17-48-46\n",
      "done: false\n",
      "episode_len_mean: 197.59\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 197.59\n",
      "episode_reward_min: 124.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 622\n",
      "experiment_id: b49f04e1c97a41198d541c5d618813f0\n",
      "hostname: qian-XPS-8920\n",
      "info:\n",
      "  grad_time_ms: 850.264\n",
      "  learner:\n",
      "    default_policy:\n",
      "      cur_kl_coeff: 0.004687500186264515\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5522329211235046\n",
      "      entropy_coeff: 0.0\n",
      "      kl: 0.005798070691525936\n",
      "      policy_loss: -0.004245055373758078\n",
      "      total_loss: 324.9952697753906\n",
      "      vf_explained_var: 0.3375612199306488\n",
      "      vf_loss: 324.99957275390625\n",
      "  load_time_ms: 0.903\n",
      "  num_steps_sampled: 68000\n",
      "  num_steps_trained: 67456\n",
      "  sample_time_ms: 769.048\n",
      "  update_time_ms: 2.118\n",
      "iterations_since_restore: 17\n",
      "node_ip: 10.236.176.76\n",
      "num_healthy_workers: 3\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 52.333333333333336\n",
      "  ram_util_percent: 72.5\n",
      "pid: 30552\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_env_wait_ms: 0.038366589220551375\n",
      "  mean_inference_ms: 0.405870894257191\n",
      "  mean_processing_ms: 0.09062832940289922\n",
      "time_since_restore: 28.000482320785522\n",
      "time_this_iter_s: 1.7676866054534912\n",
      "time_total_s: 28.000482320785522\n",
      "timestamp: 1582498126\n",
      "timesteps_since_restore: 68000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 68000\n",
      "training_iteration: 17\n",
      "\n",
      "custom_metrics: {}\n",
      "date: 2020-02-23_17-48-47\n",
      "done: false\n",
      "episode_len_mean: 198.38\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 198.38\n",
      "episode_reward_min: 60.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 642\n",
      "experiment_id: b49f04e1c97a41198d541c5d618813f0\n",
      "hostname: qian-XPS-8920\n",
      "info:\n",
      "  grad_time_ms: 858.267\n",
      "  learner:\n",
      "    default_policy:\n",
      "      cur_kl_coeff: 0.004687500186264515\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5464231967926025\n",
      "      entropy_coeff: 0.0\n",
      "      kl: 0.006721454672515392\n",
      "      policy_loss: -0.002669051755219698\n",
      "      total_loss: 300.8284606933594\n",
      "      vf_explained_var: 0.4472771883010864\n",
      "      vf_loss: 300.8310852050781\n",
      "  load_time_ms: 0.911\n",
      "  num_steps_sampled: 72000\n",
      "  num_steps_trained: 71424\n",
      "  sample_time_ms: 779.266\n",
      "  update_time_ms: 2.202\n",
      "iterations_since_restore: 18\n",
      "node_ip: 10.236.176.76\n",
      "num_healthy_workers: 3\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 52.73333333333333\n",
      "  ram_util_percent: 72.5\n",
      "pid: 30552\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_env_wait_ms: 0.03854386423726337\n",
      "  mean_inference_ms: 0.40749653494684296\n",
      "  mean_processing_ms: 0.09091712685508728\n",
      "time_since_restore: 29.753266096115112\n",
      "time_this_iter_s: 1.7527837753295898\n",
      "time_total_s: 29.753266096115112\n",
      "timestamp: 1582498127\n",
      "timesteps_since_restore: 72000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 72000\n",
      "training_iteration: 18\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "custom_metrics: {}\n",
      "date: 2020-02-23_17-48-49\n",
      "done: false\n",
      "episode_len_mean: 198.06\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 198.06\n",
      "episode_reward_min: 60.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 662\n",
      "experiment_id: b49f04e1c97a41198d541c5d618813f0\n",
      "hostname: qian-XPS-8920\n",
      "info:\n",
      "  grad_time_ms: 866.448\n",
      "  learner:\n",
      "    default_policy:\n",
      "      cur_kl_coeff: 0.004687500186264515\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5659090280532837\n",
      "      entropy_coeff: 0.0\n",
      "      kl: 0.005861836951225996\n",
      "      policy_loss: -0.0025119411293417215\n",
      "      total_loss: 261.8939208984375\n",
      "      vf_explained_var: 0.5556763410568237\n",
      "      vf_loss: 261.8963623046875\n",
      "  load_time_ms: 0.931\n",
      "  num_steps_sampled: 76000\n",
      "  num_steps_trained: 75392\n",
      "  sample_time_ms: 787.942\n",
      "  update_time_ms: 2.274\n",
      "iterations_since_restore: 19\n",
      "node_ip: 10.236.176.76\n",
      "num_healthy_workers: 3\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 54.099999999999994\n",
      "  ram_util_percent: 72.5\n",
      "pid: 30552\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_env_wait_ms: 0.03875891293334569\n",
      "  mean_inference_ms: 0.40945192271005726\n",
      "  mean_processing_ms: 0.09129024456248402\n",
      "time_since_restore: 31.48140835762024\n",
      "time_this_iter_s: 1.728142261505127\n",
      "time_total_s: 31.48140835762024\n",
      "timestamp: 1582498129\n",
      "timesteps_since_restore: 76000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 76000\n",
      "training_iteration: 19\n",
      "\n",
      "custom_metrics: {}\n",
      "date: 2020-02-23_17-48-51\n",
      "done: false\n",
      "episode_len_mean: 196.08\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 196.08\n",
      "episode_reward_min: 60.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 683\n",
      "experiment_id: b49f04e1c97a41198d541c5d618813f0\n",
      "hostname: qian-XPS-8920\n",
      "info:\n",
      "  grad_time_ms: 874.187\n",
      "  learner:\n",
      "    default_policy:\n",
      "      cur_kl_coeff: 0.004687500186264515\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5363664031028748\n",
      "      entropy_coeff: 0.0\n",
      "      kl: 0.007300561293959618\n",
      "      policy_loss: -0.00381543324328959\n",
      "      total_loss: 225.7675323486328\n",
      "      vf_explained_var: 0.6223536133766174\n",
      "      vf_loss: 225.77134704589844\n",
      "  load_time_ms: 0.932\n",
      "  num_steps_sampled: 80000\n",
      "  num_steps_trained: 79360\n",
      "  sample_time_ms: 794.782\n",
      "  update_time_ms: 2.291\n",
      "iterations_since_restore: 20\n",
      "node_ip: 10.236.176.76\n",
      "num_healthy_workers: 3\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 53.95\n",
      "  ram_util_percent: 72.5\n",
      "pid: 30552\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_env_wait_ms: 0.03898339587064182\n",
      "  mean_inference_ms: 0.411460211366373\n",
      "  mean_processing_ms: 0.09177706534760997\n",
      "time_since_restore: 33.20142102241516\n",
      "time_this_iter_s: 1.7200126647949219\n",
      "time_total_s: 33.20142102241516\n",
      "timestamp: 1582498131\n",
      "timesteps_since_restore: 80000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 80000\n",
      "training_iteration: 20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Train for a while\n",
    "for i in range(20):\n",
    "    result = agent.train()\n",
    "    print(pretty_print(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/qian/ray_results/PPO_CartPole-v0_2020-02-23_17-48-01xjw58fo0/checkpoint_20/checkpoint-20\n"
     ]
    }
   ],
   "source": [
    "## Save the agent off (this may become sticky depending which agent you've used)\n",
    "checkpoint_path = agent.save()\n",
    "print(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qian/anaconda3/envs/ray_ece/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "2020-02-23 17:50:02,001\tWARNING util.py:41 -- Install gputil for GPU system monitoring.\n",
      "2020-02-23 17:50:02,060\tWARNING trainable.py:210 -- Getting current IP.\n",
      "2020-02-23 17:50:02,061\tINFO trainable.py:416 -- Restored on 10.236.176.76 from checkpoint: /home/qian/ray_results/PPO_CartPole-v0_2020-02-23_17-48-01xjw58fo0/checkpoint_20/checkpoint-20\n",
      "2020-02-23 17:50:02,061\tINFO trainable.py:423 -- Current state after restoring: {'_iteration': 20, '_timesteps_total': 80000, '_time_total': 33.20142102241516, '_episodes_total': 683}\n"
     ]
    }
   ],
   "source": [
    "trained_config = config.copy() # copy training config (this is also located in ~/ray_results)\n",
    "test_agent = PPOTrainer(trained_config, 'CartPole-v0')\n",
    "test_agent.restore(checkpoint_path) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXERCISE:\n",
    "Verify that the reward received roughly matches up with the reward printed in the training logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200.0\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('CartPole-v0')\n",
    "state = env.reset()\n",
    "done = False\n",
    "cumulative_reward = 0\n",
    "\n",
    "# same a single trajectory\n",
    "while not done:\n",
    "    action = test_agent.compute_action(state)\n",
    "    state, reward, done, _ = env.step(action)\n",
    "    cumulative_reward += reward\n",
    "\n",
    "print(cumulative_reward)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Follow ups:\n",
    "1. Using the `test_agent` what is the distribution of cummulative reward?\n",
    "1. Instead of a well trained agent, what does a poorly trained agent reward distribution look like?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring tune\n",
    "https://ray.readthedocs.io/en/latest/tune-usage.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise:\n",
    "Get logging from previous ppo training into a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.1.3-cp37-cp37m-manylinux1_x86_64.whl (13.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 13.1 MB 7.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.1 in /home/qian/anaconda3/envs/ray_ece/lib/python3.7/site-packages (from matplotlib) (2.8.1)\n",
      "Collecting cycler>=0.10\n",
      "  Downloading cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\n",
      "Collecting kiwisolver>=1.0.1\n",
      "  Downloading kiwisolver-1.1.0-cp37-cp37m-manylinux1_x86_64.whl (90 kB)\n",
      "\u001b[K     |████████████████████████████████| 90 kB 1.4 MB/s eta 0:00:0101\n",
      "\u001b[?25hRequirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /home/qian/anaconda3/envs/ray_ece/lib/python3.7/site-packages (from matplotlib) (2.4.6)\n",
      "Requirement already satisfied: numpy>=1.11 in /home/qian/anaconda3/envs/ray_ece/lib/python3.7/site-packages (from matplotlib) (1.18.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/qian/anaconda3/envs/ray_ece/lib/python3.7/site-packages (from python-dateutil>=2.1->matplotlib) (1.14.0)\n",
      "Requirement already satisfied: setuptools in /home/qian/anaconda3/envs/ray_ece/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib) (45.2.0.post20200210)\n",
      "Installing collected packages: cycler, kiwisolver, matplotlib\n",
      "Successfully installed cycler-0.10.0 kiwisolver-1.1.0 matplotlib-3.1.3\n"
     ]
    }
   ],
   "source": [
    "# matplotlib and magic\n",
    "! pip install matplotlib\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.tune import Analysis\n",
    "# change paths appropriately\n",
    "analysis = Analysis(\"/home/qian/ray_results/PPO_CartPole-v0_2020-02-23_17-48-01xjw58fo0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = analysis.dataframe() # last trial from checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trials = analysis.trial_dataframes['/home/qian/ray_results/PPO_CartPole-v0_2020-02-23_17-48-01xjw58fo0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "window.mpl = {};\n",
       "\n",
       "\n",
       "mpl.get_websocket_type = function() {\n",
       "    if (typeof(WebSocket) !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert('Your browser does not have WebSocket support. ' +\n",
       "              'Please try Chrome, Safari or Firefox ≥ 6. ' +\n",
       "              'Firefox 4 and 5 are also supported but you ' +\n",
       "              'have to enable WebSockets in about:config.');\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = (this.ws.binaryType != undefined);\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById(\"mpl-warnings\");\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent = (\n",
       "                \"This browser does not support binary websocket messages. \" +\n",
       "                    \"Performance may be slow.\");\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = $('<div/>');\n",
       "    this._root_extra_style(this.root)\n",
       "    this.root.attr('style', 'display: inline-block');\n",
       "\n",
       "    $(parent_element).append(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen =  function () {\n",
       "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
       "            fig.send_message(\"send_image_mode\", {});\n",
       "            if (mpl.ratio != 1) {\n",
       "                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n",
       "            }\n",
       "            fig.send_message(\"refresh\", {});\n",
       "        }\n",
       "\n",
       "    this.imageObj.onload = function() {\n",
       "            if (fig.image_mode == 'full') {\n",
       "                // Full images could contain transparency (where diff images\n",
       "                // almost always do), so we need to clear the canvas so that\n",
       "                // there is no ghosting.\n",
       "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "            }\n",
       "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "        };\n",
       "\n",
       "    this.imageObj.onunload = function() {\n",
       "        fig.ws.close();\n",
       "    }\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_header = function() {\n",
       "    var titlebar = $(\n",
       "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
       "        'ui-helper-clearfix\"/>');\n",
       "    var titletext = $(\n",
       "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
       "        'text-align: center; padding: 3px;\"/>');\n",
       "    titlebar.append(titletext)\n",
       "    this.root.append(titlebar);\n",
       "    this.header = titletext[0];\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = $('<div/>');\n",
       "\n",
       "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
       "\n",
       "    function canvas_keyboard_event(event) {\n",
       "        return fig.key_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
       "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
       "    this.canvas_div = canvas_div\n",
       "    this._canvas_extra_style(canvas_div)\n",
       "    this.root.append(canvas_div);\n",
       "\n",
       "    var canvas = $('<canvas/>');\n",
       "    canvas.addClass('mpl-canvas');\n",
       "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
       "\n",
       "    this.canvas = canvas[0];\n",
       "    this.context = canvas[0].getContext(\"2d\");\n",
       "\n",
       "    var backingStore = this.context.backingStorePixelRatio ||\n",
       "\tthis.context.webkitBackingStorePixelRatio ||\n",
       "\tthis.context.mozBackingStorePixelRatio ||\n",
       "\tthis.context.msBackingStorePixelRatio ||\n",
       "\tthis.context.oBackingStorePixelRatio ||\n",
       "\tthis.context.backingStorePixelRatio || 1;\n",
       "\n",
       "    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband = $('<canvas/>');\n",
       "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
       "\n",
       "    var pass_mouse_events = true;\n",
       "\n",
       "    canvas_div.resizable({\n",
       "        start: function(event, ui) {\n",
       "            pass_mouse_events = false;\n",
       "        },\n",
       "        resize: function(event, ui) {\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "        stop: function(event, ui) {\n",
       "            pass_mouse_events = true;\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "    });\n",
       "\n",
       "    function mouse_event_fn(event) {\n",
       "        if (pass_mouse_events)\n",
       "            return fig.mouse_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    rubberband.mousedown('button_press', mouse_event_fn);\n",
       "    rubberband.mouseup('button_release', mouse_event_fn);\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
       "\n",
       "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
       "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
       "\n",
       "    canvas_div.on(\"wheel\", function (event) {\n",
       "        event = event.originalEvent;\n",
       "        event['data'] = 'scroll'\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        mouse_event_fn(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.append(canvas);\n",
       "    canvas_div.append(rubberband);\n",
       "\n",
       "    this.rubberband = rubberband;\n",
       "    this.rubberband_canvas = rubberband[0];\n",
       "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
       "    this.rubberband_context.strokeStyle = \"#000000\";\n",
       "\n",
       "    this._resize_canvas = function(width, height) {\n",
       "        // Keep the size of the canvas, canvas container, and rubber band\n",
       "        // canvas in synch.\n",
       "        canvas_div.css('width', width)\n",
       "        canvas_div.css('height', height)\n",
       "\n",
       "        canvas.attr('width', width * mpl.ratio);\n",
       "        canvas.attr('height', height * mpl.ratio);\n",
       "        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n",
       "\n",
       "        rubberband.attr('width', width);\n",
       "        rubberband.attr('height', height);\n",
       "    }\n",
       "\n",
       "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
       "    // upon first draw.\n",
       "    this._resize_canvas(600, 600);\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus () {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            // put a spacer in here.\n",
       "            continue;\n",
       "        }\n",
       "        var button = $('<button/>');\n",
       "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
       "                        'ui-button-icon-only');\n",
       "        button.attr('role', 'button');\n",
       "        button.attr('aria-disabled', 'false');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "\n",
       "        var icon_img = $('<span/>');\n",
       "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
       "        icon_img.addClass(image);\n",
       "        icon_img.addClass('ui-corner-all');\n",
       "\n",
       "        var tooltip_span = $('<span/>');\n",
       "        tooltip_span.addClass('ui-button-text');\n",
       "        tooltip_span.html(tooltip);\n",
       "\n",
       "        button.append(icon_img);\n",
       "        button.append(tooltip_span);\n",
       "\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    var fmt_picker_span = $('<span/>');\n",
       "\n",
       "    var fmt_picker = $('<select/>');\n",
       "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
       "    fmt_picker_span.append(fmt_picker);\n",
       "    nav_element.append(fmt_picker_span);\n",
       "    this.format_dropdown = fmt_picker[0];\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = $(\n",
       "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
       "        fmt_picker.append(option);\n",
       "    }\n",
       "\n",
       "    // Add hover states to the ui-buttons\n",
       "    $( \".ui-button\" ).hover(\n",
       "        function() { $(this).addClass(\"ui-state-hover\");},\n",
       "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
       "    );\n",
       "\n",
       "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_message = function(type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function() {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
       "    }\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1]);\n",
       "        fig.send_message(\"refresh\", {});\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
       "    var x0 = msg['x0'] / mpl.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n",
       "    var x1 = msg['x1'] / mpl.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0, 0, fig.canvas.width / mpl.ratio, fig.canvas.height / mpl.ratio);\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch(cursor)\n",
       "    {\n",
       "    case 0:\n",
       "        cursor = 'pointer';\n",
       "        break;\n",
       "    case 1:\n",
       "        cursor = 'default';\n",
       "        break;\n",
       "    case 2:\n",
       "        cursor = 'crosshair';\n",
       "        break;\n",
       "    case 3:\n",
       "        cursor = 'move';\n",
       "        break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message(\"ack\", {});\n",
       "}\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = \"image/png\";\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src);\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data);\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig[\"handle_\" + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "}\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function(e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e)\n",
       "        e = window.event;\n",
       "    if (e.target)\n",
       "        targ = e.target;\n",
       "    else if (e.srcElement)\n",
       "        targ = e.srcElement;\n",
       "    if (targ.nodeType == 3) // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "\n",
       "    // jQuery normalizes the pageX and pageY\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    // offset() returns the position of the element relative to the document\n",
       "    var x = e.pageX - $(targ).offset().left;\n",
       "    var y = e.pageY - $(targ).offset().top;\n",
       "\n",
       "    return {\"x\": x, \"y\": y};\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys (original) {\n",
       "  return Object.keys(original).reduce(function (obj, key) {\n",
       "    if (typeof original[key] !== 'object')\n",
       "        obj[key] = original[key]\n",
       "    return obj;\n",
       "  }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function(event, name) {\n",
       "    var canvas_pos = mpl.findpos(event)\n",
       "\n",
       "    if (name === 'button_press')\n",
       "    {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * mpl.ratio;\n",
       "    var y = canvas_pos.y * mpl.ratio;\n",
       "\n",
       "    this.send_message(name, {x: x, y: y, button: event.button,\n",
       "                             step: event.step,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.key_event = function(event, name) {\n",
       "\n",
       "    // Prevent repeat events\n",
       "    if (name == 'key_press')\n",
       "    {\n",
       "        if (event.which === this._key)\n",
       "            return;\n",
       "        else\n",
       "            this._key = event.which;\n",
       "    }\n",
       "    if (name == 'key_release')\n",
       "        this._key = null;\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which != 17)\n",
       "        value += \"ctrl+\";\n",
       "    if (event.altKey && event.which != 18)\n",
       "        value += \"alt+\";\n",
       "    if (event.shiftKey && event.which != 16)\n",
       "        value += \"shift+\";\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, {key: value,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
       "    if (name == 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message(\"toolbar_button\", {name: name});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function() {\n",
       "        comm.close()\n",
       "    };\n",
       "    ws.send = function(m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function(msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data'])\n",
       "    });\n",
       "    return ws;\n",
       "}\n",
       "\n",
       "mpl.mpl_figure_comm = function(comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = $(\"#\" + id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm)\n",
       "\n",
       "    function ondownload(figure, format) {\n",
       "        window.open(figure.imageObj.src);\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy,\n",
       "                           ondownload,\n",
       "                           element.get(0));\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element.get(0);\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error(\"Failed to find cell for figure\", id, fig);\n",
       "        return;\n",
       "    }\n",
       "\n",
       "    var output_index = fig.cell_info[2]\n",
       "    var cell = fig.cell_info[0];\n",
       "\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
       "    var width = fig.canvas.width/mpl.ratio\n",
       "    fig.root.unbind('remove')\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable()\n",
       "    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n",
       "    fig.close_ws(fig, msg);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.close_ws = function(fig, msg){\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width/mpl.ratio\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message(\"ack\", {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items){\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) { continue; };\n",
       "\n",
       "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
       "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
       "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
       "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
       "    buttongrp.append(button);\n",
       "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
       "    titlebar.prepend(buttongrp);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(el){\n",
       "    var fig = this\n",
       "    el.on(\"remove\", function(){\n",
       "\tfig.close_ws(fig, {});\n",
       "    });\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(el){\n",
       "    // this is important to make the div 'focusable\n",
       "    el.attr('tabindex', 0)\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    }\n",
       "    else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager)\n",
       "        manager = IPython.keyboard_manager;\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which == 13) {\n",
       "        this.canvas_div.blur();\n",
       "        // select the cell after this one\n",
       "        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n",
       "        IPython.notebook.select(index + 1);\n",
       "    }\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.find_output_cell = function(html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i=0; i<ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code'){\n",
       "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] == html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "}\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel != null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"640\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fbd6c09e690>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trials['episode_reward_mean'].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise:\n",
    "Look at same with tensorboard. In a console, start tensorboard with: `tensorboard --logdir=~/ray_results`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorboard in /home/qian/anaconda3/envs/ray_ece/lib/python3.7/site-packages (2.1.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/qian/anaconda3/envs/ray_ece/lib/python3.7/site-packages (from tensorboard) (1.0.0)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /home/qian/anaconda3/envs/ray_ece/lib/python3.7/site-packages (from tensorboard) (1.27.2)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /home/qian/anaconda3/envs/ray_ece/lib/python3.7/site-packages (from tensorboard) (45.2.0.post20200210)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/qian/anaconda3/envs/ray_ece/lib/python3.7/site-packages (from tensorboard) (0.4.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/qian/anaconda3/envs/ray_ece/lib/python3.7/site-packages (from tensorboard) (3.2.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/qian/anaconda3/envs/ray_ece/lib/python3.7/site-packages (from tensorboard) (2.23.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /home/qian/anaconda3/envs/ray_ece/lib/python3.7/site-packages (from tensorboard) (1.14.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in /home/qian/anaconda3/envs/ray_ece/lib/python3.7/site-packages (from tensorboard) (0.9.0)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /home/qian/anaconda3/envs/ray_ece/lib/python3.7/site-packages (from tensorboard) (1.11.2)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /home/qian/anaconda3/envs/ray_ece/lib/python3.7/site-packages (from tensorboard) (3.11.3)\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /home/qian/anaconda3/envs/ray_ece/lib/python3.7/site-packages (from tensorboard) (0.34.2)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /home/qian/anaconda3/envs/ray_ece/lib/python3.7/site-packages (from tensorboard) (1.18.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/qian/anaconda3/envs/ray_ece/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (1.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/qian/anaconda3/envs/ray_ece/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard) (2019.11.28)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/qian/anaconda3/envs/ray_ece/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard) (1.25.8)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /home/qian/anaconda3/envs/ray_ece/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/qian/anaconda3/envs/ray_ece/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard) (2.9)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/qian/anaconda3/envs/ray_ece/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /home/qian/anaconda3/envs/ray_ece/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard) (4.0.0)\n",
      "Requirement already satisfied: rsa<4.1,>=3.1.4 in /home/qian/anaconda3/envs/ray_ece/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard) (4.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/qian/anaconda3/envs/ray_ece/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (3.1.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/qian/anaconda3/envs/ray_ece/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard) (0.4.8)\n"
     ]
    }
   ],
   "source": [
    "! pip install tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\n",
      "TensorBoard 2.1.0 at http://localhost:6007/ (Press CTRL+C to quit)\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "! tensorboard --logdir=~/ray_results # Kernel -> interupt to stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More details on tune\n",
    "* https://github.com/ray-project/ray/tree/master/rllib/tuned_examples list essentially yaml that can be used with the command line interface for tune\n",
    "* we will use tune to run of the a3c examples (this is a cpu only regression test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install pyyaml # install package to read yamls, import with yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'# This can reach 18-19 reward in ~3 minutes on p3.16xl head w/m4.16xl workers\\n#   128 workers -> 3 minutes (best case)\\n#    64 workers -> 4 minutes\\n#    32 workers -> 7 minutes\\n# See also: pong-impala.yaml, pong-impala-vectorized.yaml\\npong-impala-fast:\\n    env: PongNoFrameskip-v4\\n    run: IMPALA\\n    config:\\n        sample_batch_size: 50\\n        train_batch_size: 1000\\n        num_workers: 128\\n        num_envs_per_worker: 5\\n        broadcast_interval: 5\\n        max_sample_requests_in_flight_per_worker: 1\\n        num_data_loader_buffers: 4\\n        num_gpus: 2\\n        model:\\n          dim: 42\\n'\n"
     ]
    }
   ],
   "source": [
    "# grab an a3c example from github\n",
    "link = \"https://raw.githubusercontent.com/ray-project/rl-experiments/master/pong-speedrun/pong-impala-fast.yaml\"\n",
    "f = urllib.request.urlopen(link)\n",
    "yaml_example = f.read()\n",
    "print(yaml_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pong-impala-fast': {'env': 'PongNoFrameskip-v4', 'run': 'IMPALA', 'config': {'sample_batch_size': 50, 'train_batch_size': 1000, 'num_workers': 128, 'num_envs_per_worker': 5, 'broadcast_interval': 5, 'max_sample_requests_in_flight_per_worker': 1, 'num_data_loader_buffers': 4, 'num_gpus': 2, 'model': {'dim': 42}}}}\n"
     ]
    }
   ],
   "source": [
    "tune_config_example = yaml.safe_load(yaml_example)\n",
    "print(tune_config_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pong-impala-fast': {'env': 'PongNoFrameskip-v4', 'run': 'IMPALA', 'config': {'sample_batch_size': 50, 'train_batch_size': 1000, 'num_workers': 7, 'num_envs_per_worker': 5, 'broadcast_interval': 5, 'max_sample_requests_in_flight_per_worker': 1, 'num_data_loader_buffers': 4, 'num_gpus': 1, 'model': {'dim': 42}}}}\n"
     ]
    }
   ],
   "source": [
    "# tune_config_example[\"pong-ppo\"][\"env\"] = \"Pong-ram-v0\"\n",
    "tune_config_example[\"pong-impala-fast\"][\"config\"][\"num_workers\"] = 7\n",
    "tune_config_example[\"pong-impala-fast\"][\"config\"][\"num_gpus\"]=1\n",
    "# tune_config_example[\"pong-ppo\"][\"config\"][\"sample_batch_size\"]=80\n",
    "# tune_config_example[\"pong-ppo\"][\"config\"][\"num_sgd_iter\"]=40\n",
    "print(tune_config_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 4.4/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8/8 CPUs, 1/1 GPUs, 0.0/7.76 GiB heap, 0.0/2.69 GiB objects<br>Result logdir: /home/qian/ray_results/pong-impala-fast<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                        </th><th>status  </th><th>loc  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>IMPALA_PongNoFrameskip-v4_00c00974</td><td>RUNNING </td><td>     </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for IMPALA_PongNoFrameskip-v4_00c00974:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-03-11_16-22-44\n",
      "  done: false\n",
      "  episode_len_mean: 3056.0\n",
      "  episode_reward_max: -21.0\n",
      "  episode_reward_mean: -21.0\n",
      "  episode_reward_min: -21.0\n",
      "  episodes_this_iter: 28\n",
      "  episodes_total: 28\n",
      "  experiment_id: 92f0827d37354e42be7025ff72050188\n",
      "  experiment_tag: '0'\n",
      "  hostname: qian-XPS-8920\n",
      "  info:\n",
      "    learner:\n",
      "      cur_lr: 0.0005000000237487257\n",
      "      entropy: 2.0085663479121017e-14\n",
      "      entropy_coeff: 0.009999999776482582\n",
      "      grad_gnorm: 39.999996185302734\n",
      "      model: {}\n",
      "      policy_loss: -0.0\n",
      "      var_gnorm: 9.91195297241211\n",
      "      vf_explained_var: -0.0058441162109375\n",
      "      vf_loss: 49.90560531616211\n",
      "    learner_queue:\n",
      "      size_count: 28\n",
      "      size_mean: 0.0\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      size_std: 0.0\n",
      "    num_steps_replayed: 0\n",
      "    num_steps_sampled: 28000\n",
      "    num_steps_trained: 28000\n",
      "    num_weight_syncs: 114\n",
      "    sample_throughput: 2343.206\n",
      "    timing_breakdown:\n",
      "      learner_dequeue_time_ms: 3573.437\n",
      "      learner_grad_time_ms: 137.143\n",
      "      learner_load_time_ms: 240.336\n",
      "      learner_load_wait_time_ms: 16.689\n",
      "      optimizer_step_time_ms: 105.871\n",
      "    train_throughput: 2343.206\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 10.236.176.76\n",
      "  num_healthy_workers: 7\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 85.7\n",
      "    ram_util_percent: 50.00625\n",
      "  pid: 13004\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 7.649499744351691\n",
      "    mean_inference_ms: 2.472751917651006\n",
      "    mean_processing_ms: 0.4826733432477967\n",
      "  time_since_restore: 10.508371353149414\n",
      "  time_this_iter_s: 10.508371353149414\n",
      "  time_total_s: 10.508371353149414\n",
      "  timestamp: 1583958164\n",
      "  timesteps_since_restore: 28000\n",
      "  timesteps_this_iter: 28000\n",
      "  timesteps_total: 28000\n",
      "  training_iteration: 1\n",
      "  trial_id: 00c00974\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 8.4/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8/8 CPUs, 1/1 GPUs, 0.0/7.76 GiB heap, 0.0/2.69 GiB objects<br>Result logdir: /home/qian/ray_results/pong-impala-fast<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                        </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>IMPALA_PongNoFrameskip-v4_00c00974</td><td>RUNNING </td><td>10.236.176.76:13004</td><td style=\"text-align: right;\">     -21</td><td style=\"text-align: right;\">         10.5084</td><td style=\"text-align: right;\">28000</td><td style=\"text-align: right;\">     1</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for IMPALA_PongNoFrameskip-v4_00c00974:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-03-11_16-22-55\n",
      "  done: false\n",
      "  episode_len_mean: 3056.0\n",
      "  episode_reward_max: -21.0\n",
      "  episode_reward_mean: -21.0\n",
      "  episode_reward_min: -21.0\n",
      "  episodes_this_iter: 35\n",
      "  episodes_total: 63\n",
      "  experiment_id: 92f0827d37354e42be7025ff72050188\n",
      "  experiment_tag: '0'\n",
      "  hostname: qian-XPS-8920\n",
      "  info:\n",
      "    learner:\n",
      "      cur_lr: 0.0005000000237487257\n",
      "      entropy: 6.190255135152256e-06\n",
      "      entropy_coeff: 0.009999999776482582\n",
      "      grad_gnorm: 40.000003814697266\n",
      "      model: {}\n",
      "      policy_loss: -0.0\n",
      "      var_gnorm: 9.982680320739746\n",
      "      vf_explained_var: 0.00839298963546753\n",
      "      vf_loss: 72.2553482055664\n",
      "    learner_queue:\n",
      "      size_count: 62\n",
      "      size_mean: 0.0\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      size_std: 0.0\n",
      "    num_steps_replayed: 0\n",
      "    num_steps_sampled: 62000\n",
      "    num_steps_trained: 61000\n",
      "    num_weight_syncs: 250\n",
      "    sample_throughput: 3249.399\n",
      "    timing_breakdown:\n",
      "      learner_dequeue_time_ms: 3925.507\n",
      "      learner_grad_time_ms: 134.348\n",
      "      learner_load_time_ms: 129.929\n",
      "      learner_load_wait_time_ms: 171.117\n",
      "      optimizer_step_time_ms: 92.061\n",
      "    train_throughput: 3153.828\n",
      "  iterations_since_restore: 2\n",
      "  node_ip: 10.236.176.76\n",
      "  num_healthy_workers: 7\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.75333333333332\n",
      "    ram_util_percent: 53.913333333333334\n",
      "  pid: 13004\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 7.585355931200132\n",
      "    mean_inference_ms: 2.394924653387843\n",
      "    mean_processing_ms: 0.47435504037809495\n",
      "  time_since_restore: 20.95911145210266\n",
      "  time_this_iter_s: 10.450740098953247\n",
      "  time_total_s: 20.95911145210266\n",
      "  timestamp: 1583958175\n",
      "  timesteps_since_restore: 62000\n",
      "  timesteps_this_iter: 34000\n",
      "  timesteps_total: 62000\n",
      "  training_iteration: 2\n",
      "  trial_id: 00c00974\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 8.4/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8/8 CPUs, 1/1 GPUs, 0.0/7.76 GiB heap, 0.0/2.69 GiB objects<br>Result logdir: /home/qian/ray_results/pong-impala-fast<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                        </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>IMPALA_PongNoFrameskip-v4_00c00974</td><td>RUNNING </td><td>10.236.176.76:13004</td><td style=\"text-align: right;\">     -21</td><td style=\"text-align: right;\">         20.9591</td><td style=\"text-align: right;\">62000</td><td style=\"text-align: right;\">     2</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for IMPALA_PongNoFrameskip-v4_00c00974:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-03-11_16-23-05\n",
      "  done: false\n",
      "  episode_len_mean: 3056.0\n",
      "  episode_reward_max: -21.0\n",
      "  episode_reward_mean: -21.0\n",
      "  episode_reward_min: -21.0\n",
      "  episodes_this_iter: 35\n",
      "  episodes_total: 98\n",
      "  experiment_id: 92f0827d37354e42be7025ff72050188\n",
      "  experiment_tag: '0'\n",
      "  hostname: qian-XPS-8920\n",
      "  info:\n",
      "    learner:\n",
      "      cur_lr: 0.0005000000237487257\n",
      "      entropy: 0.007373851723968983\n",
      "      entropy_coeff: 0.009999999776482582\n",
      "      grad_gnorm: 40.0\n",
      "      model: {}\n",
      "      policy_loss: 0.00021057658887002617\n",
      "      var_gnorm: 10.001086235046387\n",
      "      vf_explained_var: 0.021030008792877197\n",
      "      vf_loss: 173.59410095214844\n",
      "    learner_queue:\n",
      "      size_count: 96\n",
      "      size_mean: 0.0\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      size_std: 0.0\n",
      "    num_steps_replayed: 0\n",
      "    num_steps_sampled: 96000\n",
      "    num_steps_trained: 95000\n",
      "    num_weight_syncs: 386\n",
      "    sample_throughput: 3240.492\n",
      "    timing_breakdown:\n",
      "      learner_dequeue_time_ms: 4265.756\n",
      "      learner_grad_time_ms: 134.08\n",
      "      learner_load_time_ms: 92.049\n",
      "      learner_load_wait_time_ms: 165.892\n",
      "      optimizer_step_time_ms: 79.328\n",
      "    train_throughput: 3240.492\n",
      "  iterations_since_restore: 3\n",
      "  node_ip: 10.236.176.76\n",
      "  num_healthy_workers: 7\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.30666666666667\n",
      "    ram_util_percent: 54.54666666666667\n",
      "  pid: 13004\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 7.55708759643112\n",
      "    mean_inference_ms: 2.355353505517178\n",
      "    mean_processing_ms: 0.4703720060428293\n",
      "  time_since_restore: 31.43911337852478\n",
      "  time_this_iter_s: 10.48000192642212\n",
      "  time_total_s: 31.43911337852478\n",
      "  timestamp: 1583958185\n",
      "  timesteps_since_restore: 96000\n",
      "  timesteps_this_iter: 34000\n",
      "  timesteps_total: 96000\n",
      "  training_iteration: 3\n",
      "  trial_id: 00c00974\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 8.6/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8/8 CPUs, 1/1 GPUs, 0.0/7.76 GiB heap, 0.0/2.69 GiB objects<br>Result logdir: /home/qian/ray_results/pong-impala-fast<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                        </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>IMPALA_PongNoFrameskip-v4_00c00974</td><td>RUNNING </td><td>10.236.176.76:13004</td><td style=\"text-align: right;\">     -21</td><td style=\"text-align: right;\">         31.4391</td><td style=\"text-align: right;\">96000</td><td style=\"text-align: right;\">     3</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for IMPALA_PongNoFrameskip-v4_00c00974:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-03-11_16-23-15\n",
      "  done: false\n",
      "  episode_len_mean: 3056.0\n",
      "  episode_reward_max: -21.0\n",
      "  episode_reward_mean: -21.0\n",
      "  episode_reward_min: -21.0\n",
      "  episodes_this_iter: 50\n",
      "  episodes_total: 148\n",
      "  experiment_id: 92f0827d37354e42be7025ff72050188\n",
      "  experiment_tag: '0'\n",
      "  hostname: qian-XPS-8920\n",
      "  info:\n",
      "    learner:\n",
      "      cur_lr: 0.0005000000237487257\n",
      "      entropy: 6.283613334043541e-16\n",
      "      entropy_coeff: 0.009999999776482582\n",
      "      grad_gnorm: 40.0\n",
      "      model: {}\n",
      "      policy_loss: -0.0\n",
      "      var_gnorm: 10.056659698486328\n",
      "      vf_explained_var: 0.017927825450897217\n",
      "      vf_loss: 62.24956512451172\n",
      "    learner_queue:\n",
      "      size_count: 130\n",
      "      size_mean: 0.0\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      size_std: 0.0\n",
      "    num_steps_replayed: 0\n",
      "    num_steps_sampled: 130000\n",
      "    num_steps_trained: 129000\n",
      "    num_weight_syncs: 521\n",
      "    sample_throughput: 3267.986\n",
      "    timing_breakdown:\n",
      "      learner_dequeue_time_ms: 4469.617\n",
      "      learner_grad_time_ms: 135.3\n",
      "      learner_load_time_ms: 67.83\n",
      "      learner_load_wait_time_ms: 169.997\n",
      "      optimizer_step_time_ms: 83.45\n",
      "    train_throughput: 3267.986\n",
      "  iterations_since_restore: 4\n",
      "  node_ip: 10.236.176.76\n",
      "  num_healthy_workers: 7\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.2\n",
      "    ram_util_percent: 55.14666666666666\n",
      "  pid: 13004\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 7.509801612034889\n",
      "    mean_inference_ms: 2.273822917900527\n",
      "    mean_processing_ms: 0.46729377835613334\n",
      "  time_since_restore: 41.8297393321991\n",
      "  time_this_iter_s: 10.390625953674316\n",
      "  time_total_s: 41.8297393321991\n",
      "  timestamp: 1583958195\n",
      "  timesteps_since_restore: 130000\n",
      "  timesteps_this_iter: 34000\n",
      "  timesteps_total: 130000\n",
      "  training_iteration: 4\n",
      "  trial_id: 00c00974\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 8.6/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8/8 CPUs, 1/1 GPUs, 0.0/7.76 GiB heap, 0.0/2.69 GiB objects<br>Result logdir: /home/qian/ray_results/pong-impala-fast<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                        </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>IMPALA_PongNoFrameskip-v4_00c00974</td><td>RUNNING </td><td>10.236.176.76:13004</td><td style=\"text-align: right;\">     -21</td><td style=\"text-align: right;\">         41.8297</td><td style=\"text-align: right;\">130000</td><td style=\"text-align: right;\">     4</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for IMPALA_PongNoFrameskip-v4_00c00974:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-03-11_16-23-26\n",
      "  done: false\n",
      "  episode_len_mean: 3056.0\n",
      "  episode_reward_max: -21.0\n",
      "  episode_reward_mean: -21.0\n",
      "  episode_reward_min: -21.0\n",
      "  episodes_this_iter: 55\n",
      "  episodes_total: 203\n",
      "  experiment_id: 92f0827d37354e42be7025ff72050188\n",
      "  experiment_tag: '0'\n",
      "  hostname: qian-XPS-8920\n",
      "  info:\n",
      "    learner:\n",
      "      cur_lr: 0.0005000000237487257\n",
      "      entropy: 7.110878641469753e-07\n",
      "      entropy_coeff: 0.009999999776482582\n",
      "      grad_gnorm: 40.0\n",
      "      model: {}\n",
      "      policy_loss: -0.0\n",
      "      var_gnorm: 10.091085433959961\n",
      "      vf_explained_var: 0.029599905014038086\n",
      "      vf_loss: 138.8087158203125\n",
      "    learner_queue:\n",
      "      size_count: 164\n",
      "      size_mean: 0.0\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      size_std: 0.0\n",
      "    num_steps_replayed: 0\n",
      "    num_steps_sampled: 164000\n",
      "    num_steps_trained: 163000\n",
      "    num_weight_syncs: 657\n",
      "    sample_throughput: 3250.414\n",
      "    timing_breakdown:\n",
      "      learner_dequeue_time_ms: 4828.554\n",
      "      learner_grad_time_ms: 134.194\n",
      "      learner_load_time_ms: 33.08\n",
      "      learner_load_wait_time_ms: 167.028\n",
      "      optimizer_step_time_ms: 82.263\n",
      "    train_throughput: 3250.414\n",
      "  iterations_since_restore: 5\n",
      "  node_ip: 10.236.176.76\n",
      "  num_healthy_workers: 7\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.49333333333333\n",
      "    ram_util_percent: 55.533333333333346\n",
      "  pid: 13004\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 7.490985616945724\n",
      "    mean_inference_ms: 2.2472804505378674\n",
      "    mean_processing_ms: 0.4748495943651976\n",
      "  time_since_restore: 52.277613401412964\n",
      "  time_this_iter_s: 10.447874069213867\n",
      "  time_total_s: 52.277613401412964\n",
      "  timestamp: 1583958206\n",
      "  timesteps_since_restore: 164000\n",
      "  timesteps_this_iter: 34000\n",
      "  timesteps_total: 164000\n",
      "  training_iteration: 5\n",
      "  trial_id: 00c00974\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 8.7/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8/8 CPUs, 1/1 GPUs, 0.0/7.76 GiB heap, 0.0/2.69 GiB objects<br>Result logdir: /home/qian/ray_results/pong-impala-fast<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                        </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>IMPALA_PongNoFrameskip-v4_00c00974</td><td>RUNNING </td><td>10.236.176.76:13004</td><td style=\"text-align: right;\">     -21</td><td style=\"text-align: right;\">         52.2776</td><td style=\"text-align: right;\">164000</td><td style=\"text-align: right;\">     5</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for IMPALA_PongNoFrameskip-v4_00c00974:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-03-11_16-23-36\n",
      "  done: false\n",
      "  episode_len_mean: 3056.0\n",
      "  episode_reward_max: -21.0\n",
      "  episode_reward_mean: -21.0\n",
      "  episode_reward_min: -21.0\n",
      "  episodes_this_iter: 35\n",
      "  episodes_total: 238\n",
      "  experiment_id: 92f0827d37354e42be7025ff72050188\n",
      "  experiment_tag: '0'\n",
      "  hostname: qian-XPS-8920\n",
      "  info:\n",
      "    learner:\n",
      "      cur_lr: 0.0005000000237487257\n",
      "      entropy: 6.406325908788027e-17\n",
      "      entropy_coeff: 0.009999999776482582\n",
      "      grad_gnorm: 40.0\n",
      "      model: {}\n",
      "      policy_loss: -0.0\n",
      "      var_gnorm: 10.167047500610352\n",
      "      vf_explained_var: 0.15899813175201416\n",
      "      vf_loss: 61.51532745361328\n",
      "    learner_queue:\n",
      "      size_count: 198\n",
      "      size_mean: 0.0\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      size_std: 0.0\n",
      "    num_steps_replayed: 0\n",
      "    num_steps_sampled: 198000\n",
      "    num_steps_trained: 197000\n",
      "    num_weight_syncs: 793\n",
      "    sample_throughput: 3258.641\n",
      "    timing_breakdown:\n",
      "      learner_dequeue_time_ms: 4899.951\n",
      "      learner_grad_time_ms: 132.052\n",
      "      learner_load_time_ms: 18.155\n",
      "      learner_load_wait_time_ms: 166.873\n",
      "      optimizer_step_time_ms: 89.576\n",
      "    train_throughput: 3258.641\n",
      "  iterations_since_restore: 6\n",
      "  node_ip: 10.236.176.76\n",
      "  num_healthy_workers: 7\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.06666666666666\n",
      "    ram_util_percent: 56.01333333333333\n",
      "  pid: 13004\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 7.488628792427534\n",
      "    mean_inference_ms: 2.246259268686485\n",
      "    mean_processing_ms: 0.47607372810127674\n",
      "  time_since_restore: 62.69901394844055\n",
      "  time_this_iter_s: 10.421400547027588\n",
      "  time_total_s: 62.69901394844055\n",
      "  timestamp: 1583958216\n",
      "  timesteps_since_restore: 198000\n",
      "  timesteps_this_iter: 34000\n",
      "  timesteps_total: 198000\n",
      "  training_iteration: 6\n",
      "  trial_id: 00c00974\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 8.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8/8 CPUs, 1/1 GPUs, 0.0/7.76 GiB heap, 0.0/2.69 GiB objects<br>Result logdir: /home/qian/ray_results/pong-impala-fast<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                        </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>IMPALA_PongNoFrameskip-v4_00c00974</td><td>RUNNING </td><td>10.236.176.76:13004</td><td style=\"text-align: right;\">     -21</td><td style=\"text-align: right;\">          62.699</td><td style=\"text-align: right;\">198000</td><td style=\"text-align: right;\">     6</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for IMPALA_PongNoFrameskip-v4_00c00974:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-03-11_16-23-47\n",
      "  done: false\n",
      "  episode_len_mean: 3056.0\n",
      "  episode_reward_max: -21.0\n",
      "  episode_reward_mean: -21.0\n",
      "  episode_reward_min: -21.0\n",
      "  episodes_this_iter: 35\n",
      "  episodes_total: 273\n",
      "  experiment_id: 92f0827d37354e42be7025ff72050188\n",
      "  experiment_tag: '0'\n",
      "  hostname: qian-XPS-8920\n",
      "  info:\n",
      "    learner:\n",
      "      cur_lr: 0.0005000000237487257\n",
      "      entropy: 6.1076838031581815e-12\n",
      "      entropy_coeff: 0.009999999776482582\n",
      "      grad_gnorm: 40.000003814697266\n",
      "      model: {}\n",
      "      policy_loss: -0.0\n",
      "      var_gnorm: 10.224838256835938\n",
      "      vf_explained_var: 0.23049664497375488\n",
      "      vf_loss: 48.89368438720703\n",
      "    learner_queue:\n",
      "      size_count: 232\n",
      "      size_mean: 0.0\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      size_std: 0.0\n",
      "    num_steps_replayed: 0\n",
      "    num_steps_sampled: 232000\n",
      "    num_steps_trained: 231000\n",
      "    num_weight_syncs: 928\n",
      "    sample_throughput: 3267.346\n",
      "    timing_breakdown:\n",
      "      learner_dequeue_time_ms: 4898.899\n",
      "      learner_grad_time_ms: 134.334\n",
      "      learner_load_time_ms: 18.061\n",
      "      learner_load_wait_time_ms: 172.668\n",
      "      optimizer_step_time_ms: 85.113\n",
      "    train_throughput: 3267.346\n",
      "  iterations_since_restore: 7\n",
      "  node_ip: 10.236.176.76\n",
      "  num_healthy_workers: 7\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.72142857142858\n",
      "    ram_util_percent: 56.45714285714286\n",
      "  pid: 13004\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 7.48536589001551\n",
      "    mean_inference_ms: 2.23336331187442\n",
      "    mean_processing_ms: 0.47388164855946846\n",
      "  time_since_restore: 73.09229564666748\n",
      "  time_this_iter_s: 10.393281698226929\n",
      "  time_total_s: 73.09229564666748\n",
      "  timestamp: 1583958227\n",
      "  timesteps_since_restore: 232000\n",
      "  timesteps_this_iter: 34000\n",
      "  timesteps_total: 232000\n",
      "  training_iteration: 7\n",
      "  trial_id: 00c00974\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 8.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8/8 CPUs, 1/1 GPUs, 0.0/7.76 GiB heap, 0.0/2.69 GiB objects<br>Result logdir: /home/qian/ray_results/pong-impala-fast<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                        </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>IMPALA_PongNoFrameskip-v4_00c00974</td><td>RUNNING </td><td>10.236.176.76:13004</td><td style=\"text-align: right;\">     -21</td><td style=\"text-align: right;\">         73.0923</td><td style=\"text-align: right;\">232000</td><td style=\"text-align: right;\">     7</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for IMPALA_PongNoFrameskip-v4_00c00974:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-03-11_16-23-57\n",
      "  done: false\n",
      "  episode_len_mean: 3056.0\n",
      "  episode_reward_max: -21.0\n",
      "  episode_reward_mean: -21.0\n",
      "  episode_reward_min: -21.0\n",
      "  episodes_this_iter: 65\n",
      "  episodes_total: 338\n",
      "  experiment_id: 92f0827d37354e42be7025ff72050188\n",
      "  experiment_tag: '0'\n",
      "  hostname: qian-XPS-8920\n",
      "  info:\n",
      "    learner:\n",
      "      cur_lr: 0.0005000000237487257\n",
      "      entropy: 1.4555118221792895e-09\n",
      "      entropy_coeff: 0.009999999776482582\n",
      "      grad_gnorm: 40.000003814697266\n",
      "      model: {}\n",
      "      policy_loss: -0.0\n",
      "      var_gnorm: 10.296533584594727\n",
      "      vf_explained_var: 0.3545066714286804\n",
      "      vf_loss: 47.459495544433594\n",
      "    learner_queue:\n",
      "      size_count: 265\n",
      "      size_mean: 0.0\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      size_std: 0.0\n",
      "    num_steps_replayed: 0\n",
      "    num_steps_sampled: 265000\n",
      "    num_steps_trained: 265000\n",
      "    num_weight_syncs: 1063\n",
      "    sample_throughput: 3158.693\n",
      "    timing_breakdown:\n",
      "      learner_dequeue_time_ms: 4891.569\n",
      "      learner_grad_time_ms: 132.918\n",
      "      learner_load_time_ms: 18.678\n",
      "      learner_load_wait_time_ms: 177.237\n",
      "      optimizer_step_time_ms: 81.567\n",
      "    train_throughput: 3254.411\n",
      "  iterations_since_restore: 8\n",
      "  node_ip: 10.236.176.76\n",
      "  num_healthy_workers: 7\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.17333333333333\n",
      "    ram_util_percent: 56.886666666666656\n",
      "  pid: 13004\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 7.478478202944887\n",
      "    mean_inference_ms: 2.219536681589953\n",
      "    mean_processing_ms: 0.4766835939042865\n",
      "  time_since_restore: 83.52729487419128\n",
      "  time_this_iter_s: 10.434999227523804\n",
      "  time_total_s: 83.52729487419128\n",
      "  timestamp: 1583958237\n",
      "  timesteps_since_restore: 265000\n",
      "  timesteps_this_iter: 33000\n",
      "  timesteps_total: 265000\n",
      "  training_iteration: 8\n",
      "  trial_id: 00c00974\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 8.9/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8/8 CPUs, 1/1 GPUs, 0.0/7.76 GiB heap, 0.0/2.69 GiB objects<br>Result logdir: /home/qian/ray_results/pong-impala-fast<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                        </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>IMPALA_PongNoFrameskip-v4_00c00974</td><td>RUNNING </td><td>10.236.176.76:13004</td><td style=\"text-align: right;\">     -21</td><td style=\"text-align: right;\">         83.5273</td><td style=\"text-align: right;\">265000</td><td style=\"text-align: right;\">     8</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for IMPALA_PongNoFrameskip-v4_00c00974:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-03-11_16-24-08\n",
      "  done: false\n",
      "  episode_len_mean: 3056.0\n",
      "  episode_reward_max: -21.0\n",
      "  episode_reward_mean: -21.0\n",
      "  episode_reward_min: -21.0\n",
      "  episodes_this_iter: 40\n",
      "  episodes_total: 378\n",
      "  experiment_id: 92f0827d37354e42be7025ff72050188\n",
      "  experiment_tag: '0'\n",
      "  hostname: qian-XPS-8920\n",
      "  info:\n",
      "    learner:\n",
      "      cur_lr: 0.0005000000237487257\n",
      "      entropy: 6.577712338184938e-05\n",
      "      entropy_coeff: 0.009999999776482582\n",
      "      grad_gnorm: 39.999996185302734\n",
      "      model: {}\n",
      "      policy_loss: -0.0\n",
      "      var_gnorm: 10.38475227355957\n",
      "      vf_explained_var: 0.3041698932647705\n",
      "      vf_loss: 67.32534790039062\n",
      "    learner_queue:\n",
      "      size_count: 299\n",
      "      size_mean: 0.0\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      size_std: 0.0\n",
      "    num_steps_replayed: 0\n",
      "    num_steps_sampled: 299000\n",
      "    num_steps_trained: 299000\n",
      "    num_weight_syncs: 1198\n",
      "    sample_throughput: 3268.766\n",
      "    timing_breakdown:\n",
      "      learner_dequeue_time_ms: 4911.498\n",
      "      learner_grad_time_ms: 133.386\n",
      "      learner_load_time_ms: 18.125\n",
      "      learner_load_wait_time_ms: 171.998\n",
      "      optimizer_step_time_ms: 74.344\n",
      "    train_throughput: 3268.766\n",
      "  iterations_since_restore: 9\n",
      "  node_ip: 10.236.176.76\n",
      "  num_healthy_workers: 7\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.48\n",
      "    ram_util_percent: 57.47333333333334\n",
      "  pid: 13004\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 7.474583376463564\n",
      "    mean_inference_ms: 2.2158136273216935\n",
      "    mean_processing_ms: 0.4795133168924316\n",
      "  time_since_restore: 93.91558265686035\n",
      "  time_this_iter_s: 10.388287782669067\n",
      "  time_total_s: 93.91558265686035\n",
      "  timestamp: 1583958248\n",
      "  timesteps_since_restore: 299000\n",
      "  timesteps_this_iter: 34000\n",
      "  timesteps_total: 299000\n",
      "  training_iteration: 9\n",
      "  trial_id: 00c00974\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 9.0/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8/8 CPUs, 1/1 GPUs, 0.0/7.76 GiB heap, 0.0/2.69 GiB objects<br>Result logdir: /home/qian/ray_results/pong-impala-fast<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                        </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>IMPALA_PongNoFrameskip-v4_00c00974</td><td>RUNNING </td><td>10.236.176.76:13004</td><td style=\"text-align: right;\">     -21</td><td style=\"text-align: right;\">         93.9156</td><td style=\"text-align: right;\">299000</td><td style=\"text-align: right;\">     9</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for IMPALA_PongNoFrameskip-v4_00c00974:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-03-11_16-24-18\n",
      "  done: false\n",
      "  episode_len_mean: 3056.0\n",
      "  episode_reward_max: -21.0\n",
      "  episode_reward_mean: -21.0\n",
      "  episode_reward_min: -21.0\n",
      "  episodes_this_iter: 35\n",
      "  episodes_total: 413\n",
      "  experiment_id: 92f0827d37354e42be7025ff72050188\n",
      "  experiment_tag: '0'\n",
      "  hostname: qian-XPS-8920\n",
      "  info:\n",
      "    learner:\n",
      "      cur_lr: 0.0005000000237487257\n",
      "      entropy: 9.33436581362912e-07\n",
      "      entropy_coeff: 0.009999999776482582\n",
      "      grad_gnorm: 40.0\n",
      "      model: {}\n",
      "      policy_loss: -0.0\n",
      "      var_gnorm: 10.503600120544434\n",
      "      vf_explained_var: 0.6846728324890137\n",
      "      vf_loss: 15.094996452331543\n",
      "    learner_queue:\n",
      "      size_count: 333\n",
      "      size_mean: 0.0\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      size_std: 0.0\n",
      "    num_steps_replayed: 0\n",
      "    num_steps_sampled: 333000\n",
      "    num_steps_trained: 333000\n",
      "    num_weight_syncs: 1334\n",
      "    sample_throughput: 3267.677\n",
      "    timing_breakdown:\n",
      "      learner_dequeue_time_ms: 4913.727\n",
      "      learner_grad_time_ms: 134.32\n",
      "      learner_load_time_ms: 18.417\n",
      "      learner_load_wait_time_ms: 162.498\n",
      "      optimizer_step_time_ms: 75.995\n",
      "    train_throughput: 3267.677\n",
      "  iterations_since_restore: 10\n",
      "  node_ip: 10.236.176.76\n",
      "  num_healthy_workers: 7\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.46000000000001\n",
      "    ram_util_percent: 57.839999999999996\n",
      "  pid: 13004\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 7.472345421259786\n",
      "    mean_inference_ms: 2.215854482171922\n",
      "    mean_processing_ms: 0.4789227599199629\n",
      "  time_since_restore: 104.308100938797\n",
      "  time_this_iter_s: 10.392518281936646\n",
      "  time_total_s: 104.308100938797\n",
      "  timestamp: 1583958258\n",
      "  timesteps_since_restore: 333000\n",
      "  timesteps_this_iter: 34000\n",
      "  timesteps_total: 333000\n",
      "  training_iteration: 10\n",
      "  trial_id: 00c00974\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 9.0/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8/8 CPUs, 1/1 GPUs, 0.0/7.76 GiB heap, 0.0/2.69 GiB objects<br>Result logdir: /home/qian/ray_results/pong-impala-fast<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                        </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>IMPALA_PongNoFrameskip-v4_00c00974</td><td>RUNNING </td><td>10.236.176.76:13004</td><td style=\"text-align: right;\">     -21</td><td style=\"text-align: right;\">         104.308</td><td style=\"text-align: right;\">333000</td><td style=\"text-align: right;\">    10</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for IMPALA_PongNoFrameskip-v4_00c00974:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-03-11_16-24-29\n",
      "  done: false\n",
      "  episode_len_mean: 3056.0\n",
      "  episode_reward_max: -21.0\n",
      "  episode_reward_mean: -21.0\n",
      "  episode_reward_min: -21.0\n",
      "  episodes_this_iter: 46\n",
      "  episodes_total: 459\n",
      "  experiment_id: 92f0827d37354e42be7025ff72050188\n",
      "  experiment_tag: '0'\n",
      "  hostname: qian-XPS-8920\n",
      "  info:\n",
      "    learner:\n",
      "      cur_lr: 0.0005000000237487257\n",
      "      entropy: 0.0006908189970999956\n",
      "      entropy_coeff: 0.009999999776482582\n",
      "      grad_gnorm: 40.0\n",
      "      model: {}\n",
      "      policy_loss: -3.471209453209667e-08\n",
      "      var_gnorm: 10.611527442932129\n",
      "      vf_explained_var: 0.8291065692901611\n",
      "      vf_loss: 9.572349548339844\n",
      "    learner_queue:\n",
      "      size_count: 367\n",
      "      size_mean: 0.0\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      size_std: 0.0\n",
      "    num_steps_replayed: 0\n",
      "    num_steps_sampled: 367000\n",
      "    num_steps_trained: 366000\n",
      "    num_weight_syncs: 1471\n",
      "    sample_throughput: 3232.726\n",
      "    timing_breakdown:\n",
      "      learner_dequeue_time_ms: 4916.212\n",
      "      learner_grad_time_ms: 134.771\n",
      "      learner_load_time_ms: 18.493\n",
      "      learner_load_wait_time_ms: 169.451\n",
      "      optimizer_step_time_ms: 63.126\n",
      "    train_throughput: 3137.645\n",
      "  iterations_since_restore: 11\n",
      "  node_ip: 10.236.176.76\n",
      "  num_healthy_workers: 7\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.78\n",
      "    ram_util_percent: 58.30666666666668\n",
      "  pid: 13004\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 7.469018026885526\n",
      "    mean_inference_ms: 2.2074162269597624\n",
      "    mean_processing_ms: 0.4760156843313838\n",
      "  time_since_restore: 114.81299829483032\n",
      "  time_this_iter_s: 10.504897356033325\n",
      "  time_total_s: 114.81299829483032\n",
      "  timestamp: 1583958269\n",
      "  timesteps_since_restore: 367000\n",
      "  timesteps_this_iter: 34000\n",
      "  timesteps_total: 367000\n",
      "  training_iteration: 11\n",
      "  trial_id: 00c00974\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 9.1/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8/8 CPUs, 1/1 GPUs, 0.0/7.76 GiB heap, 0.0/2.69 GiB objects<br>Result logdir: /home/qian/ray_results/pong-impala-fast<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                        </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>IMPALA_PongNoFrameskip-v4_00c00974</td><td>RUNNING </td><td>10.236.176.76:13004</td><td style=\"text-align: right;\">     -21</td><td style=\"text-align: right;\">         114.813</td><td style=\"text-align: right;\">367000</td><td style=\"text-align: right;\">    11</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for IMPALA_PongNoFrameskip-v4_00c00974:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-03-11_16-24-39\n",
      "  done: false\n",
      "  episode_len_mean: 3056.0\n",
      "  episode_reward_max: -21.0\n",
      "  episode_reward_mean: -21.0\n",
      "  episode_reward_min: -21.0\n",
      "  episodes_this_iter: 54\n",
      "  episodes_total: 513\n",
      "  experiment_id: 92f0827d37354e42be7025ff72050188\n",
      "  experiment_tag: '0'\n",
      "  hostname: qian-XPS-8920\n",
      "  info:\n",
      "    learner:\n",
      "      cur_lr: 0.0005000000237487257\n",
      "      entropy: 4.4295148849487305\n",
      "      entropy_coeff: 0.009999999776482582\n",
      "      grad_gnorm: 40.0\n",
      "      model: {}\n",
      "      policy_loss: -0.11964450776576996\n",
      "      var_gnorm: 10.687281608581543\n",
      "      vf_explained_var: 0.769416332244873\n",
      "      vf_loss: 36.68797302246094\n",
      "    learner_queue:\n",
      "      size_count: 401\n",
      "      size_mean: 0.0\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      size_std: 0.0\n",
      "    num_steps_replayed: 0\n",
      "    num_steps_sampled: 401000\n",
      "    num_steps_trained: 401000\n",
      "    num_weight_syncs: 1606\n",
      "    sample_throughput: 3256.987\n",
      "    timing_breakdown:\n",
      "      learner_dequeue_time_ms: 4885.421\n",
      "      learner_grad_time_ms: 133.602\n",
      "      learner_load_time_ms: 18.667\n",
      "      learner_load_wait_time_ms: 171.332\n",
      "      optimizer_step_time_ms: 70.119\n",
      "    train_throughput: 3352.781\n",
      "  iterations_since_restore: 12\n",
      "  node_ip: 10.236.176.76\n",
      "  num_healthy_workers: 7\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.25333333333334\n",
      "    ram_util_percent: 58.72666666666665\n",
      "  pid: 13004\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 7.46666281279561\n",
      "    mean_inference_ms: 2.2067361523085087\n",
      "    mean_processing_ms: 0.47710764023358077\n",
      "  time_since_restore: 125.239670753479\n",
      "  time_this_iter_s: 10.426672458648682\n",
      "  time_total_s: 125.239670753479\n",
      "  timestamp: 1583958279\n",
      "  timesteps_since_restore: 401000\n",
      "  timesteps_this_iter: 34000\n",
      "  timesteps_total: 401000\n",
      "  training_iteration: 12\n",
      "  trial_id: 00c00974\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 9.2/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8/8 CPUs, 1/1 GPUs, 0.0/7.76 GiB heap, 0.0/2.69 GiB objects<br>Result logdir: /home/qian/ray_results/pong-impala-fast<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                        </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>IMPALA_PongNoFrameskip-v4_00c00974</td><td>RUNNING </td><td>10.236.176.76:13004</td><td style=\"text-align: right;\">     -21</td><td style=\"text-align: right;\">          125.24</td><td style=\"text-align: right;\">401000</td><td style=\"text-align: right;\">    12</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for IMPALA_PongNoFrameskip-v4_00c00974:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-03-11_16-24-49\n",
      "  done: false\n",
      "  episode_len_mean: 3056.0\n",
      "  episode_reward_max: -21.0\n",
      "  episode_reward_mean: -21.0\n",
      "  episode_reward_min: -21.0\n",
      "  episodes_this_iter: 40\n",
      "  episodes_total: 553\n",
      "  experiment_id: 92f0827d37354e42be7025ff72050188\n",
      "  experiment_tag: '0'\n",
      "  hostname: qian-XPS-8920\n",
      "  info:\n",
      "    learner:\n",
      "      cur_lr: 0.0005000000237487257\n",
      "      entropy: 649.2923583984375\n",
      "      entropy_coeff: 0.009999999776482582\n",
      "      grad_gnorm: 40.000003814697266\n",
      "      model: {}\n",
      "      policy_loss: -3.9020564556121826\n",
      "      var_gnorm: 10.77084732055664\n",
      "      vf_explained_var: 0.9010138511657715\n",
      "      vf_loss: 2.4020020961761475\n",
      "    learner_queue:\n",
      "      size_count: 435\n",
      "      size_mean: 0.0\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      size_std: 0.0\n",
      "    num_steps_replayed: 0\n",
      "    num_steps_sampled: 435000\n",
      "    num_steps_trained: 434000\n",
      "    num_weight_syncs: 1742\n",
      "    sample_throughput: 3255.122\n",
      "    timing_breakdown:\n",
      "      learner_dequeue_time_ms: 4891.119\n",
      "      learner_grad_time_ms: 133.881\n",
      "      learner_load_time_ms: 19.41\n",
      "      learner_load_wait_time_ms: 171.847\n",
      "      optimizer_step_time_ms: 62.875\n",
      "    train_throughput: 3159.384\n",
      "  iterations_since_restore: 13\n",
      "  node_ip: 10.236.176.76\n",
      "  num_healthy_workers: 7\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.29333333333332\n",
      "    ram_util_percent: 59.126666666666665\n",
      "  pid: 13004\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 7.466148688893216\n",
      "    mean_inference_ms: 2.2101646015282523\n",
      "    mean_processing_ms: 0.4785651979001711\n",
      "  time_since_restore: 135.67205810546875\n",
      "  time_this_iter_s: 10.432387351989746\n",
      "  time_total_s: 135.67205810546875\n",
      "  timestamp: 1583958289\n",
      "  timesteps_since_restore: 435000\n",
      "  timesteps_this_iter: 34000\n",
      "  timesteps_total: 435000\n",
      "  training_iteration: 13\n",
      "  trial_id: 00c00974\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 9.3/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8/8 CPUs, 1/1 GPUs, 0.0/7.76 GiB heap, 0.0/2.69 GiB objects<br>Result logdir: /home/qian/ray_results/pong-impala-fast<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                        </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>IMPALA_PongNoFrameskip-v4_00c00974</td><td>RUNNING </td><td>10.236.176.76:13004</td><td style=\"text-align: right;\">     -21</td><td style=\"text-align: right;\">         135.672</td><td style=\"text-align: right;\">435000</td><td style=\"text-align: right;\">    13</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for IMPALA_PongNoFrameskip-v4_00c00974:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-03-11_16-25-00\n",
      "  done: false\n",
      "  episode_len_mean: 3056.0\n",
      "  episode_reward_max: -21.0\n",
      "  episode_reward_mean: -21.0\n",
      "  episode_reward_min: -21.0\n",
      "  episodes_this_iter: 35\n",
      "  episodes_total: 588\n",
      "  experiment_id: 92f0827d37354e42be7025ff72050188\n",
      "  experiment_tag: '0'\n",
      "  hostname: qian-XPS-8920\n",
      "  info:\n",
      "    learner:\n",
      "      cur_lr: 0.0005000000237487257\n",
      "      entropy: 406.1515808105469\n",
      "      entropy_coeff: 0.009999999776482582\n",
      "      grad_gnorm: 40.000003814697266\n",
      "      model: {}\n",
      "      policy_loss: -2.779203414916992\n",
      "      var_gnorm: 10.885876655578613\n",
      "      vf_explained_var: 0.9948538541793823\n",
      "      vf_loss: 0.27158284187316895\n",
      "    learner_queue:\n",
      "      size_count: 469\n",
      "      size_mean: 0.0\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      size_std: 0.0\n",
      "    num_steps_replayed: 0\n",
      "    num_steps_sampled: 469000\n",
      "    num_steps_trained: 468000\n",
      "    num_weight_syncs: 1877\n",
      "    sample_throughput: 3265.894\n",
      "    timing_breakdown:\n",
      "      learner_dequeue_time_ms: 4874.678\n",
      "      learner_grad_time_ms: 134.158\n",
      "      learner_load_time_ms: 19.507\n",
      "      learner_load_wait_time_ms: 174.631\n",
      "      optimizer_step_time_ms: 77.355\n",
      "    train_throughput: 3265.894\n",
      "  iterations_since_restore: 14\n",
      "  node_ip: 10.236.176.76\n",
      "  num_healthy_workers: 7\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.68\n",
      "    ram_util_percent: 59.65999999999999\n",
      "  pid: 13004\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 7.462525722683944\n",
      "    mean_inference_ms: 2.207142521332399\n",
      "    mean_processing_ms: 0.4778107937271014\n",
      "  time_since_restore: 146.07050442695618\n",
      "  time_this_iter_s: 10.398446321487427\n",
      "  time_total_s: 146.07050442695618\n",
      "  timestamp: 1583958300\n",
      "  timesteps_since_restore: 469000\n",
      "  timesteps_this_iter: 34000\n",
      "  timesteps_total: 469000\n",
      "  training_iteration: 14\n",
      "  trial_id: 00c00974\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 9.3/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8/8 CPUs, 1/1 GPUs, 0.0/7.76 GiB heap, 0.0/2.69 GiB objects<br>Result logdir: /home/qian/ray_results/pong-impala-fast<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                        </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>IMPALA_PongNoFrameskip-v4_00c00974</td><td>RUNNING </td><td>10.236.176.76:13004</td><td style=\"text-align: right;\">     -21</td><td style=\"text-align: right;\">         146.071</td><td style=\"text-align: right;\">469000</td><td style=\"text-align: right;\">    14</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for IMPALA_PongNoFrameskip-v4_00c00974:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-03-11_16-25-10\n",
      "  done: false\n",
      "  episode_len_mean: 3056.0\n",
      "  episode_reward_max: -21.0\n",
      "  episode_reward_mean: -21.0\n",
      "  episode_reward_min: -21.0\n",
      "  episodes_this_iter: 55\n",
      "  episodes_total: 643\n",
      "  experiment_id: 92f0827d37354e42be7025ff72050188\n",
      "  experiment_tag: '0'\n",
      "  hostname: qian-XPS-8920\n",
      "  info:\n",
      "    learner:\n",
      "      cur_lr: 0.0005000000237487257\n",
      "      entropy: 684.3929443359375\n",
      "      entropy_coeff: 0.009999999776482582\n",
      "      grad_gnorm: 40.0\n",
      "      model: {}\n",
      "      policy_loss: 74.81912994384766\n",
      "      var_gnorm: 10.955300331115723\n",
      "      vf_explained_var: 0.3704206347465515\n",
      "      vf_loss: 50.47029113769531\n",
      "    learner_queue:\n",
      "      size_count: 502\n",
      "      size_mean: 0.0\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      size_std: 0.0\n",
      "    num_steps_replayed: 0\n",
      "    num_steps_sampled: 502000\n",
      "    num_steps_trained: 502000\n",
      "    num_weight_syncs: 2011\n",
      "    sample_throughput: 3171.603\n",
      "    timing_breakdown:\n",
      "      learner_dequeue_time_ms: 4912.018\n",
      "      learner_grad_time_ms: 132.495\n",
      "      learner_load_time_ms: 24.181\n",
      "      learner_load_wait_time_ms: 177.506\n",
      "      optimizer_step_time_ms: 75.044\n",
      "    train_throughput: 3267.712\n",
      "  iterations_since_restore: 15\n",
      "  node_ip: 10.236.176.76\n",
      "  num_healthy_workers: 7\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.21428571428571\n",
      "    ram_util_percent: 60.01428571428573\n",
      "  pid: 13004\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 7.455679367917994\n",
      "    mean_inference_ms: 2.201371779853529\n",
      "    mean_processing_ms: 0.4764962702526613\n",
      "  time_since_restore: 156.46309232711792\n",
      "  time_this_iter_s: 10.392587900161743\n",
      "  time_total_s: 156.46309232711792\n",
      "  timestamp: 1583958310\n",
      "  timesteps_since_restore: 502000\n",
      "  timesteps_this_iter: 33000\n",
      "  timesteps_total: 502000\n",
      "  training_iteration: 15\n",
      "  trial_id: 00c00974\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 9.4/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8/8 CPUs, 1/1 GPUs, 0.0/7.76 GiB heap, 0.0/2.69 GiB objects<br>Result logdir: /home/qian/ray_results/pong-impala-fast<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                        </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>IMPALA_PongNoFrameskip-v4_00c00974</td><td>RUNNING </td><td>10.236.176.76:13004</td><td style=\"text-align: right;\">     -21</td><td style=\"text-align: right;\">         156.463</td><td style=\"text-align: right;\">502000</td><td style=\"text-align: right;\">    15</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for IMPALA_PongNoFrameskip-v4_00c00974:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-03-11_16-25-21\n",
      "  done: false\n",
      "  episode_len_mean: 3056.0\n",
      "  episode_reward_max: -21.0\n",
      "  episode_reward_mean: -21.0\n",
      "  episode_reward_min: -21.0\n",
      "  episodes_this_iter: 50\n",
      "  episodes_total: 693\n",
      "  experiment_id: 92f0827d37354e42be7025ff72050188\n",
      "  experiment_tag: '0'\n",
      "  hostname: qian-XPS-8920\n",
      "  info:\n",
      "    learner:\n",
      "      cur_lr: 0.0005000000237487257\n",
      "      entropy: 1192.4285888671875\n",
      "      entropy_coeff: 0.009999999776482582\n",
      "      grad_gnorm: 40.0\n",
      "      model: {}\n",
      "      policy_loss: 204.80088806152344\n",
      "      var_gnorm: 11.072354316711426\n",
      "      vf_explained_var: 0.1699962615966797\n",
      "      vf_loss: 91.99214172363281\n",
      "    learner_queue:\n",
      "      size_count: 536\n",
      "      size_mean: 0.0\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      size_std: 0.0\n",
      "    num_steps_replayed: 0\n",
      "    num_steps_sampled: 536000\n",
      "    num_steps_trained: 535000\n",
      "    num_weight_syncs: 2146\n",
      "    sample_throughput: 3259.72\n",
      "    timing_breakdown:\n",
      "      learner_dequeue_time_ms: 4915.128\n",
      "      learner_grad_time_ms: 133.372\n",
      "      learner_load_time_ms: 25.082\n",
      "      learner_load_wait_time_ms: 179.238\n",
      "      optimizer_step_time_ms: 89.207\n",
      "    train_throughput: 3163.846\n",
      "  iterations_since_restore: 16\n",
      "  node_ip: 10.236.176.76\n",
      "  num_healthy_workers: 7\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.42\n",
      "    ram_util_percent: 60.50666666666666\n",
      "  pid: 13004\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 7.455171530274467\n",
      "    mean_inference_ms: 2.20281633478946\n",
      "    mean_processing_ms: 0.4778711817258538\n",
      "  time_since_restore: 166.88073801994324\n",
      "  time_this_iter_s: 10.417645692825317\n",
      "  time_total_s: 166.88073801994324\n",
      "  timestamp: 1583958321\n",
      "  timesteps_since_restore: 536000\n",
      "  timesteps_this_iter: 34000\n",
      "  timesteps_total: 536000\n",
      "  training_iteration: 16\n",
      "  trial_id: 00c00974\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 9.5/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8/8 CPUs, 1/1 GPUs, 0.0/7.76 GiB heap, 0.0/2.69 GiB objects<br>Result logdir: /home/qian/ray_results/pong-impala-fast<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                        </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>IMPALA_PongNoFrameskip-v4_00c00974</td><td>RUNNING </td><td>10.236.176.76:13004</td><td style=\"text-align: right;\">     -21</td><td style=\"text-align: right;\">         166.881</td><td style=\"text-align: right;\">536000</td><td style=\"text-align: right;\">    16</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for IMPALA_PongNoFrameskip-v4_00c00974:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-03-11_16-25-31\n",
      "  done: false\n",
      "  episode_len_mean: 3133.18\n",
      "  episode_reward_max: -20.0\n",
      "  episode_reward_mean: -20.91\n",
      "  episode_reward_min: -21.0\n",
      "  episodes_this_iter: 35\n",
      "  episodes_total: 728\n",
      "  experiment_id: 92f0827d37354e42be7025ff72050188\n",
      "  experiment_tag: '0'\n",
      "  hostname: qian-XPS-8920\n",
      "  info:\n",
      "    learner:\n",
      "      cur_lr: 0.0005000000237487257\n",
      "      entropy: 1243.5333251953125\n",
      "      entropy_coeff: 0.009999999776482582\n",
      "      grad_gnorm: 40.000003814697266\n",
      "      model: {}\n",
      "      policy_loss: -0.7852026224136353\n",
      "      var_gnorm: 11.126350402832031\n",
      "      vf_explained_var: 0.8954365253448486\n",
      "      vf_loss: 4.030021667480469\n",
      "    learner_queue:\n",
      "      size_count: 570\n",
      "      size_mean: 0.0\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      size_std: 0.0\n",
      "    num_steps_replayed: 0\n",
      "    num_steps_sampled: 570000\n",
      "    num_steps_trained: 569000\n",
      "    num_weight_syncs: 2282\n",
      "    sample_throughput: 3260.347\n",
      "    timing_breakdown:\n",
      "      learner_dequeue_time_ms: 4919.502\n",
      "      learner_grad_time_ms: 134.414\n",
      "      learner_load_time_ms: 24.942\n",
      "      learner_load_wait_time_ms: 170.508\n",
      "      optimizer_step_time_ms: 76.216\n",
      "    train_throughput: 3260.347\n",
      "  iterations_since_restore: 17\n",
      "  node_ip: 10.236.176.76\n",
      "  num_healthy_workers: 7\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.08000000000001\n",
      "    ram_util_percent: 60.940000000000005\n",
      "  pid: 13004\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 7.457433602493685\n",
      "    mean_inference_ms: 2.208045049203426\n",
      "    mean_processing_ms: 0.4787063716755711\n",
      "  time_since_restore: 177.29685831069946\n",
      "  time_this_iter_s: 10.416120290756226\n",
      "  time_total_s: 177.29685831069946\n",
      "  timestamp: 1583958331\n",
      "  timesteps_since_restore: 570000\n",
      "  timesteps_this_iter: 34000\n",
      "  timesteps_total: 570000\n",
      "  training_iteration: 17\n",
      "  trial_id: 00c00974\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 9.5/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8/8 CPUs, 1/1 GPUs, 0.0/7.76 GiB heap, 0.0/2.69 GiB objects<br>Result logdir: /home/qian/ray_results/pong-impala-fast<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                        </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>IMPALA_PongNoFrameskip-v4_00c00974</td><td>RUNNING </td><td>10.236.176.76:13004</td><td style=\"text-align: right;\">  -20.91</td><td style=\"text-align: right;\">         177.297</td><td style=\"text-align: right;\">570000</td><td style=\"text-align: right;\">    17</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for IMPALA_PongNoFrameskip-v4_00c00974:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-03-11_16-25-42\n",
      "  done: false\n",
      "  episode_len_mean: 3220.65\n",
      "  episode_reward_max: -20.0\n",
      "  episode_reward_mean: -20.81\n",
      "  episode_reward_min: -21.0\n",
      "  episodes_this_iter: 35\n",
      "  episodes_total: 763\n",
      "  experiment_id: 92f0827d37354e42be7025ff72050188\n",
      "  experiment_tag: '0'\n",
      "  hostname: qian-XPS-8920\n",
      "  info:\n",
      "    learner:\n",
      "      cur_lr: 0.0005000000237487257\n",
      "      entropy: 1197.749267578125\n",
      "      entropy_coeff: 0.009999999776482582\n",
      "      grad_gnorm: 40.0\n",
      "      model: {}\n",
      "      policy_loss: -17.25745964050293\n",
      "      var_gnorm: 11.269607543945312\n",
      "      vf_explained_var: 0.6140624284744263\n",
      "      vf_loss: 5.678046226501465\n",
      "    learner_queue:\n",
      "      size_count: 604\n",
      "      size_mean: 0.0\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      size_std: 0.0\n",
      "    num_steps_replayed: 0\n",
      "    num_steps_sampled: 604000\n",
      "    num_steps_trained: 604000\n",
      "    num_weight_syncs: 2418\n",
      "    sample_throughput: 3239.761\n",
      "    timing_breakdown:\n",
      "      learner_dequeue_time_ms: 4897.307\n",
      "      learner_grad_time_ms: 134.688\n",
      "      learner_load_time_ms: 27.424\n",
      "      learner_load_wait_time_ms: 160.016\n",
      "      optimizer_step_time_ms: 77.727\n",
      "    train_throughput: 3335.048\n",
      "  iterations_since_restore: 18\n",
      "  node_ip: 10.236.176.76\n",
      "  num_healthy_workers: 7\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.09333333333332\n",
      "    ram_util_percent: 61.37333333333333\n",
      "  pid: 13004\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 7.454928251054051\n",
      "    mean_inference_ms: 2.201992810097117\n",
      "    mean_processing_ms: 0.4769656039492956\n",
      "  time_since_restore: 187.77870416641235\n",
      "  time_this_iter_s: 10.48184585571289\n",
      "  time_total_s: 187.77870416641235\n",
      "  timestamp: 1583958342\n",
      "  timesteps_since_restore: 604000\n",
      "  timesteps_this_iter: 34000\n",
      "  timesteps_total: 604000\n",
      "  training_iteration: 18\n",
      "  trial_id: 00c00974\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 9.6/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8/8 CPUs, 1/1 GPUs, 0.0/7.76 GiB heap, 0.0/2.69 GiB objects<br>Result logdir: /home/qian/ray_results/pong-impala-fast<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                        </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>IMPALA_PongNoFrameskip-v4_00c00974</td><td>RUNNING </td><td>10.236.176.76:13004</td><td style=\"text-align: right;\">  -20.81</td><td style=\"text-align: right;\">         187.779</td><td style=\"text-align: right;\">604000</td><td style=\"text-align: right;\">    18</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for IMPALA_PongNoFrameskip-v4_00c00974:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-03-11_16-25-52\n",
      "  done: false\n",
      "  episode_len_mean: 3386.15\n",
      "  episode_reward_max: -19.0\n",
      "  episode_reward_mean: -20.58\n",
      "  episode_reward_min: -21.0\n",
      "  episodes_this_iter: 36\n",
      "  episodes_total: 799\n",
      "  experiment_id: 92f0827d37354e42be7025ff72050188\n",
      "  experiment_tag: '0'\n",
      "  hostname: qian-XPS-8920\n",
      "  info:\n",
      "    learner:\n",
      "      cur_lr: 0.0005000000237487257\n",
      "      entropy: 1292.041259765625\n",
      "      entropy_coeff: 0.009999999776482582\n",
      "      grad_gnorm: 40.0\n",
      "      model: {}\n",
      "      policy_loss: -43.93090057373047\n",
      "      var_gnorm: 11.610307693481445\n",
      "      vf_explained_var: 0.5274286270141602\n",
      "      vf_loss: 13.120972633361816\n",
      "    learner_queue:\n",
      "      size_count: 638\n",
      "      size_mean: 0.0\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      size_std: 0.0\n",
      "    num_steps_replayed: 0\n",
      "    num_steps_sampled: 638000\n",
      "    num_steps_trained: 638000\n",
      "    num_weight_syncs: 2553\n",
      "    sample_throughput: 3258.093\n",
      "    timing_breakdown:\n",
      "      learner_dequeue_time_ms: 4922.379\n",
      "      learner_grad_time_ms: 132.61\n",
      "      learner_load_time_ms: 27.618\n",
      "      learner_load_wait_time_ms: 162.122\n",
      "      optimizer_step_time_ms: 89.05\n",
      "    train_throughput: 3258.093\n",
      "  iterations_since_restore: 19\n",
      "  node_ip: 10.236.176.76\n",
      "  num_healthy_workers: 7\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.03999999999999\n",
      "    ram_util_percent: 61.82666666666667\n",
      "  pid: 13004\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 7.457086653903441\n",
      "    mean_inference_ms: 2.2014982216712555\n",
      "    mean_processing_ms: 0.4753324004587239\n",
      "  time_since_restore: 198.2014136314392\n",
      "  time_this_iter_s: 10.422709465026855\n",
      "  time_total_s: 198.2014136314392\n",
      "  timestamp: 1583958352\n",
      "  timesteps_since_restore: 638000\n",
      "  timesteps_this_iter: 34000\n",
      "  timesteps_total: 638000\n",
      "  training_iteration: 19\n",
      "  trial_id: 00c00974\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 9.7/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8/8 CPUs, 1/1 GPUs, 0.0/7.76 GiB heap, 0.0/2.69 GiB objects<br>Result logdir: /home/qian/ray_results/pong-impala-fast<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                        </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>IMPALA_PongNoFrameskip-v4_00c00974</td><td>RUNNING </td><td>10.236.176.76:13004</td><td style=\"text-align: right;\">  -20.58</td><td style=\"text-align: right;\">         198.201</td><td style=\"text-align: right;\">638000</td><td style=\"text-align: right;\">    19</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for IMPALA_PongNoFrameskip-v4_00c00974:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-03-11_16-26-02\n",
      "  done: false\n",
      "  episode_len_mean: 3445.16\n",
      "  episode_reward_max: -19.0\n",
      "  episode_reward_mean: -20.54\n",
      "  episode_reward_min: -21.0\n",
      "  episodes_this_iter: 45\n",
      "  episodes_total: 844\n",
      "  experiment_id: 92f0827d37354e42be7025ff72050188\n",
      "  experiment_tag: '0'\n",
      "  hostname: qian-XPS-8920\n",
      "  info:\n",
      "    learner:\n",
      "      cur_lr: 0.0005000000237487257\n",
      "      entropy: 1302.8270263671875\n",
      "      entropy_coeff: 0.009999999776482582\n",
      "      grad_gnorm: 40.000003814697266\n",
      "      model: {}\n",
      "      policy_loss: 4.7856550216674805\n",
      "      var_gnorm: 12.014742851257324\n",
      "      vf_explained_var: 0.7774420380592346\n",
      "      vf_loss: 11.71455192565918\n",
      "    learner_queue:\n",
      "      size_count: 672\n",
      "      size_mean: 0.0\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      size_std: 0.0\n",
      "    num_steps_replayed: 0\n",
      "    num_steps_sampled: 672000\n",
      "    num_steps_trained: 671000\n",
      "    num_weight_syncs: 2688\n",
      "    sample_throughput: 3270.603\n",
      "    timing_breakdown:\n",
      "      learner_dequeue_time_ms: 4907.489\n",
      "      learner_grad_time_ms: 134.682\n",
      "      learner_load_time_ms: 22.769\n",
      "      learner_load_wait_time_ms: 175.322\n",
      "      optimizer_step_time_ms: 89.366\n",
      "    train_throughput: 3174.408\n",
      "  iterations_since_restore: 20\n",
      "  node_ip: 10.236.176.76\n",
      "  num_healthy_workers: 7\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.16\n",
      "    ram_util_percent: 62.23333333333332\n",
      "  pid: 13004\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 7.456220558613261\n",
      "    mean_inference_ms: 2.197653124246757\n",
      "    mean_processing_ms: 0.47480286446760955\n",
      "  time_since_restore: 208.58420252799988\n",
      "  time_this_iter_s: 10.382788896560669\n",
      "  time_total_s: 208.58420252799988\n",
      "  timestamp: 1583958362\n",
      "  timesteps_since_restore: 672000\n",
      "  timesteps_this_iter: 34000\n",
      "  timesteps_total: 672000\n",
      "  training_iteration: 20\n",
      "  trial_id: 00c00974\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 9.7/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8/8 CPUs, 1/1 GPUs, 0.0/7.76 GiB heap, 0.0/2.69 GiB objects<br>Result logdir: /home/qian/ray_results/pong-impala-fast<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                        </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>IMPALA_PongNoFrameskip-v4_00c00974</td><td>RUNNING </td><td>10.236.176.76:13004</td><td style=\"text-align: right;\">  -20.54</td><td style=\"text-align: right;\">         208.584</td><td style=\"text-align: right;\">672000</td><td style=\"text-align: right;\">    20</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for IMPALA_PongNoFrameskip-v4_00c00974:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-03-11_16-26-13\n",
      "  done: false\n",
      "  episode_len_mean: 3416.74\n",
      "  episode_reward_max: -19.0\n",
      "  episode_reward_mean: -20.66\n",
      "  episode_reward_min: -21.0\n",
      "  episodes_this_iter: 42\n",
      "  episodes_total: 886\n",
      "  experiment_id: 92f0827d37354e42be7025ff72050188\n",
      "  experiment_tag: '0'\n",
      "  hostname: qian-XPS-8920\n",
      "  info:\n",
      "    learner:\n",
      "      cur_lr: 0.0005000000237487257\n",
      "      entropy: 1438.8963623046875\n",
      "      entropy_coeff: 0.009999999776482582\n",
      "      grad_gnorm: 40.0\n",
      "      model: {}\n",
      "      policy_loss: 60.31205749511719\n",
      "      var_gnorm: 12.262328147888184\n",
      "      vf_explained_var: 0.6993663311004639\n",
      "      vf_loss: 20.83046531677246\n",
      "    learner_queue:\n",
      "      size_count: 705\n",
      "      size_mean: 0.0\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      size_std: 0.0\n",
      "    num_steps_replayed: 0\n",
      "    num_steps_sampled: 705000\n",
      "    num_steps_trained: 705000\n",
      "    num_weight_syncs: 2823\n",
      "    sample_throughput: 3168.219\n",
      "    timing_breakdown:\n",
      "      learner_dequeue_time_ms: 4900.909\n",
      "      learner_grad_time_ms: 134.333\n",
      "      learner_load_time_ms: 24.945\n",
      "      learner_load_wait_time_ms: 160.938\n",
      "      optimizer_step_time_ms: 80.952\n",
      "    train_throughput: 3264.226\n",
      "  iterations_since_restore: 21\n",
      "  node_ip: 10.236.176.76\n",
      "  num_healthy_workers: 7\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.85333333333334\n",
      "    ram_util_percent: 62.72666666666666\n",
      "  pid: 13004\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 7.454018198589001\n",
      "    mean_inference_ms: 2.1971142984780507\n",
      "    mean_processing_ms: 0.4749047066212349\n",
      "  time_since_restore: 218.98718810081482\n",
      "  time_this_iter_s: 10.402985572814941\n",
      "  time_total_s: 218.98718810081482\n",
      "  timestamp: 1583958373\n",
      "  timesteps_since_restore: 705000\n",
      "  timesteps_this_iter: 33000\n",
      "  timesteps_total: 705000\n",
      "  training_iteration: 21\n",
      "  trial_id: 00c00974\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 9.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8/8 CPUs, 1/1 GPUs, 0.0/7.76 GiB heap, 0.0/2.69 GiB objects<br>Result logdir: /home/qian/ray_results/pong-impala-fast<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                        </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>IMPALA_PongNoFrameskip-v4_00c00974</td><td>RUNNING </td><td>10.236.176.76:13004</td><td style=\"text-align: right;\">  -20.66</td><td style=\"text-align: right;\">         218.987</td><td style=\"text-align: right;\">705000</td><td style=\"text-align: right;\">    21</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for IMPALA_PongNoFrameskip-v4_00c00974:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-03-11_16-26-23\n",
      "  done: false\n",
      "  episode_len_mean: 3421.72\n",
      "  episode_reward_max: -17.0\n",
      "  episode_reward_mean: -20.67\n",
      "  episode_reward_min: -21.0\n",
      "  episodes_this_iter: 39\n",
      "  episodes_total: 925\n",
      "  experiment_id: 92f0827d37354e42be7025ff72050188\n",
      "  experiment_tag: '0'\n",
      "  hostname: qian-XPS-8920\n",
      "  info:\n",
      "    learner:\n",
      "      cur_lr: 0.0005000000237487257\n",
      "      entropy: 1662.3336181640625\n",
      "      entropy_coeff: 0.009999999776482582\n",
      "      grad_gnorm: 40.0\n",
      "      model: {}\n",
      "      policy_loss: -18.767887115478516\n",
      "      var_gnorm: 12.48880386352539\n",
      "      vf_explained_var: 0.6945608854293823\n",
      "      vf_loss: 19.4770565032959\n",
      "    learner_queue:\n",
      "      size_count: 740\n",
      "      size_mean: 0.0\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      size_std: 0.0\n",
      "    num_steps_replayed: 0\n",
      "    num_steps_sampled: 740000\n",
      "    num_steps_trained: 739000\n",
      "    num_weight_syncs: 2960\n",
      "    sample_throughput: 3333.163\n",
      "    timing_breakdown:\n",
      "      learner_dequeue_time_ms: 4898.21\n",
      "      learner_grad_time_ms: 134.918\n",
      "      learner_load_time_ms: 22.988\n",
      "      learner_load_wait_time_ms: 163.278\n",
      "      optimizer_step_time_ms: 70.566\n",
      "    train_throughput: 3237.93\n",
      "  iterations_since_restore: 22\n",
      "  node_ip: 10.236.176.76\n",
      "  num_healthy_workers: 7\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.73333333333333\n",
      "    ram_util_percent: 63.13333333333333\n",
      "  pid: 13004\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 7.453071473610829\n",
      "    mean_inference_ms: 2.1975938843839136\n",
      "    mean_processing_ms: 0.4751382489019218\n",
      "  time_since_restore: 229.47460794448853\n",
      "  time_this_iter_s: 10.487419843673706\n",
      "  time_total_s: 229.47460794448853\n",
      "  timestamp: 1583958383\n",
      "  timesteps_since_restore: 740000\n",
      "  timesteps_this_iter: 35000\n",
      "  timesteps_total: 740000\n",
      "  training_iteration: 22\n",
      "  trial_id: 00c00974\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 9.9/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8/8 CPUs, 1/1 GPUs, 0.0/7.76 GiB heap, 0.0/2.69 GiB objects<br>Result logdir: /home/qian/ray_results/pong-impala-fast<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                        </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>IMPALA_PongNoFrameskip-v4_00c00974</td><td>RUNNING </td><td>10.236.176.76:13004</td><td style=\"text-align: right;\">  -20.67</td><td style=\"text-align: right;\">         229.475</td><td style=\"text-align: right;\">740000</td><td style=\"text-align: right;\">    22</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for IMPALA_PongNoFrameskip-v4_00c00974:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-03-11_16-26-34\n",
      "  done: false\n",
      "  episode_len_mean: 3504.67\n",
      "  episode_reward_max: -17.0\n",
      "  episode_reward_mean: -20.54\n",
      "  episode_reward_min: -21.0\n",
      "  episodes_this_iter: 40\n",
      "  episodes_total: 965\n",
      "  experiment_id: 92f0827d37354e42be7025ff72050188\n",
      "  experiment_tag: '0'\n",
      "  hostname: qian-XPS-8920\n",
      "  info:\n",
      "    learner:\n",
      "      cur_lr: 0.0005000000237487257\n",
      "      entropy: 1588.15234375\n",
      "      entropy_coeff: 0.009999999776482582\n",
      "      grad_gnorm: 40.0\n",
      "      model: {}\n",
      "      policy_loss: 133.72320556640625\n",
      "      var_gnorm: 12.781712532043457\n",
      "      vf_explained_var: 0.6437276005744934\n",
      "      vf_loss: 32.654998779296875\n",
      "    learner_queue:\n",
      "      size_count: 774\n",
      "      size_mean: 0.0\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      size_std: 0.0\n",
      "    num_steps_replayed: 0\n",
      "    num_steps_sampled: 774000\n",
      "    num_steps_trained: 773000\n",
      "    num_weight_syncs: 3097\n",
      "    sample_throughput: 3230.61\n",
      "    timing_breakdown:\n",
      "      learner_dequeue_time_ms: 4890.303\n",
      "      learner_grad_time_ms: 136.395\n",
      "      learner_load_time_ms: 23.742\n",
      "      learner_load_wait_time_ms: 163.632\n",
      "      optimizer_step_time_ms: 74.443\n",
      "    train_throughput: 3230.61\n",
      "  iterations_since_restore: 23\n",
      "  node_ip: 10.236.176.76\n",
      "  num_healthy_workers: 7\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.68\n",
      "    ram_util_percent: 63.60666666666667\n",
      "  pid: 13004\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 7.4552749230028414\n",
      "    mean_inference_ms: 2.1994062397415632\n",
      "    mean_processing_ms: 0.4754521229170502\n",
      "  time_since_restore: 239.9860382080078\n",
      "  time_this_iter_s: 10.511430263519287\n",
      "  time_total_s: 239.9860382080078\n",
      "  timestamp: 1583958394\n",
      "  timesteps_since_restore: 774000\n",
      "  timesteps_this_iter: 34000\n",
      "  timesteps_total: 774000\n",
      "  training_iteration: 23\n",
      "  trial_id: 00c00974\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 9.9/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8/8 CPUs, 1/1 GPUs, 0.0/7.76 GiB heap, 0.0/2.69 GiB objects<br>Result logdir: /home/qian/ray_results/pong-impala-fast<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                        </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>IMPALA_PongNoFrameskip-v4_00c00974</td><td>RUNNING </td><td>10.236.176.76:13004</td><td style=\"text-align: right;\">  -20.54</td><td style=\"text-align: right;\">         239.986</td><td style=\"text-align: right;\">774000</td><td style=\"text-align: right;\">    23</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for IMPALA_PongNoFrameskip-v4_00c00974:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-03-11_16-26-44\n",
      "  done: false\n",
      "  episode_len_mean: 3535.29\n",
      "  episode_reward_max: -17.0\n",
      "  episode_reward_mean: -20.45\n",
      "  episode_reward_min: -21.0\n",
      "  episodes_this_iter: 40\n",
      "  episodes_total: 1005\n",
      "  experiment_id: 92f0827d37354e42be7025ff72050188\n",
      "  experiment_tag: '0'\n",
      "  hostname: qian-XPS-8920\n",
      "  info:\n",
      "    learner:\n",
      "      cur_lr: 0.0005000000237487257\n",
      "      entropy: 1599.383544921875\n",
      "      entropy_coeff: 0.009999999776482582\n",
      "      grad_gnorm: 40.0\n",
      "      model: {}\n",
      "      policy_loss: 31.953630447387695\n",
      "      var_gnorm: 13.004910469055176\n",
      "      vf_explained_var: 0.8404693603515625\n",
      "      vf_loss: 13.276896476745605\n",
      "    learner_queue:\n",
      "      size_count: 808\n",
      "      size_mean: 0.0\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      size_std: 0.0\n",
      "    num_steps_replayed: 0\n",
      "    num_steps_sampled: 808000\n",
      "    num_steps_trained: 807000\n",
      "    num_weight_syncs: 3234\n",
      "    sample_throughput: 3245.763\n",
      "    timing_breakdown:\n",
      "      learner_dequeue_time_ms: 4886.211\n",
      "      learner_grad_time_ms: 132.683\n",
      "      learner_load_time_ms: 23.538\n",
      "      learner_load_wait_time_ms: 175.279\n",
      "      optimizer_step_time_ms: 63.061\n",
      "    train_throughput: 3245.763\n",
      "  iterations_since_restore: 24\n",
      "  node_ip: 10.236.176.76\n",
      "  num_healthy_workers: 7\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.70666666666666\n",
      "    ram_util_percent: 64.02000000000001\n",
      "  pid: 13004\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 7.456319265295549\n",
      "    mean_inference_ms: 2.1994513028263287\n",
      "    mean_processing_ms: 0.4753036549422967\n",
      "  time_since_restore: 250.44820713996887\n",
      "  time_this_iter_s: 10.46216893196106\n",
      "  time_total_s: 250.44820713996887\n",
      "  timestamp: 1583958404\n",
      "  timesteps_since_restore: 808000\n",
      "  timesteps_this_iter: 34000\n",
      "  timesteps_total: 808000\n",
      "  training_iteration: 24\n",
      "  trial_id: 00c00974\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.0/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8/8 CPUs, 1/1 GPUs, 0.0/7.76 GiB heap, 0.0/2.69 GiB objects<br>Result logdir: /home/qian/ray_results/pong-impala-fast<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                        </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>IMPALA_PongNoFrameskip-v4_00c00974</td><td>RUNNING </td><td>10.236.176.76:13004</td><td style=\"text-align: right;\">  -20.45</td><td style=\"text-align: right;\">         250.448</td><td style=\"text-align: right;\">808000</td><td style=\"text-align: right;\">    24</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for IMPALA_PongNoFrameskip-v4_00c00974:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-03-11_16-26-55\n",
      "  done: false\n",
      "  episode_len_mean: 3434.5\n",
      "  episode_reward_max: -18.0\n",
      "  episode_reward_mean: -20.58\n",
      "  episode_reward_min: -21.0\n",
      "  episodes_this_iter: 39\n",
      "  episodes_total: 1044\n",
      "  experiment_id: 92f0827d37354e42be7025ff72050188\n",
      "  experiment_tag: '0'\n",
      "  hostname: qian-XPS-8920\n",
      "  info:\n",
      "    learner:\n",
      "      cur_lr: 0.0005000000237487257\n",
      "      entropy: 1681.9005126953125\n",
      "      entropy_coeff: 0.009999999776482582\n",
      "      grad_gnorm: 40.0\n",
      "      model: {}\n",
      "      policy_loss: 14.644647598266602\n",
      "      var_gnorm: 13.164284706115723\n",
      "      vf_explained_var: 0.7714036703109741\n",
      "      vf_loss: 18.333057403564453\n",
      "    learner_queue:\n",
      "      size_count: 842\n",
      "      size_mean: 0.0\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      size_std: 0.0\n",
      "    num_steps_replayed: 0\n",
      "    num_steps_sampled: 842000\n",
      "    num_steps_trained: 842000\n",
      "    num_weight_syncs: 3370\n",
      "    sample_throughput: 3259.084\n",
      "    timing_breakdown:\n",
      "      learner_dequeue_time_ms: 4870.602\n",
      "      learner_grad_time_ms: 134.127\n",
      "      learner_load_time_ms: 26.807\n",
      "      learner_load_wait_time_ms: 162.339\n",
      "      optimizer_step_time_ms: 80.555\n",
      "    train_throughput: 3354.94\n",
      "  iterations_since_restore: 25\n",
      "  node_ip: 10.236.176.76\n",
      "  num_healthy_workers: 7\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.72142857142858\n",
      "    ram_util_percent: 64.42857142857143\n",
      "  pid: 13004\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 7.456537349027529\n",
      "    mean_inference_ms: 2.1981233216257423\n",
      "    mean_processing_ms: 0.474907539582391\n",
      "  time_since_restore: 260.8684780597687\n",
      "  time_this_iter_s: 10.420270919799805\n",
      "  time_total_s: 260.8684780597687\n",
      "  timestamp: 1583958415\n",
      "  timesteps_since_restore: 842000\n",
      "  timesteps_this_iter: 34000\n",
      "  timesteps_total: 842000\n",
      "  training_iteration: 25\n",
      "  trial_id: 00c00974\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.1/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8/8 CPUs, 1/1 GPUs, 0.0/7.76 GiB heap, 0.0/2.69 GiB objects<br>Result logdir: /home/qian/ray_results/pong-impala-fast<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                        </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>IMPALA_PongNoFrameskip-v4_00c00974</td><td>RUNNING </td><td>10.236.176.76:13004</td><td style=\"text-align: right;\">  -20.58</td><td style=\"text-align: right;\">         260.868</td><td style=\"text-align: right;\">842000</td><td style=\"text-align: right;\">    25</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for IMPALA_PongNoFrameskip-v4_00c00974:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-03-11_16-27-05\n",
      "  done: false\n",
      "  episode_len_mean: 3403.51\n",
      "  episode_reward_max: -18.0\n",
      "  episode_reward_mean: -20.61\n",
      "  episode_reward_min: -21.0\n",
      "  episodes_this_iter: 36\n",
      "  episodes_total: 1080\n",
      "  experiment_id: 92f0827d37354e42be7025ff72050188\n",
      "  experiment_tag: '0'\n",
      "  hostname: qian-XPS-8920\n",
      "  info:\n",
      "    learner:\n",
      "      cur_lr: 0.0005000000237487257\n",
      "      entropy: 1662.663818359375\n",
      "      entropy_coeff: 0.009999999776482582\n",
      "      grad_gnorm: 40.0\n",
      "      model: {}\n",
      "      policy_loss: -42.13800048828125\n",
      "      var_gnorm: 13.34787654876709\n",
      "      vf_explained_var: 0.7157775163650513\n",
      "      vf_loss: 21.4232177734375\n",
      "    learner_queue:\n",
      "      size_count: 876\n",
      "      size_mean: 0.0\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      size_std: 0.0\n",
      "    num_steps_replayed: 0\n",
      "    num_steps_sampled: 876000\n",
      "    num_steps_trained: 875000\n",
      "    num_weight_syncs: 3505\n",
      "    sample_throughput: 3276.571\n",
      "    timing_breakdown:\n",
      "      learner_dequeue_time_ms: 4885.366\n",
      "      learner_grad_time_ms: 135.074\n",
      "      learner_load_time_ms: 25.277\n",
      "      learner_load_wait_time_ms: 172.398\n",
      "      optimizer_step_time_ms: 90.363\n",
      "    train_throughput: 3180.201\n",
      "  iterations_since_restore: 26\n",
      "  node_ip: 10.236.176.76\n",
      "  num_healthy_workers: 7\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.18666666666667\n",
      "    ram_util_percent: 64.96000000000001\n",
      "  pid: 13004\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 7.455208705751289\n",
      "    mean_inference_ms: 2.196659694390914\n",
      "    mean_processing_ms: 0.4741155996813282\n",
      "  time_since_restore: 271.2307696342468\n",
      "  time_this_iter_s: 10.36229157447815\n",
      "  time_total_s: 271.2307696342468\n",
      "  timestamp: 1583958425\n",
      "  timesteps_since_restore: 876000\n",
      "  timesteps_this_iter: 34000\n",
      "  timesteps_total: 876000\n",
      "  training_iteration: 26\n",
      "  trial_id: 00c00974\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.1/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8/8 CPUs, 1/1 GPUs, 0.0/7.76 GiB heap, 0.0/2.69 GiB objects<br>Result logdir: /home/qian/ray_results/pong-impala-fast<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                        </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>IMPALA_PongNoFrameskip-v4_00c00974</td><td>RUNNING </td><td>10.236.176.76:13004</td><td style=\"text-align: right;\">  -20.61</td><td style=\"text-align: right;\">         271.231</td><td style=\"text-align: right;\">876000</td><td style=\"text-align: right;\">    26</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for IMPALA_PongNoFrameskip-v4_00c00974:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-03-11_16-27-16\n",
      "  done: false\n",
      "  episode_len_mean: 3496.1\n",
      "  episode_reward_max: -18.0\n",
      "  episode_reward_mean: -20.53\n",
      "  episode_reward_min: -21.0\n",
      "  episodes_this_iter: 35\n",
      "  episodes_total: 1115\n",
      "  experiment_id: 92f0827d37354e42be7025ff72050188\n",
      "  experiment_tag: '0'\n",
      "  hostname: qian-XPS-8920\n",
      "  info:\n",
      "    learner:\n",
      "      cur_lr: 0.0005000000237487257\n",
      "      entropy: 1719.791748046875\n",
      "      entropy_coeff: 0.009999999776482582\n",
      "      grad_gnorm: 40.0\n",
      "      model: {}\n",
      "      policy_loss: -36.872806549072266\n",
      "      var_gnorm: 13.492778778076172\n",
      "      vf_explained_var: 0.47007036209106445\n",
      "      vf_loss: 25.893020629882812\n",
      "    learner_queue:\n",
      "      size_count: 910\n",
      "      size_mean: 0.0\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      size_std: 0.0\n",
      "    num_steps_replayed: 0\n",
      "    num_steps_sampled: 910000\n",
      "    num_steps_trained: 909000\n",
      "    num_weight_syncs: 3641\n",
      "    sample_throughput: 3259.456\n",
      "    timing_breakdown:\n",
      "      learner_dequeue_time_ms: 4881.307\n",
      "      learner_grad_time_ms: 133.917\n",
      "      learner_load_time_ms: 32.272\n",
      "      learner_load_wait_time_ms: 163.967\n",
      "      optimizer_step_time_ms: 72.058\n",
      "    train_throughput: 3259.456\n",
      "  iterations_since_restore: 27\n",
      "  node_ip: 10.236.176.76\n",
      "  num_healthy_workers: 7\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.35999999999999\n",
      "    ram_util_percent: 65.29333333333332\n",
      "  pid: 13004\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 7.455095906329074\n",
      "    mean_inference_ms: 2.195171761506781\n",
      "    mean_processing_ms: 0.4730309461222403\n",
      "  time_since_restore: 281.64903354644775\n",
      "  time_this_iter_s: 10.418263912200928\n",
      "  time_total_s: 281.64903354644775\n",
      "  timestamp: 1583958436\n",
      "  timesteps_since_restore: 910000\n",
      "  timesteps_this_iter: 34000\n",
      "  timesteps_total: 910000\n",
      "  training_iteration: 27\n",
      "  trial_id: 00c00974\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.2/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8/8 CPUs, 1/1 GPUs, 0.0/7.76 GiB heap, 0.0/2.69 GiB objects<br>Result logdir: /home/qian/ray_results/pong-impala-fast<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                        </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>IMPALA_PongNoFrameskip-v4_00c00974</td><td>RUNNING </td><td>10.236.176.76:13004</td><td style=\"text-align: right;\">  -20.53</td><td style=\"text-align: right;\">         281.649</td><td style=\"text-align: right;\">910000</td><td style=\"text-align: right;\">    27</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for IMPALA_PongNoFrameskip-v4_00c00974:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-03-11_16-27-26\n",
      "  done: false\n",
      "  episode_len_mean: 3647.77\n",
      "  episode_reward_max: -18.0\n",
      "  episode_reward_mean: -20.33\n",
      "  episode_reward_min: -21.0\n",
      "  episodes_this_iter: 37\n",
      "  episodes_total: 1152\n",
      "  experiment_id: 92f0827d37354e42be7025ff72050188\n",
      "  experiment_tag: '0'\n",
      "  hostname: qian-XPS-8920\n",
      "  info:\n",
      "    learner:\n",
      "      cur_lr: 0.0005000000237487257\n",
      "      entropy: 1634.4840087890625\n",
      "      entropy_coeff: 0.009999999776482582\n",
      "      grad_gnorm: 40.0\n",
      "      model: {}\n",
      "      policy_loss: -8.770087242126465\n",
      "      var_gnorm: 13.628939628601074\n",
      "      vf_explained_var: 0.6429784893989563\n",
      "      vf_loss: 15.862067222595215\n",
      "    learner_queue:\n",
      "      size_count: 944\n",
      "      size_mean: 0.0\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      size_std: 0.0\n",
      "    num_steps_replayed: 0\n",
      "    num_steps_sampled: 944000\n",
      "    num_steps_trained: 943000\n",
      "    num_weight_syncs: 3777\n",
      "    sample_throughput: 3246.72\n",
      "    timing_breakdown:\n",
      "      learner_dequeue_time_ms: 4884.049\n",
      "      learner_grad_time_ms: 134.059\n",
      "      learner_load_time_ms: 31.311\n",
      "      learner_load_wait_time_ms: 170.693\n",
      "      optimizer_step_time_ms: 76.776\n",
      "    train_throughput: 3246.721\n",
      "  iterations_since_restore: 28\n",
      "  node_ip: 10.236.176.76\n",
      "  num_healthy_workers: 7\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.83999999999999\n",
      "    ram_util_percent: 65.78\n",
      "  pid: 13004\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 7.455407602821424\n",
      "    mean_inference_ms: 2.1953915027398385\n",
      "    mean_processing_ms: 0.47234677152120885\n",
      "  time_since_restore: 292.10859847068787\n",
      "  time_this_iter_s: 10.459564924240112\n",
      "  time_total_s: 292.10859847068787\n",
      "  timestamp: 1583958446\n",
      "  timesteps_since_restore: 944000\n",
      "  timesteps_this_iter: 34000\n",
      "  timesteps_total: 944000\n",
      "  training_iteration: 28\n",
      "  trial_id: 00c00974\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.3/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8/8 CPUs, 1/1 GPUs, 0.0/7.76 GiB heap, 0.0/2.69 GiB objects<br>Result logdir: /home/qian/ray_results/pong-impala-fast<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                        </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>IMPALA_PongNoFrameskip-v4_00c00974</td><td>RUNNING </td><td>10.236.176.76:13004</td><td style=\"text-align: right;\">  -20.33</td><td style=\"text-align: right;\">         292.109</td><td style=\"text-align: right;\">944000</td><td style=\"text-align: right;\">    28</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for IMPALA_PongNoFrameskip-v4_00c00974:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-03-11_16-27-36\n",
      "  done: false\n",
      "  episode_len_mean: 3642.36\n",
      "  episode_reward_max: -18.0\n",
      "  episode_reward_mean: -20.32\n",
      "  episode_reward_min: -21.0\n",
      "  episodes_this_iter: 40\n",
      "  episodes_total: 1192\n",
      "  experiment_id: 92f0827d37354e42be7025ff72050188\n",
      "  experiment_tag: '0'\n",
      "  hostname: qian-XPS-8920\n",
      "  info:\n",
      "    learner:\n",
      "      cur_lr: 0.0005000000237487257\n",
      "      entropy: 1667.537353515625\n",
      "      entropy_coeff: 0.009999999776482582\n",
      "      grad_gnorm: 40.0\n",
      "      model: {}\n",
      "      policy_loss: 207.74041748046875\n",
      "      var_gnorm: 13.818253517150879\n",
      "      vf_explained_var: 0.7659886479377747\n",
      "      vf_loss: 46.778282165527344\n",
      "    learner_queue:\n",
      "      size_count: 978\n",
      "      size_mean: 0.0\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      size_std: 0.0\n",
      "    num_steps_replayed: 0\n",
      "    num_steps_sampled: 978000\n",
      "    num_steps_trained: 977000\n",
      "    num_weight_syncs: 3913\n",
      "    sample_throughput: 3244.988\n",
      "    timing_breakdown:\n",
      "      learner_dequeue_time_ms: 4881.867\n",
      "      learner_grad_time_ms: 134.416\n",
      "      learner_load_time_ms: 29.162\n",
      "      learner_load_wait_time_ms: 168.173\n",
      "      optimizer_step_time_ms: 82.641\n",
      "    train_throughput: 3244.988\n",
      "  iterations_since_restore: 29\n",
      "  node_ip: 10.236.176.76\n",
      "  num_healthy_workers: 7\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.74666666666667\n",
      "    ram_util_percent: 66.19999999999999\n",
      "  pid: 13004\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 7.4552202995147665\n",
      "    mean_inference_ms: 2.194986448358719\n",
      "    mean_processing_ms: 0.47202871231618365\n",
      "  time_since_restore: 302.573753118515\n",
      "  time_this_iter_s: 10.465154647827148\n",
      "  time_total_s: 302.573753118515\n",
      "  timestamp: 1583958456\n",
      "  timesteps_since_restore: 978000\n",
      "  timesteps_this_iter: 34000\n",
      "  timesteps_total: 978000\n",
      "  training_iteration: 29\n",
      "  trial_id: 00c00974\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.3/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8/8 CPUs, 1/1 GPUs, 0.0/7.76 GiB heap, 0.0/2.69 GiB objects<br>Result logdir: /home/qian/ray_results/pong-impala-fast<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                        </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>IMPALA_PongNoFrameskip-v4_00c00974</td><td>RUNNING </td><td>10.236.176.76:13004</td><td style=\"text-align: right;\">  -20.32</td><td style=\"text-align: right;\">         302.574</td><td style=\"text-align: right;\">978000</td><td style=\"text-align: right;\">    29</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for IMPALA_PongNoFrameskip-v4_00c00974:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-03-11_16-27-47\n",
      "  done: false\n",
      "  episode_len_mean: 3624.8\n",
      "  episode_reward_max: -18.0\n",
      "  episode_reward_mean: -20.21\n",
      "  episode_reward_min: -21.0\n",
      "  episodes_this_iter: 35\n",
      "  episodes_total: 1227\n",
      "  experiment_id: 92f0827d37354e42be7025ff72050188\n",
      "  experiment_tag: '0'\n",
      "  hostname: qian-XPS-8920\n",
      "  info:\n",
      "    learner:\n",
      "      cur_lr: 0.0005000000237487257\n",
      "      entropy: 1698.872802734375\n",
      "      entropy_coeff: 0.009999999776482582\n",
      "      grad_gnorm: 40.0\n",
      "      model: {}\n",
      "      policy_loss: -82.8425064086914\n",
      "      var_gnorm: 13.959712982177734\n",
      "      vf_explained_var: 0.573201060295105\n",
      "      vf_loss: 25.131118774414062\n",
      "    learner_queue:\n",
      "      size_count: 1012\n",
      "      size_mean: 0.0\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      size_std: 0.0\n",
      "    num_steps_replayed: 0\n",
      "    num_steps_sampled: 1012000\n",
      "    num_steps_trained: 1011000\n",
      "    num_weight_syncs: 4049\n",
      "    sample_throughput: 3257.459\n",
      "    timing_breakdown:\n",
      "      learner_dequeue_time_ms: 4884.477\n",
      "      learner_grad_time_ms: 133.997\n",
      "      learner_load_time_ms: 27.282\n",
      "      learner_load_wait_time_ms: 173.36\n",
      "      optimizer_step_time_ms: 67.717\n",
      "    train_throughput: 3257.46\n",
      "  iterations_since_restore: 30\n",
      "  node_ip: 10.236.176.76\n",
      "  num_healthy_workers: 7\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.13333333333335\n",
      "    ram_util_percent: 66.66666666666666\n",
      "  pid: 13004\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 7.454808494338283\n",
      "    mean_inference_ms: 2.194975631366228\n",
      "    mean_processing_ms: 0.4717021387146961\n",
      "  time_since_restore: 312.99879455566406\n",
      "  time_this_iter_s: 10.425041437149048\n",
      "  time_total_s: 312.99879455566406\n",
      "  timestamp: 1583958467\n",
      "  timesteps_since_restore: 1012000\n",
      "  timesteps_this_iter: 34000\n",
      "  timesteps_total: 1012000\n",
      "  training_iteration: 30\n",
      "  trial_id: 00c00974\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.4/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8/8 CPUs, 1/1 GPUs, 0.0/7.76 GiB heap, 0.0/2.69 GiB objects<br>Result logdir: /home/qian/ray_results/pong-impala-fast<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                        </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>IMPALA_PongNoFrameskip-v4_00c00974</td><td>RUNNING </td><td>10.236.176.76:13004</td><td style=\"text-align: right;\">  -20.21</td><td style=\"text-align: right;\">         312.999</td><td style=\"text-align: right;\">1012000</td><td style=\"text-align: right;\">    30</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for IMPALA_PongNoFrameskip-v4_00c00974:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-03-11_16-27-57\n",
      "  done: false\n",
      "  episode_len_mean: 3692.54\n",
      "  episode_reward_max: -18.0\n",
      "  episode_reward_mean: -20.12\n",
      "  episode_reward_min: -21.0\n",
      "  episodes_this_iter: 39\n",
      "  episodes_total: 1266\n",
      "  experiment_id: 92f0827d37354e42be7025ff72050188\n",
      "  experiment_tag: '0'\n",
      "  hostname: qian-XPS-8920\n",
      "  info:\n",
      "    learner:\n",
      "      cur_lr: 0.0005000000237487257\n",
      "      entropy: 1618.65625\n",
      "      entropy_coeff: 0.009999999776482582\n",
      "      grad_gnorm: 40.000003814697266\n",
      "      model: {}\n",
      "      policy_loss: -4.920584678649902\n",
      "      var_gnorm: 14.158555030822754\n",
      "      vf_explained_var: 0.8303945064544678\n",
      "      vf_loss: 10.154319763183594\n",
      "    learner_queue:\n",
      "      size_count: 1046\n",
      "      size_mean: 0.0\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      size_std: 0.0\n",
      "    num_steps_replayed: 0\n",
      "    num_steps_sampled: 1046000\n",
      "    num_steps_trained: 1045000\n",
      "    num_weight_syncs: 4184\n",
      "    sample_throughput: 3269.712\n",
      "    timing_breakdown:\n",
      "      learner_dequeue_time_ms: 4890.783\n",
      "      learner_grad_time_ms: 136.243\n",
      "      learner_load_time_ms: 21.102\n",
      "      learner_load_wait_time_ms: 174.594\n",
      "      optimizer_step_time_ms: 93.795\n",
      "    train_throughput: 3269.712\n",
      "  iterations_since_restore: 31\n",
      "  node_ip: 10.236.176.76\n",
      "  num_healthy_workers: 7\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.12666666666668\n",
      "    ram_util_percent: 67.10666666666667\n",
      "  pid: 13004\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 7.454271470244114\n",
      "    mean_inference_ms: 2.1945452752588124\n",
      "    mean_processing_ms: 0.4714271746075253\n",
      "  time_since_restore: 323.3843309879303\n",
      "  time_this_iter_s: 10.385536432266235\n",
      "  time_total_s: 323.3843309879303\n",
      "  timestamp: 1583958477\n",
      "  timesteps_since_restore: 1046000\n",
      "  timesteps_this_iter: 34000\n",
      "  timesteps_total: 1046000\n",
      "  training_iteration: 31\n",
      "  trial_id: 00c00974\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.5/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8/8 CPUs, 1/1 GPUs, 0.0/7.76 GiB heap, 0.0/2.69 GiB objects<br>Result logdir: /home/qian/ray_results/pong-impala-fast<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                        </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>IMPALA_PongNoFrameskip-v4_00c00974</td><td>RUNNING </td><td>10.236.176.76:13004</td><td style=\"text-align: right;\">  -20.12</td><td style=\"text-align: right;\">         323.384</td><td style=\"text-align: right;\">1046000</td><td style=\"text-align: right;\">    31</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for IMPALA_PongNoFrameskip-v4_00c00974:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-03-11_16-28-08\n",
      "  done: false\n",
      "  episode_len_mean: 3742.12\n",
      "  episode_reward_max: -18.0\n",
      "  episode_reward_mean: -19.99\n",
      "  episode_reward_min: -21.0\n",
      "  episodes_this_iter: 42\n",
      "  episodes_total: 1308\n",
      "  experiment_id: 92f0827d37354e42be7025ff72050188\n",
      "  experiment_tag: '0'\n",
      "  hostname: qian-XPS-8920\n",
      "  info:\n",
      "    learner:\n",
      "      cur_lr: 0.0005000000237487257\n",
      "      entropy: 1692.2939453125\n",
      "      entropy_coeff: 0.009999999776482582\n",
      "      grad_gnorm: 40.000003814697266\n",
      "      model: {}\n",
      "      policy_loss: 8.095510482788086\n",
      "      var_gnorm: 14.317482948303223\n",
      "      vf_explained_var: 0.7198552489280701\n",
      "      vf_loss: 24.241432189941406\n",
      "    learner_queue:\n",
      "      size_count: 1080\n",
      "      size_mean: 0.0\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      size_std: 0.0\n",
      "    num_steps_replayed: 0\n",
      "    num_steps_sampled: 1080000\n",
      "    num_steps_trained: 1080000\n",
      "    num_weight_syncs: 4321\n",
      "    sample_throughput: 3225.821\n",
      "    timing_breakdown:\n",
      "      learner_dequeue_time_ms: 4891.598\n",
      "      learner_grad_time_ms: 135.471\n",
      "      learner_load_time_ms: 19.096\n",
      "      learner_load_wait_time_ms: 160.488\n",
      "      optimizer_step_time_ms: 79.687\n",
      "    train_throughput: 3320.698\n",
      "  iterations_since_restore: 32\n",
      "  node_ip: 10.236.176.76\n",
      "  num_healthy_workers: 7\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.58\n",
      "    ram_util_percent: 67.52000000000001\n",
      "  pid: 13004\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 7.454879708315345\n",
      "    mean_inference_ms: 2.195957534323751\n",
      "    mean_processing_ms: 0.47148434386571964\n",
      "  time_since_restore: 333.9119257926941\n",
      "  time_this_iter_s: 10.527594804763794\n",
      "  time_total_s: 333.9119257926941\n",
      "  timestamp: 1583958488\n",
      "  timesteps_since_restore: 1080000\n",
      "  timesteps_this_iter: 34000\n",
      "  timesteps_total: 1080000\n",
      "  training_iteration: 32\n",
      "  trial_id: 00c00974\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.5/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8/8 CPUs, 1/1 GPUs, 0.0/7.76 GiB heap, 0.0/2.69 GiB objects<br>Result logdir: /home/qian/ray_results/pong-impala-fast<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                        </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>IMPALA_PongNoFrameskip-v4_00c00974</td><td>RUNNING </td><td>10.236.176.76:13004</td><td style=\"text-align: right;\">  -19.99</td><td style=\"text-align: right;\">         333.912</td><td style=\"text-align: right;\">1080000</td><td style=\"text-align: right;\">    32</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for IMPALA_PongNoFrameskip-v4_00c00974:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-03-11_16-28-18\n",
      "  done: false\n",
      "  episode_len_mean: 3687.91\n",
      "  episode_reward_max: -18.0\n",
      "  episode_reward_mean: -20.12\n",
      "  episode_reward_min: -21.0\n",
      "  episodes_this_iter: 37\n",
      "  episodes_total: 1345\n",
      "  experiment_id: 92f0827d37354e42be7025ff72050188\n",
      "  experiment_tag: '0'\n",
      "  hostname: qian-XPS-8920\n",
      "  info:\n",
      "    learner:\n",
      "      cur_lr: 0.0005000000237487257\n",
      "      entropy: 1671.63330078125\n",
      "      entropy_coeff: 0.009999999776482582\n",
      "      grad_gnorm: 39.999996185302734\n",
      "      model: {}\n",
      "      policy_loss: -39.26728057861328\n",
      "      var_gnorm: 14.474471092224121\n",
      "      vf_explained_var: 0.8476907014846802\n",
      "      vf_loss: 14.572874069213867\n",
      "    learner_queue:\n",
      "      size_count: 1114\n",
      "      size_mean: 0.0\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      size_std: 0.0\n",
      "    num_steps_replayed: 0\n",
      "    num_steps_sampled: 1114000\n",
      "    num_steps_trained: 1113000\n",
      "    num_weight_syncs: 4457\n",
      "    sample_throughput: 3238.609\n",
      "    timing_breakdown:\n",
      "      learner_dequeue_time_ms: 4889.886\n",
      "      learner_grad_time_ms: 134.39\n",
      "      learner_load_time_ms: 19.368\n",
      "      learner_load_wait_time_ms: 175.155\n",
      "      optimizer_step_time_ms: 85.913\n",
      "    train_throughput: 3143.356\n",
      "  iterations_since_restore: 33\n",
      "  node_ip: 10.236.176.76\n",
      "  num_healthy_workers: 7\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.57333333333334\n",
      "    ram_util_percent: 67.98000000000002\n",
      "  pid: 13004\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 7.45512394245456\n",
      "    mean_inference_ms: 2.195902216172537\n",
      "    mean_processing_ms: 0.471339127442807\n",
      "  time_since_restore: 344.3974869251251\n",
      "  time_this_iter_s: 10.48556113243103\n",
      "  time_total_s: 344.3974869251251\n",
      "  timestamp: 1583958498\n",
      "  timesteps_since_restore: 1114000\n",
      "  timesteps_this_iter: 34000\n",
      "  timesteps_total: 1114000\n",
      "  training_iteration: 33\n",
      "  trial_id: 00c00974\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.6/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8/8 CPUs, 1/1 GPUs, 0.0/7.76 GiB heap, 0.0/2.69 GiB objects<br>Result logdir: /home/qian/ray_results/pong-impala-fast<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                        </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>IMPALA_PongNoFrameskip-v4_00c00974</td><td>RUNNING </td><td>10.236.176.76:13004</td><td style=\"text-align: right;\">  -20.12</td><td style=\"text-align: right;\">         344.397</td><td style=\"text-align: right;\">1114000</td><td style=\"text-align: right;\">    33</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for IMPALA_PongNoFrameskip-v4_00c00974:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-03-11_16-28-29\n",
      "  done: false\n",
      "  episode_len_mean: 3616.95\n",
      "  episode_reward_max: -18.0\n",
      "  episode_reward_mean: -20.29\n",
      "  episode_reward_min: -21.0\n",
      "  episodes_this_iter: 30\n",
      "  episodes_total: 1375\n",
      "  experiment_id: 92f0827d37354e42be7025ff72050188\n",
      "  experiment_tag: '0'\n",
      "  hostname: qian-XPS-8920\n",
      "  info:\n",
      "    learner:\n",
      "      cur_lr: 0.0005000000237487257\n",
      "      entropy: 1660.5638427734375\n",
      "      entropy_coeff: 0.009999999776482582\n",
      "      grad_gnorm: 40.0\n",
      "      model: {}\n",
      "      policy_loss: -63.22930908203125\n",
      "      var_gnorm: 14.593052864074707\n",
      "      vf_explained_var: 0.8867931365966797\n",
      "      vf_loss: 11.762579917907715\n",
      "    learner_queue:\n",
      "      size_count: 1148\n",
      "      size_mean: 0.0\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      size_std: 0.0\n",
      "    num_steps_replayed: 0\n",
      "    num_steps_sampled: 1148000\n",
      "    num_steps_trained: 1147000\n",
      "    num_weight_syncs: 4592\n",
      "    sample_throughput: 3267.386\n",
      "    timing_breakdown:\n",
      "      learner_dequeue_time_ms: 4901.691\n",
      "      learner_grad_time_ms: 135.885\n",
      "      learner_load_time_ms: 20.602\n",
      "      learner_load_wait_time_ms: 173.132\n",
      "      optimizer_step_time_ms: 92.591\n",
      "    train_throughput: 3267.386\n",
      "  iterations_since_restore: 34\n",
      "  node_ip: 10.236.176.76\n",
      "  num_healthy_workers: 7\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.67333333333335\n",
      "    ram_util_percent: 68.43333333333334\n",
      "  pid: 13004\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 7.4547916782493715\n",
      "    mean_inference_ms: 2.1953337819183965\n",
      "    mean_processing_ms: 0.4709197393595885\n",
      "  time_since_restore: 354.79012632369995\n",
      "  time_this_iter_s: 10.392639398574829\n",
      "  time_total_s: 354.79012632369995\n",
      "  timestamp: 1583958509\n",
      "  timesteps_since_restore: 1148000\n",
      "  timesteps_this_iter: 34000\n",
      "  timesteps_total: 1148000\n",
      "  training_iteration: 34\n",
      "  trial_id: 00c00974\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.7/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8/8 CPUs, 1/1 GPUs, 0.0/7.76 GiB heap, 0.0/2.69 GiB objects<br>Result logdir: /home/qian/ray_results/pong-impala-fast<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                        </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>IMPALA_PongNoFrameskip-v4_00c00974</td><td>RUNNING </td><td>10.236.176.76:13004</td><td style=\"text-align: right;\">  -20.29</td><td style=\"text-align: right;\">          354.79</td><td style=\"text-align: right;\">1148000</td><td style=\"text-align: right;\">    34</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for IMPALA_PongNoFrameskip-v4_00c00974:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-03-11_16-28-39\n",
      "  done: false\n",
      "  episode_len_mean: 3778.29\n",
      "  episode_reward_max: -16.0\n",
      "  episode_reward_mean: -20.16\n",
      "  episode_reward_min: -21.0\n",
      "  episodes_this_iter: 37\n",
      "  episodes_total: 1412\n",
      "  experiment_id: 92f0827d37354e42be7025ff72050188\n",
      "  experiment_tag: '0'\n",
      "  hostname: qian-XPS-8920\n",
      "  info:\n",
      "    learner:\n",
      "      cur_lr: 0.0005000000237487257\n",
      "      entropy: 1458.6282958984375\n",
      "      entropy_coeff: 0.009999999776482582\n",
      "      grad_gnorm: 40.0\n",
      "      model: {}\n",
      "      policy_loss: 29.77704620361328\n",
      "      var_gnorm: 14.725942611694336\n",
      "      vf_explained_var: 0.8177354335784912\n",
      "      vf_loss: 18.23238754272461\n",
      "    learner_queue:\n",
      "      size_count: 1181\n",
      "      size_mean: 0.0\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      size_std: 0.0\n",
      "    num_steps_replayed: 0\n",
      "    num_steps_sampled: 1181000\n",
      "    num_steps_trained: 1181000\n",
      "    num_weight_syncs: 4727\n",
      "    sample_throughput: 3177.972\n",
      "    timing_breakdown:\n",
      "      learner_dequeue_time_ms: 4907.879\n",
      "      learner_grad_time_ms: 134.187\n",
      "      learner_load_time_ms: 20.071\n",
      "      learner_load_wait_time_ms: 156.228\n",
      "      optimizer_step_time_ms: 88.782\n",
      "    train_throughput: 3274.275\n",
      "  iterations_since_restore: 35\n",
      "  node_ip: 10.236.176.76\n",
      "  num_healthy_workers: 7\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.45\n",
      "    ram_util_percent: 68.84285714285714\n",
      "  pid: 13004\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 7.456785536306593\n",
      "    mean_inference_ms: 2.1963855814326574\n",
      "    mean_processing_ms: 0.4706510187508042\n",
      "  time_since_restore: 365.16167736053467\n",
      "  time_this_iter_s: 10.371551036834717\n",
      "  time_total_s: 365.16167736053467\n",
      "  timestamp: 1583958519\n",
      "  timesteps_since_restore: 1181000\n",
      "  timesteps_this_iter: 33000\n",
      "  timesteps_total: 1181000\n",
      "  training_iteration: 35\n",
      "  trial_id: 00c00974\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8/8 CPUs, 1/1 GPUs, 0.0/7.76 GiB heap, 0.0/2.69 GiB objects<br>Result logdir: /home/qian/ray_results/pong-impala-fast<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                        </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>IMPALA_PongNoFrameskip-v4_00c00974</td><td>RUNNING </td><td>10.236.176.76:13004</td><td style=\"text-align: right;\">  -20.16</td><td style=\"text-align: right;\">         365.162</td><td style=\"text-align: right;\">1181000</td><td style=\"text-align: right;\">    35</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for IMPALA_PongNoFrameskip-v4_00c00974:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-03-11_16-28-50\n",
      "  done: false\n",
      "  episode_len_mean: 3867.79\n",
      "  episode_reward_max: -16.0\n",
      "  episode_reward_mean: -19.97\n",
      "  episode_reward_min: -21.0\n",
      "  episodes_this_iter: 33\n",
      "  episodes_total: 1445\n",
      "  experiment_id: 92f0827d37354e42be7025ff72050188\n",
      "  experiment_tag: '0'\n",
      "  hostname: qian-XPS-8920\n",
      "  info:\n",
      "    learner:\n",
      "      cur_lr: 0.0005000000237487257\n",
      "      entropy: 1651.0244140625\n",
      "      entropy_coeff: 0.009999999776482582\n",
      "      grad_gnorm: 40.0\n",
      "      model: {}\n",
      "      policy_loss: 130.63290405273438\n",
      "      var_gnorm: 14.818488121032715\n",
      "      vf_explained_var: 0.45991069078445435\n",
      "      vf_loss: 49.06059265136719\n",
      "    learner_queue:\n",
      "      size_count: 1215\n",
      "      size_mean: 0.0\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      size_std: 0.0\n",
      "    num_steps_replayed: 0\n",
      "    num_steps_sampled: 1215000\n",
      "    num_steps_trained: 1215000\n",
      "    num_weight_syncs: 4863\n",
      "    sample_throughput: 3250.911\n",
      "    timing_breakdown:\n",
      "      learner_dequeue_time_ms: 4903.578\n",
      "      learner_grad_time_ms: 134.115\n",
      "      learner_load_time_ms: 28.695\n",
      "      learner_load_wait_time_ms: 170.547\n",
      "      optimizer_step_time_ms: 74.247\n",
      "    train_throughput: 3250.911\n",
      "  iterations_since_restore: 36\n",
      "  node_ip: 10.236.176.76\n",
      "  num_healthy_workers: 7\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.45333333333333\n",
      "    ram_util_percent: 69.23333333333332\n",
      "  pid: 13004\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 7.459004968530792\n",
      "    mean_inference_ms: 2.196640609535925\n",
      "    mean_processing_ms: 0.47027208439298107\n",
      "  time_since_restore: 375.607275724411\n",
      "  time_this_iter_s: 10.445598363876343\n",
      "  time_total_s: 375.607275724411\n",
      "  timestamp: 1583958530\n",
      "  timesteps_since_restore: 1215000\n",
      "  timesteps_this_iter: 34000\n",
      "  timesteps_total: 1215000\n",
      "  training_iteration: 36\n",
      "  trial_id: 00c00974\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8/8 CPUs, 1/1 GPUs, 0.0/7.76 GiB heap, 0.0/2.69 GiB objects<br>Result logdir: /home/qian/ray_results/pong-impala-fast<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                        </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>IMPALA_PongNoFrameskip-v4_00c00974</td><td>RUNNING </td><td>10.236.176.76:13004</td><td style=\"text-align: right;\">  -19.97</td><td style=\"text-align: right;\">         375.607</td><td style=\"text-align: right;\">1215000</td><td style=\"text-align: right;\">    36</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for IMPALA_PongNoFrameskip-v4_00c00974:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-03-11_16-29-00\n",
      "  done: false\n",
      "  episode_len_mean: 3951.9\n",
      "  episode_reward_max: -16.0\n",
      "  episode_reward_mean: -19.91\n",
      "  episode_reward_min: -21.0\n",
      "  episodes_this_iter: 33\n",
      "  episodes_total: 1478\n",
      "  experiment_id: 92f0827d37354e42be7025ff72050188\n",
      "  experiment_tag: '0'\n",
      "  hostname: qian-XPS-8920\n",
      "  info:\n",
      "    learner:\n",
      "      cur_lr: 0.0005000000237487257\n",
      "      entropy: 1671.125244140625\n",
      "      entropy_coeff: 0.009999999776482582\n",
      "      grad_gnorm: 40.0\n",
      "      model: {}\n",
      "      policy_loss: 43.48185729980469\n",
      "      var_gnorm: 14.865190505981445\n",
      "      vf_explained_var: 0.35184431076049805\n",
      "      vf_loss: 64.8327865600586\n",
      "    learner_queue:\n",
      "      size_count: 1249\n",
      "      size_mean: 0.0\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      size_std: 0.0\n",
      "    num_steps_replayed: 0\n",
      "    num_steps_sampled: 1249000\n",
      "    num_steps_trained: 1249000\n",
      "    num_weight_syncs: 4999\n",
      "    sample_throughput: 3257.346\n",
      "    timing_breakdown:\n",
      "      learner_dequeue_time_ms: 4877.917\n",
      "      learner_grad_time_ms: 135.328\n",
      "      learner_load_time_ms: 28.232\n",
      "      learner_load_wait_time_ms: 162.298\n",
      "      optimizer_step_time_ms: 82.84\n",
      "    train_throughput: 3257.346\n",
      "  iterations_since_restore: 37\n",
      "  node_ip: 10.236.176.76\n",
      "  num_healthy_workers: 7\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.75333333333333\n",
      "    ram_util_percent: 69.66\n",
      "  pid: 13004\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 7.458404725426828\n",
      "    mean_inference_ms: 2.1948868484515667\n",
      "    mean_processing_ms: 0.46940861494231995\n",
      "  time_since_restore: 386.03224420547485\n",
      "  time_this_iter_s: 10.424968481063843\n",
      "  time_total_s: 386.03224420547485\n",
      "  timestamp: 1583958540\n",
      "  timesteps_since_restore: 1249000\n",
      "  timesteps_this_iter: 34000\n",
      "  timesteps_total: 1249000\n",
      "  training_iteration: 37\n",
      "  trial_id: 00c00974\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.9/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8/8 CPUs, 1/1 GPUs, 0.0/7.76 GiB heap, 0.0/2.69 GiB objects<br>Result logdir: /home/qian/ray_results/pong-impala-fast<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                        </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>IMPALA_PongNoFrameskip-v4_00c00974</td><td>RUNNING </td><td>10.236.176.76:13004</td><td style=\"text-align: right;\">  -19.91</td><td style=\"text-align: right;\">         386.032</td><td style=\"text-align: right;\">1249000</td><td style=\"text-align: right;\">    37</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for IMPALA_PongNoFrameskip-v4_00c00974:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-03-11_16-29-10\n",
      "  done: false\n",
      "  episode_len_mean: 3970.05\n",
      "  episode_reward_max: -16.0\n",
      "  episode_reward_mean: -19.87\n",
      "  episode_reward_min: -21.0\n",
      "  episodes_this_iter: 35\n",
      "  episodes_total: 1513\n",
      "  experiment_id: 92f0827d37354e42be7025ff72050188\n",
      "  experiment_tag: '0'\n",
      "  hostname: qian-XPS-8920\n",
      "  info:\n",
      "    learner:\n",
      "      cur_lr: 0.0005000000237487257\n",
      "      entropy: 1554.6966552734375\n",
      "      entropy_coeff: 0.009999999776482582\n",
      "      grad_gnorm: 40.0\n",
      "      model: {}\n",
      "      policy_loss: -7.424671649932861\n",
      "      var_gnorm: 14.9569091796875\n",
      "      vf_explained_var: 0.8687633275985718\n",
      "      vf_loss: 12.701977729797363\n",
      "    learner_queue:\n",
      "      size_count: 1283\n",
      "      size_mean: 0.0\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      size_std: 0.0\n",
      "    num_steps_replayed: 0\n",
      "    num_steps_sampled: 1283000\n",
      "    num_steps_trained: 1283000\n",
      "    num_weight_syncs: 5134\n",
      "    sample_throughput: 3266.518\n",
      "    timing_breakdown:\n",
      "      learner_dequeue_time_ms: 4887.573\n",
      "      learner_grad_time_ms: 133.378\n",
      "      learner_load_time_ms: 28.999\n",
      "      learner_load_wait_time_ms: 157.833\n",
      "      optimizer_step_time_ms: 80.298\n",
      "    train_throughput: 3266.518\n",
      "  iterations_since_restore: 38\n",
      "  node_ip: 10.236.176.76\n",
      "  num_healthy_workers: 7\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.30000000000001\n",
      "    ram_util_percent: 70.08666666666667\n",
      "  pid: 13004\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 7.458914476241364\n",
      "    mean_inference_ms: 2.1940901694831494\n",
      "    mean_processing_ms: 0.4688028851290141\n",
      "  time_since_restore: 396.42797660827637\n",
      "  time_this_iter_s: 10.395732402801514\n",
      "  time_total_s: 396.42797660827637\n",
      "  timestamp: 1583958550\n",
      "  timesteps_since_restore: 1283000\n",
      "  timesteps_this_iter: 34000\n",
      "  timesteps_total: 1283000\n",
      "  training_iteration: 38\n",
      "  trial_id: 00c00974\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.9/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8/8 CPUs, 1/1 GPUs, 0.0/7.76 GiB heap, 0.0/2.69 GiB objects<br>Result logdir: /home/qian/ray_results/pong-impala-fast<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                        </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>IMPALA_PongNoFrameskip-v4_00c00974</td><td>RUNNING </td><td>10.236.176.76:13004</td><td style=\"text-align: right;\">  -19.87</td><td style=\"text-align: right;\">         396.428</td><td style=\"text-align: right;\">1283000</td><td style=\"text-align: right;\">    38</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for IMPALA_PongNoFrameskip-v4_00c00974:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-03-11_16-29-21\n",
      "  done: false\n",
      "  episode_len_mean: 3978.07\n",
      "  episode_reward_max: -17.0\n",
      "  episode_reward_mean: -19.87\n",
      "  episode_reward_min: -21.0\n",
      "  episodes_this_iter: 31\n",
      "  episodes_total: 1544\n",
      "  experiment_id: 92f0827d37354e42be7025ff72050188\n",
      "  experiment_tag: '0'\n",
      "  hostname: qian-XPS-8920\n",
      "  info:\n",
      "    learner:\n",
      "      cur_lr: 0.0005000000237487257\n",
      "      entropy: 1646.4647216796875\n",
      "      entropy_coeff: 0.009999999776482582\n",
      "      grad_gnorm: 40.0\n",
      "      model: {}\n",
      "      policy_loss: -141.337646484375\n",
      "      var_gnorm: 15.045096397399902\n",
      "      vf_explained_var: 0.5755552053451538\n",
      "      vf_loss: 32.94483947753906\n",
      "    learner_queue:\n",
      "      size_count: 1317\n",
      "      size_mean: 0.0\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      size_std: 0.0\n",
      "    num_steps_replayed: 0\n",
      "    num_steps_sampled: 1317000\n",
      "    num_steps_trained: 1316000\n",
      "    num_weight_syncs: 5270\n",
      "    sample_throughput: 3260.734\n",
      "    timing_breakdown:\n",
      "      learner_dequeue_time_ms: 4876.743\n",
      "      learner_grad_time_ms: 136.5\n",
      "      learner_load_time_ms: 29.778\n",
      "      learner_load_wait_time_ms: 169.95\n",
      "      optimizer_step_time_ms: 83.125\n",
      "    train_throughput: 3164.831\n",
      "  iterations_since_restore: 39\n",
      "  node_ip: 10.236.176.76\n",
      "  num_healthy_workers: 7\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.46000000000001\n",
      "    ram_util_percent: 70.52666666666667\n",
      "  pid: 13004\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 7.458219887850318\n",
      "    mean_inference_ms: 2.194894195293182\n",
      "    mean_processing_ms: 0.4685424130418116\n",
      "  time_since_restore: 406.8423180580139\n",
      "  time_this_iter_s: 10.414341449737549\n",
      "  time_total_s: 406.8423180580139\n",
      "  timestamp: 1583958561\n",
      "  timesteps_since_restore: 1317000\n",
      "  timesteps_this_iter: 34000\n",
      "  timesteps_total: 1317000\n",
      "  training_iteration: 39\n",
      "  trial_id: 00c00974\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 11.0/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8/8 CPUs, 1/1 GPUs, 0.0/7.76 GiB heap, 0.0/2.69 GiB objects<br>Result logdir: /home/qian/ray_results/pong-impala-fast<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                        </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>IMPALA_PongNoFrameskip-v4_00c00974</td><td>RUNNING </td><td>10.236.176.76:13004</td><td style=\"text-align: right;\">  -19.87</td><td style=\"text-align: right;\">         406.842</td><td style=\"text-align: right;\">1317000</td><td style=\"text-align: right;\">    39</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for IMPALA_PongNoFrameskip-v4_00c00974:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-03-11_16-29-31\n",
      "  done: false\n",
      "  episode_len_mean: 4076.59\n",
      "  episode_reward_max: -17.0\n",
      "  episode_reward_mean: -19.66\n",
      "  episode_reward_min: -21.0\n",
      "  episodes_this_iter: 33\n",
      "  episodes_total: 1577\n",
      "  experiment_id: 92f0827d37354e42be7025ff72050188\n",
      "  experiment_tag: '0'\n",
      "  hostname: qian-XPS-8920\n",
      "  info:\n",
      "    learner:\n",
      "      cur_lr: 0.0005000000237487257\n",
      "      entropy: 1667.2125244140625\n",
      "      entropy_coeff: 0.009999999776482582\n",
      "      grad_gnorm: 40.0\n",
      "      model: {}\n",
      "      policy_loss: -69.42626953125\n",
      "      var_gnorm: 15.150594711303711\n",
      "      vf_explained_var: 0.7419306039810181\n",
      "      vf_loss: 25.75934410095215\n",
      "    learner_queue:\n",
      "      size_count: 1351\n",
      "      size_mean: 0.0\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      size_std: 0.0\n",
      "    num_steps_replayed: 0\n",
      "    num_steps_sampled: 1351000\n",
      "    num_steps_trained: 1351000\n",
      "    num_weight_syncs: 5405\n",
      "    sample_throughput: 3259.17\n",
      "    timing_breakdown:\n",
      "      learner_dequeue_time_ms: 4893.175\n",
      "      learner_grad_time_ms: 133.289\n",
      "      learner_load_time_ms: 21.56\n",
      "      learner_load_wait_time_ms: 157.737\n",
      "      optimizer_step_time_ms: 81.74\n",
      "    train_throughput: 3355.028\n",
      "  iterations_since_restore: 40\n",
      "  node_ip: 10.236.176.76\n",
      "  num_healthy_workers: 7\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.12666666666668\n",
      "    ram_util_percent: 70.96666666666668\n",
      "  pid: 13004\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 7.458661531549692\n",
      "    mean_inference_ms: 2.1964678632140346\n",
      "    mean_processing_ms: 0.46833182559898534\n",
      "  time_since_restore: 417.26223039627075\n",
      "  time_this_iter_s: 10.419912338256836\n",
      "  time_total_s: 417.26223039627075\n",
      "  timestamp: 1583958571\n",
      "  timesteps_since_restore: 1351000\n",
      "  timesteps_this_iter: 34000\n",
      "  timesteps_total: 1351000\n",
      "  training_iteration: 40\n",
      "  trial_id: 00c00974\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 11.1/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8/8 CPUs, 1/1 GPUs, 0.0/7.76 GiB heap, 0.0/2.69 GiB objects<br>Result logdir: /home/qian/ray_results/pong-impala-fast<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                        </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>IMPALA_PongNoFrameskip-v4_00c00974</td><td>RUNNING </td><td>10.236.176.76:13004</td><td style=\"text-align: right;\">  -19.66</td><td style=\"text-align: right;\">         417.262</td><td style=\"text-align: right;\">1351000</td><td style=\"text-align: right;\">    40</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for IMPALA_PongNoFrameskip-v4_00c00974:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-03-11_16-29-42\n",
      "  done: false\n",
      "  episode_len_mean: 4118.56\n",
      "  episode_reward_max: -17.0\n",
      "  episode_reward_mean: -19.61\n",
      "  episode_reward_min: -21.0\n",
      "  episodes_this_iter: 29\n",
      "  episodes_total: 1606\n",
      "  experiment_id: 92f0827d37354e42be7025ff72050188\n",
      "  experiment_tag: '0'\n",
      "  hostname: qian-XPS-8920\n",
      "  info:\n",
      "    learner:\n",
      "      cur_lr: 0.0005000000237487257\n",
      "      entropy: 1641.0380859375\n",
      "      entropy_coeff: 0.009999999776482582\n",
      "      grad_gnorm: 39.999996185302734\n",
      "      model: {}\n",
      "      policy_loss: 212.66697692871094\n",
      "      var_gnorm: 15.248076438903809\n",
      "      vf_explained_var: 0.18807601928710938\n",
      "      vf_loss: 73.76873779296875\n",
      "    learner_queue:\n",
      "      size_count: 1384\n",
      "      size_mean: 0.0\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      size_std: 0.0\n",
      "    num_steps_replayed: 0\n",
      "    num_steps_sampled: 1384000\n",
      "    num_steps_trained: 1384000\n",
      "    num_weight_syncs: 5539\n",
      "    sample_throughput: 3178.697\n",
      "    timing_breakdown:\n",
      "      learner_dequeue_time_ms: 4905.122\n",
      "      learner_grad_time_ms: 134.406\n",
      "      learner_load_time_ms: 21.167\n",
      "      learner_load_wait_time_ms: 174.469\n",
      "      optimizer_step_time_ms: 88.005\n",
      "    train_throughput: 3178.697\n",
      "  iterations_since_restore: 41\n",
      "  node_ip: 10.236.176.76\n",
      "  num_healthy_workers: 7\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.06666666666666\n",
      "    ram_util_percent: 71.40666666666667\n",
      "  pid: 13004\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 7.45769139535236\n",
      "    mean_inference_ms: 2.1970695533114646\n",
      "    mean_processing_ms: 0.4680615972808085\n",
      "  time_since_restore: 427.6311020851135\n",
      "  time_this_iter_s: 10.368871688842773\n",
      "  time_total_s: 427.6311020851135\n",
      "  timestamp: 1583958582\n",
      "  timesteps_since_restore: 1384000\n",
      "  timesteps_this_iter: 33000\n",
      "  timesteps_total: 1384000\n",
      "  training_iteration: 41\n",
      "  trial_id: 00c00974\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 11.1/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8/8 CPUs, 1/1 GPUs, 0.0/7.76 GiB heap, 0.0/2.69 GiB objects<br>Result logdir: /home/qian/ray_results/pong-impala-fast<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                        </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>IMPALA_PongNoFrameskip-v4_00c00974</td><td>RUNNING </td><td>10.236.176.76:13004</td><td style=\"text-align: right;\">  -19.61</td><td style=\"text-align: right;\">         427.631</td><td style=\"text-align: right;\">1384000</td><td style=\"text-align: right;\">    41</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for IMPALA_PongNoFrameskip-v4_00c00974:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-03-11_16-29-52\n",
      "  done: false\n",
      "  episode_len_mean: 4305.22\n",
      "  episode_reward_max: -15.0\n",
      "  episode_reward_mean: -19.31\n",
      "  episode_reward_min: -21.0\n",
      "  episodes_this_iter: 30\n",
      "  episodes_total: 1636\n",
      "  experiment_id: 92f0827d37354e42be7025ff72050188\n",
      "  experiment_tag: '0'\n",
      "  hostname: qian-XPS-8920\n",
      "  info:\n",
      "    learner:\n",
      "      cur_lr: 0.0005000000237487257\n",
      "      entropy: 1685.282470703125\n",
      "      entropy_coeff: 0.009999999776482582\n",
      "      grad_gnorm: 40.000003814697266\n",
      "      model: {}\n",
      "      policy_loss: -26.052173614501953\n",
      "      var_gnorm: 15.416752815246582\n",
      "      vf_explained_var: 0.6941786408424377\n",
      "      vf_loss: 23.013748168945312\n",
      "    learner_queue:\n",
      "      size_count: 1418\n",
      "      size_mean: 0.0\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      size_std: 0.0\n",
      "    num_steps_replayed: 0\n",
      "    num_steps_sampled: 1418000\n",
      "    num_steps_trained: 1418000\n",
      "    num_weight_syncs: 5674\n",
      "    sample_throughput: 3259.602\n",
      "    timing_breakdown:\n",
      "      learner_dequeue_time_ms: 4916.071\n",
      "      learner_grad_time_ms: 133.533\n",
      "      learner_load_time_ms: 21.651\n",
      "      learner_load_wait_time_ms: 159.986\n",
      "      optimizer_step_time_ms: 94.797\n",
      "    train_throughput: 3259.602\n",
      "  iterations_since_restore: 42\n",
      "  node_ip: 10.236.176.76\n",
      "  num_healthy_workers: 7\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.4\n",
      "    ram_util_percent: 71.83571428571427\n",
      "  pid: 13004\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 7.457625395186374\n",
      "    mean_inference_ms: 2.196395317961922\n",
      "    mean_processing_ms: 0.46754997338525073\n",
      "  time_since_restore: 438.04921436309814\n",
      "  time_this_iter_s: 10.41811227798462\n",
      "  time_total_s: 438.04921436309814\n",
      "  timestamp: 1583958592\n",
      "  timesteps_since_restore: 1418000\n",
      "  timesteps_this_iter: 34000\n",
      "  timesteps_total: 1418000\n",
      "  training_iteration: 42\n",
      "  trial_id: 00c00974\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 11.2/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8/8 CPUs, 1/1 GPUs, 0.0/7.76 GiB heap, 0.0/2.69 GiB objects<br>Result logdir: /home/qian/ray_results/pong-impala-fast<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                        </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>IMPALA_PongNoFrameskip-v4_00c00974</td><td>RUNNING </td><td>10.236.176.76:13004</td><td style=\"text-align: right;\">  -19.31</td><td style=\"text-align: right;\">         438.049</td><td style=\"text-align: right;\">1418000</td><td style=\"text-align: right;\">    42</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for IMPALA_PongNoFrameskip-v4_00c00974:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-03-11_16-30-03\n",
      "  done: false\n",
      "  episode_len_mean: 4539.44\n",
      "  episode_reward_max: -15.0\n",
      "  episode_reward_mean: -18.94\n",
      "  episode_reward_min: -21.0\n",
      "  episodes_this_iter: 29\n",
      "  episodes_total: 1665\n",
      "  experiment_id: 92f0827d37354e42be7025ff72050188\n",
      "  experiment_tag: '0'\n",
      "  hostname: qian-XPS-8920\n",
      "  info:\n",
      "    learner:\n",
      "      cur_lr: 0.0005000000237487257\n",
      "      entropy: 1685.771728515625\n",
      "      entropy_coeff: 0.009999999776482582\n",
      "      grad_gnorm: 39.999996185302734\n",
      "      model: {}\n",
      "      policy_loss: -113.37711334228516\n",
      "      var_gnorm: 15.570281028747559\n",
      "      vf_explained_var: 0.47787392139434814\n",
      "      vf_loss: 32.95582580566406\n",
      "    learner_queue:\n",
      "      size_count: 1452\n",
      "      size_mean: 0.0\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      size_std: 0.0\n",
      "    num_steps_replayed: 0\n",
      "    num_steps_sampled: 1452000\n",
      "    num_steps_trained: 1451000\n",
      "    num_weight_syncs: 5809\n",
      "    sample_throughput: 3265.806\n",
      "    timing_breakdown:\n",
      "      learner_dequeue_time_ms: 4915.658\n",
      "      learner_grad_time_ms: 135.598\n",
      "      learner_load_time_ms: 28.445\n",
      "      learner_load_wait_time_ms: 166.807\n",
      "      optimizer_step_time_ms: 81.335\n",
      "    train_throughput: 3169.753\n",
      "  iterations_since_restore: 43\n",
      "  node_ip: 10.236.176.76\n",
      "  num_healthy_workers: 7\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.13333333333334\n",
      "    ram_util_percent: 72.22666666666666\n",
      "  pid: 13004\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 7.456309648507766\n",
      "    mean_inference_ms: 2.194979941533308\n",
      "    mean_processing_ms: 0.4669394234281451\n",
      "  time_since_restore: 448.4472289085388\n",
      "  time_this_iter_s: 10.398014545440674\n",
      "  time_total_s: 448.4472289085388\n",
      "  timestamp: 1583958603\n",
      "  timesteps_since_restore: 1452000\n",
      "  timesteps_this_iter: 34000\n",
      "  timesteps_total: 1452000\n",
      "  training_iteration: 43\n",
      "  trial_id: 00c00974\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 11.3/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8/8 CPUs, 1/1 GPUs, 0.0/7.76 GiB heap, 0.0/2.69 GiB objects<br>Result logdir: /home/qian/ray_results/pong-impala-fast<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                        </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>IMPALA_PongNoFrameskip-v4_00c00974</td><td>RUNNING </td><td>10.236.176.76:13004</td><td style=\"text-align: right;\">  -18.94</td><td style=\"text-align: right;\">         448.447</td><td style=\"text-align: right;\">1452000</td><td style=\"text-align: right;\">    43</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for IMPALA_PongNoFrameskip-v4_00c00974:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-03-11_16-30-13\n",
      "  done: false\n",
      "  episode_len_mean: 4704.63\n",
      "  episode_reward_max: -15.0\n",
      "  episode_reward_mean: -18.84\n",
      "  episode_reward_min: -21.0\n",
      "  episodes_this_iter: 26\n",
      "  episodes_total: 1691\n",
      "  experiment_id: 92f0827d37354e42be7025ff72050188\n",
      "  experiment_tag: '0'\n",
      "  hostname: qian-XPS-8920\n",
      "  info:\n",
      "    learner:\n",
      "      cur_lr: 0.0005000000237487257\n",
      "      entropy: 1649.772705078125\n",
      "      entropy_coeff: 0.009999999776482582\n",
      "      grad_gnorm: 39.999996185302734\n",
      "      model: {}\n",
      "      policy_loss: 48.76262664794922\n",
      "      var_gnorm: 15.743563652038574\n",
      "      vf_explained_var: 0.5129671692848206\n",
      "      vf_loss: 31.2193546295166\n",
      "    learner_queue:\n",
      "      size_count: 1486\n",
      "      size_mean: 0.0\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      size_std: 0.0\n",
      "    num_steps_replayed: 0\n",
      "    num_steps_sampled: 1486000\n",
      "    num_steps_trained: 1485000\n",
      "    num_weight_syncs: 5946\n",
      "    sample_throughput: 3254.329\n",
      "    timing_breakdown:\n",
      "      learner_dequeue_time_ms: 4914.921\n",
      "      learner_grad_time_ms: 134.626\n",
      "      learner_load_time_ms: 29.616\n",
      "      learner_load_wait_time_ms: 172.502\n",
      "      optimizer_step_time_ms: 68.584\n",
      "    train_throughput: 3254.329\n",
      "  iterations_since_restore: 44\n",
      "  node_ip: 10.236.176.76\n",
      "  num_healthy_workers: 7\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.98666666666666\n",
      "    ram_util_percent: 72.68\n",
      "  pid: 13004\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 7.456373170023165\n",
      "    mean_inference_ms: 2.193930515190828\n",
      "    mean_processing_ms: 0.46609333447335727\n",
      "  time_since_restore: 458.88200211524963\n",
      "  time_this_iter_s: 10.434773206710815\n",
      "  time_total_s: 458.88200211524963\n",
      "  timestamp: 1583958613\n",
      "  timesteps_since_restore: 1486000\n",
      "  timesteps_this_iter: 34000\n",
      "  timesteps_total: 1486000\n",
      "  training_iteration: 44\n",
      "  trial_id: 00c00974\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 11.3/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8/8 CPUs, 1/1 GPUs, 0.0/7.76 GiB heap, 0.0/2.69 GiB objects<br>Result logdir: /home/qian/ray_results/pong-impala-fast<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                        </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>IMPALA_PongNoFrameskip-v4_00c00974</td><td>RUNNING </td><td>10.236.176.76:13004</td><td style=\"text-align: right;\">  -18.84</td><td style=\"text-align: right;\">         458.882</td><td style=\"text-align: right;\">1486000</td><td style=\"text-align: right;\">    44</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for IMPALA_PongNoFrameskip-v4_00c00974:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-03-11_16-30-23\n",
      "  done: false\n",
      "  episode_len_mean: 4890.29\n",
      "  episode_reward_max: -15.0\n",
      "  episode_reward_mean: -18.65\n",
      "  episode_reward_min: -21.0\n",
      "  episodes_this_iter: 25\n",
      "  episodes_total: 1716\n",
      "  experiment_id: 92f0827d37354e42be7025ff72050188\n",
      "  experiment_tag: '0'\n",
      "  hostname: qian-XPS-8920\n",
      "  info:\n",
      "    learner:\n",
      "      cur_lr: 0.0005000000237487257\n",
      "      entropy: 1589.5989990234375\n",
      "      entropy_coeff: 0.009999999776482582\n",
      "      grad_gnorm: 40.0\n",
      "      model: {}\n",
      "      policy_loss: 40.02159881591797\n",
      "      var_gnorm: 15.90740966796875\n",
      "      vf_explained_var: 0.4640006422996521\n",
      "      vf_loss: 26.135812759399414\n",
      "    learner_queue:\n",
      "      size_count: 1520\n",
      "      size_mean: 0.0\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      size_std: 0.0\n",
      "    num_steps_replayed: 0\n",
      "    num_steps_sampled: 1520000\n",
      "    num_steps_trained: 1519000\n",
      "    num_weight_syncs: 6081\n",
      "    sample_throughput: 3266.011\n",
      "    timing_breakdown:\n",
      "      learner_dequeue_time_ms: 4905.991\n",
      "      learner_grad_time_ms: 134.577\n",
      "      learner_load_time_ms: 31.641\n",
      "      learner_load_wait_time_ms: 166.753\n",
      "      optimizer_step_time_ms: 85.476\n",
      "    train_throughput: 3266.011\n",
      "  iterations_since_restore: 45\n",
      "  node_ip: 10.236.176.76\n",
      "  num_healthy_workers: 7\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.6\n",
      "    ram_util_percent: 73.08666666666667\n",
      "  pid: 13004\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 7.456935747790766\n",
      "    mean_inference_ms: 2.195009990690088\n",
      "    mean_processing_ms: 0.465601004574504\n",
      "  time_since_restore: 469.27988147735596\n",
      "  time_this_iter_s: 10.397879362106323\n",
      "  time_total_s: 469.27988147735596\n",
      "  timestamp: 1583958623\n",
      "  timesteps_since_restore: 1520000\n",
      "  timesteps_this_iter: 34000\n",
      "  timesteps_total: 1520000\n",
      "  training_iteration: 45\n",
      "  trial_id: 00c00974\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 11.4/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8/8 CPUs, 1/1 GPUs, 0.0/7.76 GiB heap, 0.0/2.69 GiB objects<br>Result logdir: /home/qian/ray_results/pong-impala-fast<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                        </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>IMPALA_PongNoFrameskip-v4_00c00974</td><td>RUNNING </td><td>10.236.176.76:13004</td><td style=\"text-align: right;\">  -18.65</td><td style=\"text-align: right;\">          469.28</td><td style=\"text-align: right;\">1520000</td><td style=\"text-align: right;\">    45</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for IMPALA_PongNoFrameskip-v4_00c00974:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-03-11_16-30-34\n",
      "  done: false\n",
      "  episode_len_mean: 5045.15\n",
      "  episode_reward_max: -13.0\n",
      "  episode_reward_mean: -18.55\n",
      "  episode_reward_min: -21.0\n",
      "  episodes_this_iter: 22\n",
      "  episodes_total: 1738\n",
      "  experiment_id: 92f0827d37354e42be7025ff72050188\n",
      "  experiment_tag: '0'\n",
      "  hostname: qian-XPS-8920\n",
      "  info:\n",
      "    learner:\n",
      "      cur_lr: 0.0005000000237487257\n",
      "      entropy: 1597.4739990234375\n",
      "      entropy_coeff: 0.009999999776482582\n",
      "      grad_gnorm: 40.000003814697266\n",
      "      model: {}\n",
      "      policy_loss: -134.83685302734375\n",
      "      var_gnorm: 16.220169067382812\n",
      "      vf_explained_var: 0.4865586757659912\n",
      "      vf_loss: 27.492475509643555\n",
      "    learner_queue:\n",
      "      size_count: 1554\n",
      "      size_mean: 0.0\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      size_std: 0.0\n",
      "    num_steps_replayed: 0\n",
      "    num_steps_sampled: 1554000\n",
      "    num_steps_trained: 1554000\n",
      "    num_weight_syncs: 6218\n",
      "    sample_throughput: 3234.35\n",
      "    timing_breakdown:\n",
      "      learner_dequeue_time_ms: 4874.972\n",
      "      learner_grad_time_ms: 133.763\n",
      "      learner_load_time_ms: 31.378\n",
      "      learner_load_wait_time_ms: 169.673\n",
      "      optimizer_step_time_ms: 83.592\n",
      "    train_throughput: 3329.478\n",
      "  iterations_since_restore: 46\n",
      "  node_ip: 10.236.176.76\n",
      "  num_healthy_workers: 7\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.82000000000001\n",
      "    ram_util_percent: 73.52666666666667\n",
      "  pid: 13004\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 7.458132256731087\n",
      "    mean_inference_ms: 2.1966962033439636\n",
      "    mean_processing_ms: 0.46514618218720605\n",
      "  time_since_restore: 479.7795829772949\n",
      "  time_this_iter_s: 10.499701499938965\n",
      "  time_total_s: 479.7795829772949\n",
      "  timestamp: 1583958634\n",
      "  timesteps_since_restore: 1554000\n",
      "  timesteps_this_iter: 34000\n",
      "  timesteps_total: 1554000\n",
      "  training_iteration: 46\n",
      "  trial_id: 00c00974\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 11.5/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8/8 CPUs, 1/1 GPUs, 0.0/7.76 GiB heap, 0.0/2.69 GiB objects<br>Result logdir: /home/qian/ray_results/pong-impala-fast<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                        </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>IMPALA_PongNoFrameskip-v4_00c00974</td><td>RUNNING </td><td>10.236.176.76:13004</td><td style=\"text-align: right;\">  -18.55</td><td style=\"text-align: right;\">          479.78</td><td style=\"text-align: right;\">1554000</td><td style=\"text-align: right;\">    46</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for IMPALA_PongNoFrameskip-v4_00c00974:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-03-11_16-30-44\n",
      "  done: false\n",
      "  episode_len_mean: 5285.24\n",
      "  episode_reward_max: -13.0\n",
      "  episode_reward_mean: -18.36\n",
      "  episode_reward_min: -21.0\n",
      "  episodes_this_iter: 26\n",
      "  episodes_total: 1764\n",
      "  experiment_id: 92f0827d37354e42be7025ff72050188\n",
      "  experiment_tag: '0'\n",
      "  hostname: qian-XPS-8920\n",
      "  info:\n",
      "    learner:\n",
      "      cur_lr: 0.0005000000237487257\n",
      "      entropy: 1547.85888671875\n",
      "      entropy_coeff: 0.009999999776482582\n",
      "      grad_gnorm: 40.000003814697266\n",
      "      model: {}\n",
      "      policy_loss: -23.71419906616211\n",
      "      var_gnorm: 16.402780532836914\n",
      "      vf_explained_var: 0.6957840323448181\n",
      "      vf_loss: 18.326126098632812\n",
      "    learner_queue:\n",
      "      size_count: 1588\n",
      "      size_mean: 0.0\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      size_std: 0.0\n",
      "    num_steps_replayed: 0\n",
      "    num_steps_sampled: 1588000\n",
      "    num_steps_trained: 1588000\n",
      "    num_weight_syncs: 6354\n",
      "    sample_throughput: 3249.765\n",
      "    timing_breakdown:\n",
      "      learner_dequeue_time_ms: 4883.227\n",
      "      learner_grad_time_ms: 134.275\n",
      "      learner_load_time_ms: 25.292\n",
      "      learner_load_wait_time_ms: 160.102\n",
      "      optimizer_step_time_ms: 76.963\n",
      "    train_throughput: 3249.765\n",
      "  iterations_since_restore: 47\n",
      "  node_ip: 10.236.176.76\n",
      "  num_healthy_workers: 7\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.45333333333333\n",
      "    ram_util_percent: 73.94\n",
      "  pid: 13004\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 7.458648155129338\n",
      "    mean_inference_ms: 2.196560035396364\n",
      "    mean_processing_ms: 0.46425958042514004\n",
      "  time_since_restore: 490.229120016098\n",
      "  time_this_iter_s: 10.4495370388031\n",
      "  time_total_s: 490.229120016098\n",
      "  timestamp: 1583958644\n",
      "  timesteps_since_restore: 1588000\n",
      "  timesteps_this_iter: 34000\n",
      "  timesteps_total: 1588000\n",
      "  training_iteration: 47\n",
      "  trial_id: 00c00974\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 11.5/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8/8 CPUs, 1/1 GPUs, 0.0/7.76 GiB heap, 0.0/2.69 GiB objects<br>Result logdir: /home/qian/ray_results/pong-impala-fast<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                        </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>IMPALA_PongNoFrameskip-v4_00c00974</td><td>RUNNING </td><td>10.236.176.76:13004</td><td style=\"text-align: right;\">  -18.36</td><td style=\"text-align: right;\">         490.229</td><td style=\"text-align: right;\">1588000</td><td style=\"text-align: right;\">    47</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for IMPALA_PongNoFrameskip-v4_00c00974:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-03-11_16-30-55\n",
      "  done: false\n",
      "  episode_len_mean: 5363.4\n",
      "  episode_reward_max: -13.0\n",
      "  episode_reward_mean: -18.28\n",
      "  episode_reward_min: -21.0\n",
      "  episodes_this_iter: 22\n",
      "  episodes_total: 1786\n",
      "  experiment_id: 92f0827d37354e42be7025ff72050188\n",
      "  experiment_tag: '0'\n",
      "  hostname: qian-XPS-8920\n",
      "  info:\n",
      "    learner:\n",
      "      cur_lr: 0.0005000000237487257\n",
      "      entropy: 1503.8065185546875\n",
      "      entropy_coeff: 0.009999999776482582\n",
      "      grad_gnorm: 39.999996185302734\n",
      "      model: {}\n",
      "      policy_loss: -55.16566467285156\n",
      "      var_gnorm: 16.603851318359375\n",
      "      vf_explained_var: 0.5636726021766663\n",
      "      vf_loss: 32.24579620361328\n",
      "    learner_queue:\n",
      "      size_count: 1622\n",
      "      size_mean: 0.0\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      size_std: 0.0\n",
      "    num_steps_replayed: 0\n",
      "    num_steps_sampled: 1622000\n",
      "    num_steps_trained: 1621000\n",
      "    num_weight_syncs: 6490\n",
      "    sample_throughput: 3258.324\n",
      "    timing_breakdown:\n",
      "      learner_dequeue_time_ms: 4889.597\n",
      "      learner_grad_time_ms: 135.004\n",
      "      learner_load_time_ms: 21.238\n",
      "      learner_load_wait_time_ms: 177.067\n",
      "      optimizer_step_time_ms: 75.203\n",
      "    train_throughput: 3162.491\n",
      "  iterations_since_restore: 48\n",
      "  node_ip: 10.236.176.76\n",
      "  num_healthy_workers: 7\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.29333333333334\n",
      "    ram_util_percent: 74.37333333333332\n",
      "  pid: 13004\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 7.45963799940765\n",
      "    mean_inference_ms: 2.1979293641990214\n",
      "    mean_processing_ms: 0.4637206193682941\n",
      "  time_since_restore: 500.65017652511597\n",
      "  time_this_iter_s: 10.421056509017944\n",
      "  time_total_s: 500.65017652511597\n",
      "  timestamp: 1583958655\n",
      "  timesteps_since_restore: 1622000\n",
      "  timesteps_this_iter: 34000\n",
      "  timesteps_total: 1622000\n",
      "  training_iteration: 48\n",
      "  trial_id: 00c00974\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 11.6/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8/8 CPUs, 1/1 GPUs, 0.0/7.76 GiB heap, 0.0/2.69 GiB objects<br>Result logdir: /home/qian/ray_results/pong-impala-fast<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                        </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>IMPALA_PongNoFrameskip-v4_00c00974</td><td>RUNNING </td><td>10.236.176.76:13004</td><td style=\"text-align: right;\">  -18.28</td><td style=\"text-align: right;\">          500.65</td><td style=\"text-align: right;\">1622000</td><td style=\"text-align: right;\">    48</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for IMPALA_PongNoFrameskip-v4_00c00974:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-03-11_16-31-05\n",
      "  done: false\n",
      "  episode_len_mean: 5611.69\n",
      "  episode_reward_max: -10.0\n",
      "  episode_reward_mean: -17.78\n",
      "  episode_reward_min: -21.0\n",
      "  episodes_this_iter: 28\n",
      "  episodes_total: 1814\n",
      "  experiment_id: 92f0827d37354e42be7025ff72050188\n",
      "  experiment_tag: '0'\n",
      "  hostname: qian-XPS-8920\n",
      "  info:\n",
      "    learner:\n",
      "      cur_lr: 0.0005000000237487257\n",
      "      entropy: 1595.75634765625\n",
      "      entropy_coeff: 0.009999999776482582\n",
      "      grad_gnorm: 40.0\n",
      "      model: {}\n",
      "      policy_loss: 30.291746139526367\n",
      "      var_gnorm: 16.759502410888672\n",
      "      vf_explained_var: 0.3582441210746765\n",
      "      vf_loss: 41.51889419555664\n",
      "    learner_queue:\n",
      "      size_count: 1656\n",
      "      size_mean: 0.0\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      size_std: 0.0\n",
      "    num_steps_replayed: 0\n",
      "    num_steps_sampled: 1656000\n",
      "    num_steps_trained: 1656000\n",
      "    num_weight_syncs: 6627\n",
      "    sample_throughput: 3243.502\n",
      "    timing_breakdown:\n",
      "      learner_dequeue_time_ms: 4878.231\n",
      "      learner_grad_time_ms: 133.658\n",
      "      learner_load_time_ms: 21.101\n",
      "      learner_load_wait_time_ms: 168.194\n",
      "      optimizer_step_time_ms: 75.593\n",
      "    train_throughput: 3338.9\n",
      "  iterations_since_restore: 49\n",
      "  node_ip: 10.236.176.76\n",
      "  num_healthy_workers: 7\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.66000000000001\n",
      "    ram_util_percent: 74.8\n",
      "  pid: 13004\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 7.460714721791434\n",
      "    mean_inference_ms: 2.1982686999634566\n",
      "    mean_processing_ms: 0.4628914528968913\n",
      "  time_since_restore: 511.12002420425415\n",
      "  time_this_iter_s: 10.469847679138184\n",
      "  time_total_s: 511.12002420425415\n",
      "  timestamp: 1583958665\n",
      "  timesteps_since_restore: 1656000\n",
      "  timesteps_this_iter: 34000\n",
      "  timesteps_total: 1656000\n",
      "  training_iteration: 49\n",
      "  trial_id: 00c00974\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 11.7/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8/8 CPUs, 1/1 GPUs, 0.0/7.76 GiB heap, 0.0/2.69 GiB objects<br>Result logdir: /home/qian/ray_results/pong-impala-fast<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                        </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>IMPALA_PongNoFrameskip-v4_00c00974</td><td>RUNNING </td><td>10.236.176.76:13004</td><td style=\"text-align: right;\">  -17.78</td><td style=\"text-align: right;\">          511.12</td><td style=\"text-align: right;\">1656000</td><td style=\"text-align: right;\">    49</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for IMPALA_PongNoFrameskip-v4_00c00974:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-03-11_16-31-16\n",
      "  done: false\n",
      "  episode_len_mean: 5716.13\n",
      "  episode_reward_max: -10.0\n",
      "  episode_reward_mean: -17.49\n",
      "  episode_reward_min: -21.0\n",
      "  episodes_this_iter: 17\n",
      "  episodes_total: 1831\n",
      "  experiment_id: 92f0827d37354e42be7025ff72050188\n",
      "  experiment_tag: '0'\n",
      "  hostname: qian-XPS-8920\n",
      "  info:\n",
      "    learner:\n",
      "      cur_lr: 0.0005000000237487257\n",
      "      entropy: 1630.6715087890625\n",
      "      entropy_coeff: 0.009999999776482582\n",
      "      grad_gnorm: 39.999996185302734\n",
      "      model: {}\n",
      "      policy_loss: -42.400787353515625\n",
      "      var_gnorm: 17.044031143188477\n",
      "      vf_explained_var: 0.49410223960876465\n",
      "      vf_loss: 28.38786506652832\n",
      "    learner_queue:\n",
      "      size_count: 1690\n",
      "      size_mean: 0.0\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      size_std: 0.0\n",
      "    num_steps_replayed: 0\n",
      "    num_steps_sampled: 1690000\n",
      "    num_steps_trained: 1690000\n",
      "    num_weight_syncs: 6763\n",
      "    sample_throughput: 3256.146\n",
      "    timing_breakdown:\n",
      "      learner_dequeue_time_ms: 4870.662\n",
      "      learner_grad_time_ms: 133.99\n",
      "      learner_load_time_ms: 20.559\n",
      "      learner_load_wait_time_ms: 157.906\n",
      "      optimizer_step_time_ms: 85.111\n",
      "    train_throughput: 3256.146\n",
      "  iterations_since_restore: 50\n",
      "  node_ip: 10.236.176.76\n",
      "  num_healthy_workers: 7\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.97333333333334\n",
      "    ram_util_percent: 75.22666666666666\n",
      "  pid: 13004\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 7.458829327899394\n",
      "    mean_inference_ms: 2.1956718763806213\n",
      "    mean_processing_ms: 0.46197881337939267\n",
      "  time_since_restore: 521.5489218235016\n",
      "  time_this_iter_s: 10.428897619247437\n",
      "  time_total_s: 521.5489218235016\n",
      "  timestamp: 1583958676\n",
      "  timesteps_since_restore: 1690000\n",
      "  timesteps_this_iter: 34000\n",
      "  timesteps_total: 1690000\n",
      "  training_iteration: 50\n",
      "  trial_id: 00c00974\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 11.7/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8/8 CPUs, 1/1 GPUs, 0.0/7.76 GiB heap, 0.0/2.69 GiB objects<br>Result logdir: /home/qian/ray_results/pong-impala-fast<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                        </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>IMPALA_PongNoFrameskip-v4_00c00974</td><td>RUNNING </td><td>10.236.176.76:13004</td><td style=\"text-align: right;\">  -17.49</td><td style=\"text-align: right;\">         521.549</td><td style=\"text-align: right;\">1690000</td><td style=\"text-align: right;\">    50</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for IMPALA_PongNoFrameskip-v4_00c00974:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-03-11_16-31-26\n",
      "  done: false\n",
      "  episode_len_mean: 5871.57\n",
      "  episode_reward_max: -9.0\n",
      "  episode_reward_mean: -17.15\n",
      "  episode_reward_min: -21.0\n",
      "  episodes_this_iter: 22\n",
      "  episodes_total: 1853\n",
      "  experiment_id: 92f0827d37354e42be7025ff72050188\n",
      "  experiment_tag: '0'\n",
      "  hostname: qian-XPS-8920\n",
      "  info:\n",
      "    learner:\n",
      "      cur_lr: 0.0005000000237487257\n",
      "      entropy: 1620.28271484375\n",
      "      entropy_coeff: 0.009999999776482582\n",
      "      grad_gnorm: 40.000003814697266\n",
      "      model: {}\n",
      "      policy_loss: 59.823204040527344\n",
      "      var_gnorm: 17.287565231323242\n",
      "      vf_explained_var: 0.3591892123222351\n",
      "      vf_loss: 46.79195785522461\n",
      "    learner_queue:\n",
      "      size_count: 1724\n",
      "      size_mean: 0.0\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      size_std: 0.0\n",
      "    num_steps_replayed: 0\n",
      "    num_steps_sampled: 1724000\n",
      "    num_steps_trained: 1724000\n",
      "    num_weight_syncs: 6898\n",
      "    sample_throughput: 3269.362\n",
      "    timing_breakdown:\n",
      "      learner_dequeue_time_ms: 4900.076\n",
      "      learner_grad_time_ms: 133.472\n",
      "      learner_load_time_ms: 20.158\n",
      "      learner_load_wait_time_ms: 163.065\n",
      "      optimizer_step_time_ms: 87.112\n",
      "    train_throughput: 3269.362\n",
      "  iterations_since_restore: 51\n",
      "  node_ip: 10.236.176.76\n",
      "  num_healthy_workers: 7\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.35714285714286\n",
      "    ram_util_percent: 75.65714285714286\n",
      "  pid: 13004\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 7.460325160531301\n",
      "    mean_inference_ms: 2.196620576796776\n",
      "    mean_processing_ms: 0.4614242412650404\n",
      "  time_since_restore: 531.9364459514618\n",
      "  time_this_iter_s: 10.387524127960205\n",
      "  time_total_s: 531.9364459514618\n",
      "  timestamp: 1583958686\n",
      "  timesteps_since_restore: 1724000\n",
      "  timesteps_this_iter: 34000\n",
      "  timesteps_total: 1724000\n",
      "  training_iteration: 51\n",
      "  trial_id: 00c00974\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 11.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8/8 CPUs, 1/1 GPUs, 0.0/7.76 GiB heap, 0.0/2.69 GiB objects<br>Result logdir: /home/qian/ray_results/pong-impala-fast<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                        </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>IMPALA_PongNoFrameskip-v4_00c00974</td><td>RUNNING </td><td>10.236.176.76:13004</td><td style=\"text-align: right;\">  -17.15</td><td style=\"text-align: right;\">         531.936</td><td style=\"text-align: right;\">1724000</td><td style=\"text-align: right;\">    51</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for IMPALA_PongNoFrameskip-v4_00c00974:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-03-11_16-31-37\n",
      "  done: false\n",
      "  episode_len_mean: 6098.03\n",
      "  episode_reward_max: -9.0\n",
      "  episode_reward_mean: -16.7\n",
      "  episode_reward_min: -21.0\n",
      "  episodes_this_iter: 23\n",
      "  episodes_total: 1876\n",
      "  experiment_id: 92f0827d37354e42be7025ff72050188\n",
      "  experiment_tag: '0'\n",
      "  hostname: qian-XPS-8920\n",
      "  info:\n",
      "    learner:\n",
      "      cur_lr: 0.0005000000237487257\n",
      "      entropy: 1609.5443115234375\n",
      "      entropy_coeff: 0.009999999776482582\n",
      "      grad_gnorm: 39.999996185302734\n",
      "      model: {}\n",
      "      policy_loss: 34.22452926635742\n",
      "      var_gnorm: 17.471086502075195\n",
      "      vf_explained_var: 0.4502236247062683\n",
      "      vf_loss: 41.833499908447266\n",
      "    learner_queue:\n",
      "      size_count: 1758\n",
      "      size_mean: 0.0\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      size_std: 0.0\n",
      "    num_steps_replayed: 0\n",
      "    num_steps_sampled: 1758000\n",
      "    num_steps_trained: 1758000\n",
      "    num_weight_syncs: 7034\n",
      "    sample_throughput: 3267.856\n",
      "    timing_breakdown:\n",
      "      learner_dequeue_time_ms: 4889.825\n",
      "      learner_grad_time_ms: 135.543\n",
      "      learner_load_time_ms: 18.661\n",
      "      learner_load_wait_time_ms: 165.767\n",
      "      optimizer_step_time_ms: 84.75\n",
      "    train_throughput: 3267.856\n",
      "  iterations_since_restore: 52\n",
      "  node_ip: 10.236.176.76\n",
      "  num_healthy_workers: 7\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.30666666666666\n",
      "    ram_util_percent: 76.07333333333334\n",
      "  pid: 13004\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 7.460851396430632\n",
      "    mean_inference_ms: 2.1965978996209357\n",
      "    mean_processing_ms: 0.4606398821934832\n",
      "  time_since_restore: 542.3276188373566\n",
      "  time_this_iter_s: 10.391172885894775\n",
      "  time_total_s: 542.3276188373566\n",
      "  timestamp: 1583958697\n",
      "  timesteps_since_restore: 1758000\n",
      "  timesteps_this_iter: 34000\n",
      "  timesteps_total: 1758000\n",
      "  training_iteration: 52\n",
      "  trial_id: 00c00974\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 11.9/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8/8 CPUs, 1/1 GPUs, 0.0/7.76 GiB heap, 0.0/2.69 GiB objects<br>Result logdir: /home/qian/ray_results/pong-impala-fast<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                        </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>IMPALA_PongNoFrameskip-v4_00c00974</td><td>RUNNING </td><td>10.236.176.76:13004</td><td style=\"text-align: right;\">   -16.7</td><td style=\"text-align: right;\">         542.328</td><td style=\"text-align: right;\">1758000</td><td style=\"text-align: right;\">    52</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for IMPALA_PongNoFrameskip-v4_00c00974:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-03-11_16-31-47\n",
      "  done: false\n",
      "  episode_len_mean: 6262.87\n",
      "  episode_reward_max: -9.0\n",
      "  episode_reward_mean: -16.55\n",
      "  episode_reward_min: -21.0\n",
      "  episodes_this_iter: 22\n",
      "  episodes_total: 1898\n",
      "  experiment_id: 92f0827d37354e42be7025ff72050188\n",
      "  experiment_tag: '0'\n",
      "  hostname: qian-XPS-8920\n",
      "  info:\n",
      "    learner:\n",
      "      cur_lr: 0.0005000000237487257\n",
      "      entropy: 1644.144775390625\n",
      "      entropy_coeff: 0.009999999776482582\n",
      "      grad_gnorm: 40.0\n",
      "      model: {}\n",
      "      policy_loss: -34.67913055419922\n",
      "      var_gnorm: 17.6832332611084\n",
      "      vf_explained_var: 0.5986090898513794\n",
      "      vf_loss: 19.90150260925293\n",
      "    learner_queue:\n",
      "      size_count: 1792\n",
      "      size_mean: 0.0\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      size_std: 0.0\n",
      "    num_steps_replayed: 0\n",
      "    num_steps_sampled: 1792000\n",
      "    num_steps_trained: 1792000\n",
      "    num_weight_syncs: 7170\n",
      "    sample_throughput: 3252.513\n",
      "    timing_breakdown:\n",
      "      learner_dequeue_time_ms: 4889.367\n",
      "      learner_grad_time_ms: 136.06\n",
      "      learner_load_time_ms: 17.789\n",
      "      learner_load_wait_time_ms: 167.618\n",
      "      optimizer_step_time_ms: 85.331\n",
      "    train_throughput: 3252.513\n",
      "  iterations_since_restore: 53\n",
      "  node_ip: 10.236.176.76\n",
      "  num_healthy_workers: 7\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.52666666666667\n",
      "    ram_util_percent: 76.48\n",
      "  pid: 13004\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 7.460755669568316\n",
      "    mean_inference_ms: 2.1951586656076785\n",
      "    mean_processing_ms: 0.4596721432464794\n",
      "  time_since_restore: 552.7668924331665\n",
      "  time_this_iter_s: 10.439273595809937\n",
      "  time_total_s: 552.7668924331665\n",
      "  timestamp: 1583958707\n",
      "  timesteps_since_restore: 1792000\n",
      "  timesteps_this_iter: 34000\n",
      "  timesteps_total: 1792000\n",
      "  training_iteration: 53\n",
      "  trial_id: 00c00974\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 11.9/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8/8 CPUs, 1/1 GPUs, 0.0/7.76 GiB heap, 0.0/2.69 GiB objects<br>Result logdir: /home/qian/ray_results/pong-impala-fast<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                        </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>IMPALA_PongNoFrameskip-v4_00c00974</td><td>RUNNING </td><td>10.236.176.76:13004</td><td style=\"text-align: right;\">  -16.55</td><td style=\"text-align: right;\">         552.767</td><td style=\"text-align: right;\">1792000</td><td style=\"text-align: right;\">    53</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for IMPALA_PongNoFrameskip-v4_00c00974:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-03-11_16-31-57\n",
      "  done: false\n",
      "  episode_len_mean: 6327.61\n",
      "  episode_reward_max: -9.0\n",
      "  episode_reward_mean: -16.38\n",
      "  episode_reward_min: -21.0\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 1918\n",
      "  experiment_id: 92f0827d37354e42be7025ff72050188\n",
      "  experiment_tag: '0'\n",
      "  hostname: qian-XPS-8920\n",
      "  info:\n",
      "    learner:\n",
      "      cur_lr: 0.0005000000237487257\n",
      "      entropy: 1555.02978515625\n",
      "      entropy_coeff: 0.009999999776482582\n",
      "      grad_gnorm: 40.000003814697266\n",
      "      model: {}\n",
      "      policy_loss: 67.9574966430664\n",
      "      var_gnorm: 17.82501220703125\n",
      "      vf_explained_var: 0.5660393834114075\n",
      "      vf_loss: 32.30367660522461\n",
      "    learner_queue:\n",
      "      size_count: 1826\n",
      "      size_mean: 0.0\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      size_std: 0.0\n",
      "    num_steps_replayed: 0\n",
      "    num_steps_sampled: 1826000\n",
      "    num_steps_trained: 1826000\n",
      "    num_weight_syncs: 7306\n",
      "    sample_throughput: 3257.53\n",
      "    timing_breakdown:\n",
      "      learner_dequeue_time_ms: 4889.426\n",
      "      learner_grad_time_ms: 135.303\n",
      "      learner_load_time_ms: 19.235\n",
      "      learner_load_wait_time_ms: 154.428\n",
      "      optimizer_step_time_ms: 86.368\n",
      "    train_throughput: 3257.53\n",
      "  iterations_since_restore: 54\n",
      "  node_ip: 10.236.176.76\n",
      "  num_healthy_workers: 7\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.64666666666666\n",
      "    ram_util_percent: 76.90666666666667\n",
      "  pid: 13004\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 7.461889709531712\n",
      "    mean_inference_ms: 2.1965969757117723\n",
      "    mean_processing_ms: 0.45920075620187545\n",
      "  time_since_restore: 563.1916325092316\n",
      "  time_this_iter_s: 10.424740076065063\n",
      "  time_total_s: 563.1916325092316\n",
      "  timestamp: 1583958717\n",
      "  timesteps_since_restore: 1826000\n",
      "  timesteps_this_iter: 34000\n",
      "  timesteps_total: 1826000\n",
      "  training_iteration: 54\n",
      "  trial_id: 00c00974\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 12.0/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8/8 CPUs, 1/1 GPUs, 0.0/7.76 GiB heap, 0.0/2.69 GiB objects<br>Result logdir: /home/qian/ray_results/pong-impala-fast<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                        </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>IMPALA_PongNoFrameskip-v4_00c00974</td><td>RUNNING </td><td>10.236.176.76:13004</td><td style=\"text-align: right;\">  -16.38</td><td style=\"text-align: right;\">         563.192</td><td style=\"text-align: right;\">1826000</td><td style=\"text-align: right;\">    54</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for IMPALA_PongNoFrameskip-v4_00c00974:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-03-11_16-32-08\n",
      "  done: false\n",
      "  episode_len_mean: 6263.94\n",
      "  episode_reward_max: -10.0\n",
      "  episode_reward_mean: -16.53\n",
      "  episode_reward_min: -21.0\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 1939\n",
      "  experiment_id: 92f0827d37354e42be7025ff72050188\n",
      "  experiment_tag: '0'\n",
      "  hostname: qian-XPS-8920\n",
      "  info:\n",
      "    learner:\n",
      "      cur_lr: 0.0005000000237487257\n",
      "      entropy: 1532.642578125\n",
      "      entropy_coeff: 0.009999999776482582\n",
      "      grad_gnorm: 39.999996185302734\n",
      "      model: {}\n",
      "      policy_loss: -98.01573944091797\n",
      "      var_gnorm: 18.016210556030273\n",
      "      vf_explained_var: 0.5504130721092224\n",
      "      vf_loss: 43.40777587890625\n",
      "    learner_queue:\n",
      "      size_count: 1860\n",
      "      size_mean: 0.0\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      size_std: 0.0\n",
      "    num_steps_replayed: 0\n",
      "    num_steps_sampled: 1860000\n",
      "    num_steps_trained: 1859000\n",
      "    num_weight_syncs: 7442\n",
      "    sample_throughput: 3266.262\n",
      "    timing_breakdown:\n",
      "      learner_dequeue_time_ms: 4881.588\n",
      "      learner_grad_time_ms: 135.412\n",
      "      learner_load_time_ms: 18.902\n",
      "      learner_load_wait_time_ms: 162.006\n",
      "      optimizer_step_time_ms: 79.015\n",
      "    train_throughput: 3170.195\n",
      "  iterations_since_restore: 55\n",
      "  node_ip: 10.236.176.76\n",
      "  num_healthy_workers: 7\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.42666666666668\n",
      "    ram_util_percent: 77.31999999999998\n",
      "  pid: 13004\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 7.461391431802747\n",
      "    mean_inference_ms: 2.1959665065788654\n",
      "    mean_processing_ms: 0.4583744972057035\n",
      "  time_since_restore: 573.5882787704468\n",
      "  time_this_iter_s: 10.39664626121521\n",
      "  time_total_s: 573.5882787704468\n",
      "  timestamp: 1583958728\n",
      "  timesteps_since_restore: 1860000\n",
      "  timesteps_this_iter: 34000\n",
      "  timesteps_total: 1860000\n",
      "  training_iteration: 55\n",
      "  trial_id: 00c00974\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 12.1/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8/8 CPUs, 1/1 GPUs, 0.0/7.76 GiB heap, 0.0/2.69 GiB objects<br>Result logdir: /home/qian/ray_results/pong-impala-fast<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                        </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>IMPALA_PongNoFrameskip-v4_00c00974</td><td>RUNNING </td><td>10.236.176.76:13004</td><td style=\"text-align: right;\">  -16.53</td><td style=\"text-align: right;\">         573.588</td><td style=\"text-align: right;\">1860000</td><td style=\"text-align: right;\">    55</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for IMPALA_PongNoFrameskip-v4_00c00974:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-03-11_16-32-18\n",
      "  done: false\n",
      "  episode_len_mean: 6316.87\n",
      "  episode_reward_max: -10.0\n",
      "  episode_reward_mean: -16.58\n",
      "  episode_reward_min: -21.0\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 1960\n",
      "  experiment_id: 92f0827d37354e42be7025ff72050188\n",
      "  experiment_tag: '0'\n",
      "  hostname: qian-XPS-8920\n",
      "  info:\n",
      "    learner:\n",
      "      cur_lr: 0.0005000000237487257\n",
      "      entropy: 1572.36328125\n",
      "      entropy_coeff: 0.009999999776482582\n",
      "      grad_gnorm: 40.0\n",
      "      model: {}\n",
      "      policy_loss: 17.551454544067383\n",
      "      var_gnorm: 18.169288635253906\n",
      "      vf_explained_var: 0.5911425352096558\n",
      "      vf_loss: 25.880611419677734\n",
      "    learner_queue:\n",
      "      size_count: 1894\n",
      "      size_mean: 0.0\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      size_std: 0.0\n",
      "    num_steps_replayed: 0\n",
      "    num_steps_sampled: 1894000\n",
      "    num_steps_trained: 1894000\n",
      "    num_weight_syncs: 7577\n",
      "    sample_throughput: 3261.365\n",
      "    timing_breakdown:\n",
      "      learner_dequeue_time_ms: 4879.179\n",
      "      learner_grad_time_ms: 134.956\n",
      "      learner_load_time_ms: 18.857\n",
      "      learner_load_wait_time_ms: 161.492\n",
      "      optimizer_step_time_ms: 98.568\n",
      "    train_throughput: 3357.287\n",
      "  iterations_since_restore: 56\n",
      "  node_ip: 10.236.176.76\n",
      "  num_healthy_workers: 7\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.29333333333334\n",
      "    ram_util_percent: 77.74\n",
      "  pid: 13004\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 7.462261828150324\n",
      "    mean_inference_ms: 2.196768922867433\n",
      "    mean_processing_ms: 0.457840043590115\n",
      "  time_since_restore: 584.0010640621185\n",
      "  time_this_iter_s: 10.412785291671753\n",
      "  time_total_s: 584.0010640621185\n",
      "  timestamp: 1583958738\n",
      "  timesteps_since_restore: 1894000\n",
      "  timesteps_this_iter: 34000\n",
      "  timesteps_total: 1894000\n",
      "  training_iteration: 56\n",
      "  trial_id: 00c00974\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 12.1/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8/8 CPUs, 1/1 GPUs, 0.0/7.76 GiB heap, 0.0/2.69 GiB objects<br>Result logdir: /home/qian/ray_results/pong-impala-fast<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                        </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>IMPALA_PongNoFrameskip-v4_00c00974</td><td>RUNNING </td><td>10.236.176.76:13004</td><td style=\"text-align: right;\">  -16.58</td><td style=\"text-align: right;\">         584.001</td><td style=\"text-align: right;\">1894000</td><td style=\"text-align: right;\">    56</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for IMPALA_PongNoFrameskip-v4_00c00974:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-03-11_16-32-29\n",
      "  done: false\n",
      "  episode_len_mean: 6375.79\n",
      "  episode_reward_max: -10.0\n",
      "  episode_reward_mean: -16.49\n",
      "  episode_reward_min: -21.0\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 1979\n",
      "  experiment_id: 92f0827d37354e42be7025ff72050188\n",
      "  experiment_tag: '0'\n",
      "  hostname: qian-XPS-8920\n",
      "  info:\n",
      "    learner:\n",
      "      cur_lr: 0.0005000000237487257\n",
      "      entropy: 1512.1614990234375\n",
      "      entropy_coeff: 0.009999999776482582\n",
      "      grad_gnorm: 39.999996185302734\n",
      "      model: {}\n",
      "      policy_loss: 89.55419158935547\n",
      "      var_gnorm: 18.32602310180664\n",
      "      vf_explained_var: 0.5998070240020752\n",
      "      vf_loss: 29.288169860839844\n",
      "    learner_queue:\n",
      "      size_count: 1928\n",
      "      size_mean: 0.0\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      size_std: 0.0\n",
      "    num_steps_replayed: 0\n",
      "    num_steps_sampled: 1928000\n",
      "    num_steps_trained: 1927000\n",
      "    num_weight_syncs: 7713\n",
      "    sample_throughput: 3263.961\n",
      "    timing_breakdown:\n",
      "      learner_dequeue_time_ms: 4880.901\n",
      "      learner_grad_time_ms: 135.499\n",
      "      learner_load_time_ms: 20.344\n",
      "      learner_load_wait_time_ms: 167.348\n",
      "      optimizer_step_time_ms: 79.348\n",
      "    train_throughput: 3167.962\n",
      "  iterations_since_restore: 57\n",
      "  node_ip: 10.236.176.76\n",
      "  num_healthy_workers: 7\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.69333333333331\n",
      "    ram_util_percent: 78.18\n",
      "  pid: 13004\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 7.462970885341945\n",
      "    mean_inference_ms: 2.1970464040555258\n",
      "    mean_processing_ms: 0.4571135061077481\n",
      "  time_since_restore: 594.4051606655121\n",
      "  time_this_iter_s: 10.404096603393555\n",
      "  time_total_s: 594.4051606655121\n",
      "  timestamp: 1583958749\n",
      "  timesteps_since_restore: 1928000\n",
      "  timesteps_this_iter: 34000\n",
      "  timesteps_total: 1928000\n",
      "  training_iteration: 57\n",
      "  trial_id: 00c00974\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 12.2/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8/8 CPUs, 1/1 GPUs, 0.0/7.76 GiB heap, 0.0/2.69 GiB objects<br>Result logdir: /home/qian/ray_results/pong-impala-fast<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                        </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>IMPALA_PongNoFrameskip-v4_00c00974</td><td>RUNNING </td><td>10.236.176.76:13004</td><td style=\"text-align: right;\">  -16.49</td><td style=\"text-align: right;\">         594.405</td><td style=\"text-align: right;\">1928000</td><td style=\"text-align: right;\">    57</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for IMPALA_PongNoFrameskip-v4_00c00974:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-03-11_16-32-39\n",
      "  done: false\n",
      "  episode_len_mean: 6466.9\n",
      "  episode_reward_max: -8.0\n",
      "  episode_reward_mean: -16.14\n",
      "  episode_reward_min: -21.0\n",
      "  episodes_this_iter: 23\n",
      "  episodes_total: 2002\n",
      "  experiment_id: 92f0827d37354e42be7025ff72050188\n",
      "  experiment_tag: '0'\n",
      "  hostname: qian-XPS-8920\n",
      "  info:\n",
      "    learner:\n",
      "      cur_lr: 0.0005000000237487257\n",
      "      entropy: 1527.65478515625\n",
      "      entropy_coeff: 0.009999999776482582\n",
      "      grad_gnorm: 40.00000762939453\n",
      "      model: {}\n",
      "      policy_loss: -38.529151916503906\n",
      "      var_gnorm: 18.45591163635254\n",
      "      vf_explained_var: 0.7485570907592773\n",
      "      vf_loss: 15.909279823303223\n",
      "    learner_queue:\n",
      "      size_count: 1962\n",
      "      size_mean: 0.0\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      size_std: 0.0\n",
      "    num_steps_replayed: 0\n",
      "    num_steps_sampled: 1962000\n",
      "    num_steps_trained: 1961000\n",
      "    num_weight_syncs: 7848\n",
      "    sample_throughput: 3244.265\n",
      "    timing_breakdown:\n",
      "      learner_dequeue_time_ms: 4871.316\n",
      "      learner_grad_time_ms: 133.801\n",
      "      learner_load_time_ms: 18.411\n",
      "      learner_load_wait_time_ms: 184.187\n",
      "      optimizer_step_time_ms: 94.163\n",
      "    train_throughput: 3244.265\n",
      "  iterations_since_restore: 58\n",
      "  node_ip: 10.236.176.76\n",
      "  num_healthy_workers: 7\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.79333333333334\n",
      "    ram_util_percent: 78.62666666666668\n",
      "  pid: 13004\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 7.462753379713929\n",
      "    mean_inference_ms: 2.1972537375038996\n",
      "    mean_processing_ms: 0.45639918690876413\n",
      "  time_since_restore: 604.8727605342865\n",
      "  time_this_iter_s: 10.467599868774414\n",
      "  time_total_s: 604.8727605342865\n",
      "  timestamp: 1583958759\n",
      "  timesteps_since_restore: 1962000\n",
      "  timesteps_this_iter: 34000\n",
      "  timesteps_total: 1962000\n",
      "  training_iteration: 58\n",
      "  trial_id: 00c00974\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 12.3/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8/8 CPUs, 1/1 GPUs, 0.0/7.76 GiB heap, 0.0/2.69 GiB objects<br>Result logdir: /home/qian/ray_results/pong-impala-fast<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                        </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>IMPALA_PongNoFrameskip-v4_00c00974</td><td>RUNNING </td><td>10.236.176.76:13004</td><td style=\"text-align: right;\">  -16.14</td><td style=\"text-align: right;\">         604.873</td><td style=\"text-align: right;\">1962000</td><td style=\"text-align: right;\">    58</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for IMPALA_PongNoFrameskip-v4_00c00974:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-03-11_16-32-50\n",
      "  done: false\n",
      "  episode_len_mean: 6608.85\n",
      "  episode_reward_max: -8.0\n",
      "  episode_reward_mean: -15.77\n",
      "  episode_reward_min: -21.0\n",
      "  episodes_this_iter: 17\n",
      "  episodes_total: 2019\n",
      "  experiment_id: 92f0827d37354e42be7025ff72050188\n",
      "  experiment_tag: '0'\n",
      "  hostname: qian-XPS-8920\n",
      "  info:\n",
      "    learner:\n",
      "      cur_lr: 0.0005000000237487257\n",
      "      entropy: 1536.1549072265625\n",
      "      entropy_coeff: 0.009999999776482582\n",
      "      grad_gnorm: 40.000003814697266\n",
      "      model: {}\n",
      "      policy_loss: 50.6048583984375\n",
      "      var_gnorm: 18.696693420410156\n",
      "      vf_explained_var: 0.6248794794082642\n",
      "      vf_loss: 25.651126861572266\n",
      "    learner_queue:\n",
      "      size_count: 1996\n",
      "      size_mean: 0.0\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      size_std: 0.0\n",
      "    num_steps_replayed: 0\n",
      "    num_steps_sampled: 1996000\n",
      "    num_steps_trained: 1995000\n",
      "    num_weight_syncs: 7984\n",
      "    sample_throughput: 3261.508\n",
      "    timing_breakdown:\n",
      "      learner_dequeue_time_ms: 4913.555\n",
      "      learner_grad_time_ms: 134.568\n",
      "      learner_load_time_ms: 18.319\n",
      "      learner_load_wait_time_ms: 170.717\n",
      "      optimizer_step_time_ms: 84.168\n",
      "    train_throughput: 3261.508\n",
      "  iterations_since_restore: 59\n",
      "  node_ip: 10.236.176.76\n",
      "  num_healthy_workers: 7\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.45000000000002\n",
      "    ram_util_percent: 79.0357142857143\n",
      "  pid: 13004\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 7.463688960653988\n",
      "    mean_inference_ms: 2.197761787888748\n",
      "    mean_processing_ms: 0.4559587191389835\n",
      "  time_since_restore: 615.2841248512268\n",
      "  time_this_iter_s: 10.411364316940308\n",
      "  time_total_s: 615.2841248512268\n",
      "  timestamp: 1583958770\n",
      "  timesteps_since_restore: 1996000\n",
      "  timesteps_this_iter: 34000\n",
      "  timesteps_total: 1996000\n",
      "  training_iteration: 59\n",
      "  trial_id: 00c00974\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 12.3/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8/8 CPUs, 1/1 GPUs, 0.0/7.76 GiB heap, 0.0/2.69 GiB objects<br>Result logdir: /home/qian/ray_results/pong-impala-fast<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                        </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>IMPALA_PongNoFrameskip-v4_00c00974</td><td>RUNNING </td><td>10.236.176.76:13004</td><td style=\"text-align: right;\">  -15.77</td><td style=\"text-align: right;\">         615.284</td><td style=\"text-align: right;\">1996000</td><td style=\"text-align: right;\">    59</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for IMPALA_PongNoFrameskip-v4_00c00974:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-03-11_16-33-00\n",
      "  done: false\n",
      "  episode_len_mean: 6794.73\n",
      "  episode_reward_max: -8.0\n",
      "  episode_reward_mean: -15.77\n",
      "  episode_reward_min: -21.0\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 2039\n",
      "  experiment_id: 92f0827d37354e42be7025ff72050188\n",
      "  experiment_tag: '0'\n",
      "  hostname: qian-XPS-8920\n",
      "  info:\n",
      "    learner:\n",
      "      cur_lr: 0.0005000000237487257\n",
      "      entropy: 1558.0657958984375\n",
      "      entropy_coeff: 0.009999999776482582\n",
      "      grad_gnorm: 40.0\n",
      "      model: {}\n",
      "      policy_loss: 94.56222534179688\n",
      "      var_gnorm: 18.89596939086914\n",
      "      vf_explained_var: 0.5272645950317383\n",
      "      vf_loss: 42.67881774902344\n",
      "    learner_queue:\n",
      "      size_count: 2030\n",
      "      size_mean: 0.0\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      size_std: 0.0\n",
      "    num_steps_replayed: 0\n",
      "    num_steps_sampled: 2030000\n",
      "    num_steps_trained: 2029000\n",
      "    num_weight_syncs: 8120\n",
      "    sample_throughput: 3248.893\n",
      "    timing_breakdown:\n",
      "      learner_dequeue_time_ms: 4892.826\n",
      "      learner_grad_time_ms: 132.629\n",
      "      learner_load_time_ms: 29.766\n",
      "      learner_load_wait_time_ms: 175.227\n",
      "      optimizer_step_time_ms: 87.774\n",
      "    train_throughput: 3248.893\n",
      "  iterations_since_restore: 60\n",
      "  node_ip: 10.236.176.76\n",
      "  num_healthy_workers: 7\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.99999999999999\n",
      "    ram_util_percent: 79.46666666666665\n",
      "  pid: 13004\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 7.465782909993816\n",
      "    mean_inference_ms: 2.198905742689897\n",
      "    mean_processing_ms: 0.4555409090541609\n",
      "  time_since_restore: 625.7366735935211\n",
      "  time_this_iter_s: 10.452548742294312\n",
      "  time_total_s: 625.7366735935211\n",
      "  timestamp: 1583958780\n",
      "  timesteps_since_restore: 2030000\n",
      "  timesteps_this_iter: 34000\n",
      "  timesteps_total: 2030000\n",
      "  training_iteration: 60\n",
      "  trial_id: 00c00974\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 12.4/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8/8 CPUs, 1/1 GPUs, 0.0/7.76 GiB heap, 0.0/2.69 GiB objects<br>Result logdir: /home/qian/ray_results/pong-impala-fast<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                        </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>IMPALA_PongNoFrameskip-v4_00c00974</td><td>RUNNING </td><td>10.236.176.76:13004</td><td style=\"text-align: right;\">  -15.77</td><td style=\"text-align: right;\">         625.737</td><td style=\"text-align: right;\">2030000</td><td style=\"text-align: right;\">    60</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for IMPALA_PongNoFrameskip-v4_00c00974:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-03-11_16-33-10\n",
      "  done: false\n",
      "  episode_len_mean: 6937.23\n",
      "  episode_reward_max: -8.0\n",
      "  episode_reward_mean: -15.52\n",
      "  episode_reward_min: -21.0\n",
      "  episodes_this_iter: 17\n",
      "  episodes_total: 2056\n",
      "  experiment_id: 92f0827d37354e42be7025ff72050188\n",
      "  experiment_tag: '0'\n",
      "  hostname: qian-XPS-8920\n",
      "  info:\n",
      "    learner:\n",
      "      cur_lr: 0.0005000000237487257\n",
      "      entropy: 1509.7979736328125\n",
      "      entropy_coeff: 0.009999999776482582\n",
      "      grad_gnorm: 39.999996185302734\n",
      "      model: {}\n",
      "      policy_loss: -0.18579626083374023\n",
      "      var_gnorm: 19.08972930908203\n",
      "      vf_explained_var: 0.7221125364303589\n",
      "      vf_loss: 20.365541458129883\n",
      "    learner_queue:\n",
      "      size_count: 2063\n",
      "      size_mean: 0.0\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      size_std: 0.0\n",
      "    num_steps_replayed: 0\n",
      "    num_steps_sampled: 2063000\n",
      "    num_steps_trained: 2063000\n",
      "    num_weight_syncs: 8255\n",
      "    sample_throughput: 3167.504\n",
      "    timing_breakdown:\n",
      "      learner_dequeue_time_ms: 4885.936\n",
      "      learner_grad_time_ms: 137.76\n",
      "      learner_load_time_ms: 40.198\n",
      "      learner_load_wait_time_ms: 154.39\n",
      "      optimizer_step_time_ms: 91.196\n",
      "    train_throughput: 3263.489\n",
      "  iterations_since_restore: 61\n",
      "  node_ip: 10.236.176.76\n",
      "  num_healthy_workers: 7\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.44666666666667\n",
      "    ram_util_percent: 79.59999999999998\n",
      "  pid: 13004\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 7.464848681950628\n",
      "    mean_inference_ms: 2.1991709856232426\n",
      "    mean_processing_ms: 0.45501436772918824\n",
      "  time_since_restore: 636.1422517299652\n",
      "  time_this_iter_s: 10.405578136444092\n",
      "  time_total_s: 636.1422517299652\n",
      "  timestamp: 1583958790\n",
      "  timesteps_since_restore: 2063000\n",
      "  timesteps_this_iter: 33000\n",
      "  timesteps_total: 2063000\n",
      "  training_iteration: 61\n",
      "  trial_id: 00c00974\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 12.4/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8/8 CPUs, 1/1 GPUs, 0.0/7.76 GiB heap, 0.0/2.69 GiB objects<br>Result logdir: /home/qian/ray_results/pong-impala-fast<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                        </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>IMPALA_PongNoFrameskip-v4_00c00974</td><td>RUNNING </td><td>10.236.176.76:13004</td><td style=\"text-align: right;\">  -15.52</td><td style=\"text-align: right;\">         636.142</td><td style=\"text-align: right;\">2063000</td><td style=\"text-align: right;\">    61</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for IMPALA_PongNoFrameskip-v4_00c00974:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-03-11_16-33-21\n",
      "  done: false\n",
      "  episode_len_mean: 7020.37\n",
      "  episode_reward_max: -4.0\n",
      "  episode_reward_mean: -15.23\n",
      "  episode_reward_min: -21.0\n",
      "  episodes_this_iter: 17\n",
      "  episodes_total: 2073\n",
      "  experiment_id: 92f0827d37354e42be7025ff72050188\n",
      "  experiment_tag: '0'\n",
      "  hostname: qian-XPS-8920\n",
      "  info:\n",
      "    learner:\n",
      "      cur_lr: 0.0005000000237487257\n",
      "      entropy: 1585.058837890625\n",
      "      entropy_coeff: 0.009999999776482582\n",
      "      grad_gnorm: 40.0\n",
      "      model: {}\n",
      "      policy_loss: -20.15105628967285\n",
      "      var_gnorm: 19.2541446685791\n",
      "      vf_explained_var: 0.6001189947128296\n",
      "      vf_loss: 28.69709014892578\n",
      "    learner_queue:\n",
      "      size_count: 2097\n",
      "      size_mean: 0.0\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      size_std: 0.0\n",
      "    num_steps_replayed: 0\n",
      "    num_steps_sampled: 2097000\n",
      "    num_steps_trained: 2097000\n",
      "    num_weight_syncs: 8391\n",
      "    sample_throughput: 3253.696\n",
      "    timing_breakdown:\n",
      "      learner_dequeue_time_ms: 4886.396\n",
      "      learner_grad_time_ms: 137.146\n",
      "      learner_load_time_ms: 40.297\n",
      "      learner_load_wait_time_ms: 162.01\n",
      "      optimizer_step_time_ms: 84.832\n",
      "    train_throughput: 3253.696\n",
      "  iterations_since_restore: 62\n",
      "  node_ip: 10.236.176.76\n",
      "  num_healthy_workers: 7\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.42666666666668\n",
      "    ram_util_percent: 79.59999999999998\n",
      "  pid: 13004\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 7.464945101907026\n",
      "    mean_inference_ms: 2.1976228346652604\n",
      "    mean_processing_ms: 0.4542253858441945\n",
      "  time_since_restore: 646.5791459083557\n",
      "  time_this_iter_s: 10.436894178390503\n",
      "  time_total_s: 646.5791459083557\n",
      "  timestamp: 1583958801\n",
      "  timesteps_since_restore: 2097000\n",
      "  timesteps_this_iter: 34000\n",
      "  timesteps_total: 2097000\n",
      "  training_iteration: 62\n",
      "  trial_id: 00c00974\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 12.4/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8/8 CPUs, 1/1 GPUs, 0.0/7.76 GiB heap, 0.0/2.69 GiB objects<br>Result logdir: /home/qian/ray_results/pong-impala-fast<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                        </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>IMPALA_PongNoFrameskip-v4_00c00974</td><td>RUNNING </td><td>10.236.176.76:13004</td><td style=\"text-align: right;\">  -15.23</td><td style=\"text-align: right;\">         646.579</td><td style=\"text-align: right;\">2097000</td><td style=\"text-align: right;\">    62</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for IMPALA_PongNoFrameskip-v4_00c00974:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-03-11_16-33-31\n",
      "  done: false\n",
      "  episode_len_mean: 7143.3\n",
      "  episode_reward_max: -4.0\n",
      "  episode_reward_mean: -15.21\n",
      "  episode_reward_min: -21.0\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 2094\n",
      "  experiment_id: 92f0827d37354e42be7025ff72050188\n",
      "  experiment_tag: '0'\n",
      "  hostname: qian-XPS-8920\n",
      "  info:\n",
      "    learner:\n",
      "      cur_lr: 0.0005000000237487257\n",
      "      entropy: 1549.0711669921875\n",
      "      entropy_coeff: 0.009999999776482582\n",
      "      grad_gnorm: 40.0\n",
      "      model: {}\n",
      "      policy_loss: 106.2232666015625\n",
      "      var_gnorm: 19.492273330688477\n",
      "      vf_explained_var: 0.5716369152069092\n",
      "      vf_loss: 35.14067077636719\n",
      "    learner_queue:\n",
      "      size_count: 2131\n",
      "      size_mean: 0.0\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      size_std: 0.0\n",
      "    num_steps_replayed: 0\n",
      "    num_steps_sampled: 2131000\n",
      "    num_steps_trained: 2131000\n",
      "    num_weight_syncs: 8527\n",
      "    sample_throughput: 3243.29\n",
      "    timing_breakdown:\n",
      "      learner_dequeue_time_ms: 4875.032\n",
      "      learner_grad_time_ms: 135.324\n",
      "      learner_load_time_ms: 41.69\n",
      "      learner_load_wait_time_ms: 168.801\n",
      "      optimizer_step_time_ms: 85.319\n",
      "    train_throughput: 3243.29\n",
      "  iterations_since_restore: 63\n",
      "  node_ip: 10.236.176.76\n",
      "  num_healthy_workers: 7\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.11333333333332\n",
      "    ram_util_percent: 79.59999999999998\n",
      "  pid: 13004\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 7.464702824412211\n",
      "    mean_inference_ms: 2.19771450084592\n",
      "    mean_processing_ms: 0.45371894232476945\n",
      "  time_since_restore: 657.0496129989624\n",
      "  time_this_iter_s: 10.47046709060669\n",
      "  time_total_s: 657.0496129989624\n",
      "  timestamp: 1583958811\n",
      "  timesteps_since_restore: 2131000\n",
      "  timesteps_this_iter: 34000\n",
      "  timesteps_total: 2131000\n",
      "  training_iteration: 63\n",
      "  trial_id: 00c00974\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 12.4/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8/8 CPUs, 1/1 GPUs, 0.0/7.76 GiB heap, 0.0/2.69 GiB objects<br>Result logdir: /home/qian/ray_results/pong-impala-fast<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                        </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>IMPALA_PongNoFrameskip-v4_00c00974</td><td>RUNNING </td><td>10.236.176.76:13004</td><td style=\"text-align: right;\">  -15.21</td><td style=\"text-align: right;\">          657.05</td><td style=\"text-align: right;\">2131000</td><td style=\"text-align: right;\">    63</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for IMPALA_PongNoFrameskip-v4_00c00974:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-03-11_16-33-42\n",
      "  done: false\n",
      "  episode_len_mean: 7279.55\n",
      "  episode_reward_max: -4.0\n",
      "  episode_reward_mean: -15.13\n",
      "  episode_reward_min: -21.0\n",
      "  episodes_this_iter: 16\n",
      "  episodes_total: 2110\n",
      "  experiment_id: 92f0827d37354e42be7025ff72050188\n",
      "  experiment_tag: '0'\n",
      "  hostname: qian-XPS-8920\n",
      "  info:\n",
      "    learner:\n",
      "      cur_lr: 0.0005000000237487257\n",
      "      entropy: 1608.0469970703125\n",
      "      entropy_coeff: 0.009999999776482582\n",
      "      grad_gnorm: 40.0\n",
      "      model: {}\n",
      "      policy_loss: -77.5020523071289\n",
      "      var_gnorm: 19.71734046936035\n",
      "      vf_explained_var: 0.6041536331176758\n",
      "      vf_loss: 16.63282585144043\n",
      "    learner_queue:\n",
      "      size_count: 2166\n",
      "      size_mean: 0.0\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      size_std: 0.0\n",
      "    num_steps_replayed: 0\n",
      "    num_steps_sampled: 2166000\n",
      "    num_steps_trained: 2165000\n",
      "    num_weight_syncs: 8664\n",
      "    sample_throughput: 3325.99\n",
      "    timing_breakdown:\n",
      "      learner_dequeue_time_ms: 4890.912\n",
      "      learner_grad_time_ms: 133.573\n",
      "      learner_load_time_ms: 30.979\n",
      "      learner_load_wait_time_ms: 171.16\n",
      "      optimizer_step_time_ms: 76.012\n",
      "    train_throughput: 3230.962\n",
      "  iterations_since_restore: 64\n",
      "  node_ip: 10.236.176.76\n",
      "  num_healthy_workers: 7\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.56666666666668\n",
      "    ram_util_percent: 79.59999999999998\n",
      "  pid: 13004\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 7.466110121623912\n",
      "    mean_inference_ms: 2.197234253659309\n",
      "    mean_processing_ms: 0.45304235322112846\n",
      "  time_since_restore: 667.5602481365204\n",
      "  time_this_iter_s: 10.510635137557983\n",
      "  time_total_s: 667.5602481365204\n",
      "  timestamp: 1583958822\n",
      "  timesteps_since_restore: 2166000\n",
      "  timesteps_this_iter: 35000\n",
      "  timesteps_total: 2166000\n",
      "  training_iteration: 64\n",
      "  trial_id: 00c00974\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 12.4/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8/8 CPUs, 1/1 GPUs, 0.0/7.76 GiB heap, 0.0/2.69 GiB objects<br>Result logdir: /home/qian/ray_results/pong-impala-fast<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                        </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>IMPALA_PongNoFrameskip-v4_00c00974</td><td>RUNNING </td><td>10.236.176.76:13004</td><td style=\"text-align: right;\">  -15.13</td><td style=\"text-align: right;\">          667.56</td><td style=\"text-align: right;\">2166000</td><td style=\"text-align: right;\">    64</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for IMPALA_PongNoFrameskip-v4_00c00974:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-03-11_16-33-52\n",
      "  done: false\n",
      "  episode_len_mean: 7406.64\n",
      "  episode_reward_max: -4.0\n",
      "  episode_reward_mean: -14.87\n",
      "  episode_reward_min: -21.0\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 2128\n",
      "  experiment_id: 92f0827d37354e42be7025ff72050188\n",
      "  experiment_tag: '0'\n",
      "  hostname: qian-XPS-8920\n",
      "  info:\n",
      "    learner:\n",
      "      cur_lr: 0.0005000000237487257\n",
      "      entropy: 1541.23388671875\n",
      "      entropy_coeff: 0.009999999776482582\n",
      "      grad_gnorm: 40.0\n",
      "      model: {}\n",
      "      policy_loss: 38.9059944152832\n",
      "      var_gnorm: 19.892335891723633\n",
      "      vf_explained_var: 0.7342184782028198\n",
      "      vf_loss: 22.51912498474121\n",
      "    learner_queue:\n",
      "      size_count: 2200\n",
      "      size_mean: 0.0\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      size_std: 0.0\n",
      "    num_steps_replayed: 0\n",
      "    num_steps_sampled: 2200000\n",
      "    num_steps_trained: 2199000\n",
      "    num_weight_syncs: 8801\n",
      "    sample_throughput: 3245.974\n",
      "    timing_breakdown:\n",
      "      learner_dequeue_time_ms: 4891.247\n",
      "      learner_grad_time_ms: 135.301\n",
      "      learner_load_time_ms: 20.569\n",
      "      learner_load_wait_time_ms: 161.997\n",
      "      optimizer_step_time_ms: 68.956\n",
      "    train_throughput: 3245.974\n",
      "  iterations_since_restore: 65\n",
      "  node_ip: 10.236.176.76\n",
      "  num_healthy_workers: 7\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.86666666666666\n",
      "    ram_util_percent: 79.59999999999998\n",
      "  pid: 13004\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 7.464964068334509\n",
      "    mean_inference_ms: 2.196520651834446\n",
      "    mean_processing_ms: 0.45231945051665\n",
      "  time_since_restore: 678.0216975212097\n",
      "  time_this_iter_s: 10.461449384689331\n",
      "  time_total_s: 678.0216975212097\n",
      "  timestamp: 1583958832\n",
      "  timesteps_since_restore: 2200000\n",
      "  timesteps_this_iter: 34000\n",
      "  timesteps_total: 2200000\n",
      "  training_iteration: 65\n",
      "  trial_id: 00c00974\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 12.4/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8/8 CPUs, 1/1 GPUs, 0.0/7.76 GiB heap, 0.0/2.69 GiB objects<br>Result logdir: /home/qian/ray_results/pong-impala-fast<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                        </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>IMPALA_PongNoFrameskip-v4_00c00974</td><td>RUNNING </td><td>10.236.176.76:13004</td><td style=\"text-align: right;\">  -14.87</td><td style=\"text-align: right;\">         678.022</td><td style=\"text-align: right;\">2200000</td><td style=\"text-align: right;\">    65</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for IMPALA_PongNoFrameskip-v4_00c00974:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-03-11_16-34-03\n",
      "  done: false\n",
      "  episode_len_mean: 7633.41\n",
      "  episode_reward_max: -4.0\n",
      "  episode_reward_mean: -13.98\n",
      "  episode_reward_min: -21.0\n",
      "  episodes_this_iter: 16\n",
      "  episodes_total: 2144\n",
      "  experiment_id: 92f0827d37354e42be7025ff72050188\n",
      "  experiment_tag: '0'\n",
      "  hostname: qian-XPS-8920\n",
      "  info:\n",
      "    learner:\n",
      "      cur_lr: 0.0005000000237487257\n",
      "      entropy: 1542.217529296875\n",
      "      entropy_coeff: 0.009999999776482582\n",
      "      grad_gnorm: 39.999996185302734\n",
      "      model: {}\n",
      "      policy_loss: -12.281146049499512\n",
      "      var_gnorm: 20.0474910736084\n",
      "      vf_explained_var: 0.5354829430580139\n",
      "      vf_loss: 28.868694305419922\n",
      "    learner_queue:\n",
      "      size_count: 2234\n",
      "      size_mean: 0.0\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      size_std: 0.0\n",
      "    num_steps_replayed: 0\n",
      "    num_steps_sampled: 2234000\n",
      "    num_steps_trained: 2233000\n",
      "    num_weight_syncs: 8937\n",
      "    sample_throughput: 3249.731\n",
      "    timing_breakdown:\n",
      "      learner_dequeue_time_ms: 4897.373\n",
      "      learner_grad_time_ms: 134.091\n",
      "      learner_load_time_ms: 20.729\n",
      "      learner_load_wait_time_ms: 177.039\n",
      "      optimizer_step_time_ms: 82.458\n",
      "    train_throughput: 3249.731\n",
      "  iterations_since_restore: 66\n",
      "  node_ip: 10.236.176.76\n",
      "  num_healthy_workers: 7\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.92666666666668\n",
      "    ram_util_percent: 79.59999999999998\n",
      "  pid: 13004\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 7.46666391596159\n",
      "    mean_inference_ms: 2.198005292220108\n",
      "    mean_processing_ms: 0.4518746814897543\n",
      "  time_since_restore: 688.4714932441711\n",
      "  time_this_iter_s: 10.449795722961426\n",
      "  time_total_s: 688.4714932441711\n",
      "  timestamp: 1583958843\n",
      "  timesteps_since_restore: 2234000\n",
      "  timesteps_this_iter: 34000\n",
      "  timesteps_total: 2234000\n",
      "  training_iteration: 66\n",
      "  trial_id: 00c00974\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 12.4/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8/8 CPUs, 1/1 GPUs, 0.0/7.76 GiB heap, 0.0/2.69 GiB objects<br>Result logdir: /home/qian/ray_results/pong-impala-fast<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                        </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>IMPALA_PongNoFrameskip-v4_00c00974</td><td>RUNNING </td><td>10.236.176.76:13004</td><td style=\"text-align: right;\">  -13.98</td><td style=\"text-align: right;\">         688.471</td><td style=\"text-align: right;\">2234000</td><td style=\"text-align: right;\">    66</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for IMPALA_PongNoFrameskip-v4_00c00974:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-03-11_16-34-13\n",
      "  done: false\n",
      "  episode_len_mean: 7628.46\n",
      "  episode_reward_max: -4.0\n",
      "  episode_reward_mean: -13.9\n",
      "  episode_reward_min: -21.0\n",
      "  episodes_this_iter: 16\n",
      "  episodes_total: 2160\n",
      "  experiment_id: 92f0827d37354e42be7025ff72050188\n",
      "  experiment_tag: '0'\n",
      "  hostname: qian-XPS-8920\n",
      "  info:\n",
      "    learner:\n",
      "      cur_lr: 0.0005000000237487257\n",
      "      entropy: 1570.931640625\n",
      "      entropy_coeff: 0.009999999776482582\n",
      "      grad_gnorm: 40.0\n",
      "      model: {}\n",
      "      policy_loss: 105.78731536865234\n",
      "      var_gnorm: 20.18597984313965\n",
      "      vf_explained_var: 0.6486018896102905\n",
      "      vf_loss: 54.577796936035156\n",
      "    learner_queue:\n",
      "      size_count: 2268\n",
      "      size_mean: 0.0\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      size_std: 0.0\n",
      "    num_steps_replayed: 0\n",
      "    num_steps_sampled: 2268000\n",
      "    num_steps_trained: 2268000\n",
      "    num_weight_syncs: 9073\n",
      "    sample_throughput: 3257.676\n",
      "    timing_breakdown:\n",
      "      learner_dequeue_time_ms: 4901.737\n",
      "      learner_grad_time_ms: 133.457\n",
      "      learner_load_time_ms: 20.838\n",
      "      learner_load_wait_time_ms: 160.983\n",
      "      optimizer_step_time_ms: 84.594\n",
      "    train_throughput: 3353.49\n",
      "  iterations_since_restore: 67\n",
      "  node_ip: 10.236.176.76\n",
      "  num_healthy_workers: 7\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.39999999999999\n",
      "    ram_util_percent: 79.59999999999998\n",
      "  pid: 13004\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 7.4656282630667405\n",
      "    mean_inference_ms: 2.196746489356645\n",
      "    mean_processing_ms: 0.45120435415087995\n",
      "  time_since_restore: 698.8956081867218\n",
      "  time_this_iter_s: 10.42411494255066\n",
      "  time_total_s: 698.8956081867218\n",
      "  timestamp: 1583958853\n",
      "  timesteps_since_restore: 2268000\n",
      "  timesteps_this_iter: 34000\n",
      "  timesteps_total: 2268000\n",
      "  training_iteration: 67\n",
      "  trial_id: 00c00974\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 12.4/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8/8 CPUs, 1/1 GPUs, 0.0/7.76 GiB heap, 0.0/2.69 GiB objects<br>Result logdir: /home/qian/ray_results/pong-impala-fast<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                        </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>IMPALA_PongNoFrameskip-v4_00c00974</td><td>RUNNING </td><td>10.236.176.76:13004</td><td style=\"text-align: right;\">   -13.9</td><td style=\"text-align: right;\">         698.896</td><td style=\"text-align: right;\">2268000</td><td style=\"text-align: right;\">    67</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for IMPALA_PongNoFrameskip-v4_00c00974:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-03-11_16-34-24\n",
      "  done: false\n",
      "  episode_len_mean: 7805.3\n",
      "  episode_reward_max: -5.0\n",
      "  episode_reward_mean: -13.29\n",
      "  episode_reward_min: -21.0\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 2179\n",
      "  experiment_id: 92f0827d37354e42be7025ff72050188\n",
      "  experiment_tag: '0'\n",
      "  hostname: qian-XPS-8920\n",
      "  info:\n",
      "    learner:\n",
      "      cur_lr: 0.0005000000237487257\n",
      "      entropy: 1551.8065185546875\n",
      "      entropy_coeff: 0.009999999776482582\n",
      "      grad_gnorm: 40.000003814697266\n",
      "      model: {}\n",
      "      policy_loss: -39.87022018432617\n",
      "      var_gnorm: 20.312618255615234\n",
      "      vf_explained_var: 0.7071465253829956\n",
      "      vf_loss: 26.749832153320312\n",
      "    learner_queue:\n",
      "      size_count: 2302\n",
      "      size_mean: 0.0\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      size_std: 0.0\n",
      "    num_steps_replayed: 0\n",
      "    num_steps_sampled: 2302000\n",
      "    num_steps_trained: 2302000\n",
      "    num_weight_syncs: 9210\n",
      "    sample_throughput: 3233.596\n",
      "    timing_breakdown:\n",
      "      learner_dequeue_time_ms: 4901.598\n",
      "      learner_grad_time_ms: 133.097\n",
      "      learner_load_time_ms: 19.613\n",
      "      learner_load_wait_time_ms: 159.445\n",
      "      optimizer_step_time_ms: 76.157\n",
      "    train_throughput: 3233.596\n",
      "  iterations_since_restore: 68\n",
      "  node_ip: 10.236.176.76\n",
      "  num_healthy_workers: 7\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.62666666666665\n",
      "    ram_util_percent: 79.59999999999998\n",
      "  pid: 13004\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 7.466985694784499\n",
      "    mean_inference_ms: 2.1974230805799384\n",
      "    mean_processing_ms: 0.4506680411903542\n",
      "  time_since_restore: 709.3980612754822\n",
      "  time_this_iter_s: 10.502453088760376\n",
      "  time_total_s: 709.3980612754822\n",
      "  timestamp: 1583958864\n",
      "  timesteps_since_restore: 2302000\n",
      "  timesteps_this_iter: 34000\n",
      "  timesteps_total: 2302000\n",
      "  training_iteration: 68\n",
      "  trial_id: 00c00974\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 12.4/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8/8 CPUs, 1/1 GPUs, 0.0/7.76 GiB heap, 0.0/2.69 GiB objects<br>Result logdir: /home/qian/ray_results/pong-impala-fast<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                        </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>IMPALA_PongNoFrameskip-v4_00c00974</td><td>RUNNING </td><td>10.236.176.76:13004</td><td style=\"text-align: right;\">  -13.29</td><td style=\"text-align: right;\">         709.398</td><td style=\"text-align: right;\">2302000</td><td style=\"text-align: right;\">    68</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for IMPALA_PongNoFrameskip-v4_00c00974:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-03-11_16-34-34\n",
      "  done: false\n",
      "  episode_len_mean: 7892.73\n",
      "  episode_reward_max: -5.0\n",
      "  episode_reward_mean: -12.8\n",
      "  episode_reward_min: -21.0\n",
      "  episodes_this_iter: 14\n",
      "  episodes_total: 2193\n",
      "  experiment_id: 92f0827d37354e42be7025ff72050188\n",
      "  experiment_tag: '0'\n",
      "  hostname: qian-XPS-8920\n",
      "  info:\n",
      "    learner:\n",
      "      cur_lr: 0.0005000000237487257\n",
      "      entropy: 1515.2828369140625\n",
      "      entropy_coeff: 0.009999999776482582\n",
      "      grad_gnorm: 40.0\n",
      "      model: {}\n",
      "      policy_loss: 87.04865264892578\n",
      "      var_gnorm: 20.55225372314453\n",
      "      vf_explained_var: 0.5454152226448059\n",
      "      vf_loss: 43.3845329284668\n",
      "    learner_queue:\n",
      "      size_count: 2336\n",
      "      size_mean: 0.0\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      size_std: 0.0\n",
      "    num_steps_replayed: 0\n",
      "    num_steps_sampled: 2336000\n",
      "    num_steps_trained: 2335000\n",
      "    num_weight_syncs: 9345\n",
      "    sample_throughput: 3263.76\n",
      "    timing_breakdown:\n",
      "      learner_dequeue_time_ms: 4901.15\n",
      "      learner_grad_time_ms: 133.859\n",
      "      learner_load_time_ms: 18.525\n",
      "      learner_load_wait_time_ms: 164.159\n",
      "      optimizer_step_time_ms: 87.889\n",
      "    train_throughput: 3167.767\n",
      "  iterations_since_restore: 69\n",
      "  node_ip: 10.236.176.76\n",
      "  num_healthy_workers: 7\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.26666666666665\n",
      "    ram_util_percent: 79.60666666666665\n",
      "  pid: 13004\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 7.4682960138128305\n",
      "    mean_inference_ms: 2.1986372585198755\n",
      "    mean_processing_ms: 0.4502119310492047\n",
      "  time_since_restore: 719.8027937412262\n",
      "  time_this_iter_s: 10.404732465744019\n",
      "  time_total_s: 719.8027937412262\n",
      "  timestamp: 1583958874\n",
      "  timesteps_since_restore: 2336000\n",
      "  timesteps_this_iter: 34000\n",
      "  timesteps_total: 2336000\n",
      "  training_iteration: 69\n",
      "  trial_id: 00c00974\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 12.4/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8/8 CPUs, 1/1 GPUs, 0.0/7.76 GiB heap, 0.0/2.69 GiB objects<br>Result logdir: /home/qian/ray_results/pong-impala-fast<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                        </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>IMPALA_PongNoFrameskip-v4_00c00974</td><td>RUNNING </td><td>10.236.176.76:13004</td><td style=\"text-align: right;\">   -12.8</td><td style=\"text-align: right;\">         719.803</td><td style=\"text-align: right;\">2336000</td><td style=\"text-align: right;\">    69</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for IMPALA_PongNoFrameskip-v4_00c00974:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-03-11_16-34-45\n",
      "  done: false\n",
      "  episode_len_mean: 7915.85\n",
      "  episode_reward_max: -5.0\n",
      "  episode_reward_mean: -12.65\n",
      "  episode_reward_min: -21.0\n",
      "  episodes_this_iter: 10\n",
      "  episodes_total: 2203\n",
      "  experiment_id: 92f0827d37354e42be7025ff72050188\n",
      "  experiment_tag: '0'\n",
      "  hostname: qian-XPS-8920\n",
      "  info:\n",
      "    learner:\n",
      "      cur_lr: 0.0005000000237487257\n",
      "      entropy: 1512.5780029296875\n",
      "      entropy_coeff: 0.009999999776482582\n",
      "      grad_gnorm: 39.999996185302734\n",
      "      model: {}\n",
      "      policy_loss: 47.306884765625\n",
      "      var_gnorm: 20.834699630737305\n",
      "      vf_explained_var: 0.489338219165802\n",
      "      vf_loss: 35.43988800048828\n",
      "    learner_queue:\n",
      "      size_count: 2370\n",
      "      size_mean: 0.0\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      size_std: 0.0\n",
      "    num_steps_replayed: 0\n",
      "    num_steps_sampled: 2370000\n",
      "    num_steps_trained: 2369000\n",
      "    num_weight_syncs: 9480\n",
      "    sample_throughput: 3265.576\n",
      "    timing_breakdown:\n",
      "      learner_dequeue_time_ms: 4889.511\n",
      "      learner_grad_time_ms: 135.574\n",
      "      learner_load_time_ms: 18.222\n",
      "      learner_load_wait_time_ms: 172.813\n",
      "      optimizer_step_time_ms: 91.206\n",
      "    train_throughput: 3265.576\n",
      "  iterations_since_restore: 70\n",
      "  node_ip: 10.236.176.76\n",
      "  num_healthy_workers: 7\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.96000000000001\n",
      "    ram_util_percent: 79.62666666666665\n",
      "  pid: 13004\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 7.468233306688667\n",
      "    mean_inference_ms: 2.1981314083400627\n",
      "    mean_processing_ms: 0.4498383549320076\n",
      "  time_since_restore: 730.2014825344086\n",
      "  time_this_iter_s: 10.398688793182373\n",
      "  time_total_s: 730.2014825344086\n",
      "  timestamp: 1583958885\n",
      "  timesteps_since_restore: 2370000\n",
      "  timesteps_this_iter: 34000\n",
      "  timesteps_total: 2370000\n",
      "  training_iteration: 70\n",
      "  trial_id: 00c00974\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 12.4/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8/8 CPUs, 1/1 GPUs, 0.0/7.76 GiB heap, 0.0/2.69 GiB objects<br>Result logdir: /home/qian/ray_results/pong-impala-fast<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                        </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>IMPALA_PongNoFrameskip-v4_00c00974</td><td>RUNNING </td><td>10.236.176.76:13004</td><td style=\"text-align: right;\">  -12.65</td><td style=\"text-align: right;\">         730.201</td><td style=\"text-align: right;\">2370000</td><td style=\"text-align: right;\">    70</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for IMPALA_PongNoFrameskip-v4_00c00974:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-03-11_16-34-55\n",
      "  done: false\n",
      "  episode_len_mean: 8244.02\n",
      "  episode_reward_max: -3.0\n",
      "  episode_reward_mean: -11.43\n",
      "  episode_reward_min: -21.0\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 2221\n",
      "  experiment_id: 92f0827d37354e42be7025ff72050188\n",
      "  experiment_tag: '0'\n",
      "  hostname: qian-XPS-8920\n",
      "  info:\n",
      "    learner:\n",
      "      cur_lr: 0.0005000000237487257\n",
      "      entropy: 1458.81201171875\n",
      "      entropy_coeff: 0.009999999776482582\n",
      "      grad_gnorm: 40.000003814697266\n",
      "      model: {}\n",
      "      policy_loss: 46.32243347167969\n",
      "      var_gnorm: 21.130823135375977\n",
      "      vf_explained_var: 0.5571929216384888\n",
      "      vf_loss: 34.25257110595703\n",
      "    learner_queue:\n",
      "      size_count: 2404\n",
      "      size_mean: 0.0\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      size_std: 0.0\n",
      "    num_steps_replayed: 0\n",
      "    num_steps_sampled: 2404000\n",
      "    num_steps_trained: 2403000\n",
      "    num_weight_syncs: 9616\n",
      "    sample_throughput: 3247.616\n",
      "    timing_breakdown:\n",
      "      learner_dequeue_time_ms: 4903.67\n",
      "      learner_grad_time_ms: 134.293\n",
      "      learner_load_time_ms: 17.658\n",
      "      learner_load_wait_time_ms: 158.618\n",
      "      optimizer_step_time_ms: 71.267\n",
      "    train_throughput: 3247.616\n",
      "  iterations_since_restore: 71\n",
      "  node_ip: 10.236.176.76\n",
      "  num_healthy_workers: 7\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.53571428571429\n",
      "    ram_util_percent: 79.61428571428571\n",
      "  pid: 13004\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 7.468828894012005\n",
      "    mean_inference_ms: 2.198526933793674\n",
      "    mean_processing_ms: 0.4492854288547617\n",
      "  time_since_restore: 740.6582577228546\n",
      "  time_this_iter_s: 10.456775188446045\n",
      "  time_total_s: 740.6582577228546\n",
      "  timestamp: 1583958895\n",
      "  timesteps_since_restore: 2404000\n",
      "  timesteps_this_iter: 34000\n",
      "  timesteps_total: 2404000\n",
      "  training_iteration: 71\n",
      "  trial_id: 00c00974\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 12.4/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8/8 CPUs, 1/1 GPUs, 0.0/7.76 GiB heap, 0.0/2.69 GiB objects<br>Result logdir: /home/qian/ray_results/pong-impala-fast<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                        </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>IMPALA_PongNoFrameskip-v4_00c00974</td><td>RUNNING </td><td>10.236.176.76:13004</td><td style=\"text-align: right;\">  -11.43</td><td style=\"text-align: right;\">         740.658</td><td style=\"text-align: right;\">2404000</td><td style=\"text-align: right;\">    71</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for IMPALA_PongNoFrameskip-v4_00c00974:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-03-11_16-35-06\n",
      "  done: false\n",
      "  episode_len_mean: 8430.57\n",
      "  episode_reward_max: -3.0\n",
      "  episode_reward_mean: -10.87\n",
      "  episode_reward_min: -21.0\n",
      "  episodes_this_iter: 12\n",
      "  episodes_total: 2233\n",
      "  experiment_id: 92f0827d37354e42be7025ff72050188\n",
      "  experiment_tag: '0'\n",
      "  hostname: qian-XPS-8920\n",
      "  info:\n",
      "    learner:\n",
      "      cur_lr: 0.0005000000237487257\n",
      "      entropy: 1444.0928955078125\n",
      "      entropy_coeff: 0.009999999776482582\n",
      "      grad_gnorm: 40.0\n",
      "      model: {}\n",
      "      policy_loss: 65.6397476196289\n",
      "      var_gnorm: 21.370758056640625\n",
      "      vf_explained_var: 0.5713934898376465\n",
      "      vf_loss: 50.24717712402344\n",
      "    learner_queue:\n",
      "      size_count: 2438\n",
      "      size_mean: 0.0\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      size_std: 0.0\n",
      "    num_steps_replayed: 0\n",
      "    num_steps_sampled: 2438000\n",
      "    num_steps_trained: 2437000\n",
      "    num_weight_syncs: 9752\n",
      "    sample_throughput: 3258.063\n",
      "    timing_breakdown:\n",
      "      learner_dequeue_time_ms: 4893.075\n",
      "      learner_grad_time_ms: 132.816\n",
      "      learner_load_time_ms: 17.411\n",
      "      learner_load_wait_time_ms: 176.523\n",
      "      optimizer_step_time_ms: 84.312\n",
      "    train_throughput: 3258.064\n",
      "  iterations_since_restore: 72\n",
      "  node_ip: 10.236.176.76\n",
      "  num_healthy_workers: 7\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.06666666666668\n",
      "    ram_util_percent: 79.59999999999998\n",
      "  pid: 13004\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 7.468265272461299\n",
      "    mean_inference_ms: 2.1969065149244225\n",
      "    mean_processing_ms: 0.44834959716588557\n",
      "  time_since_restore: 751.0814139842987\n",
      "  time_this_iter_s: 10.423156261444092\n",
      "  time_total_s: 751.0814139842987\n",
      "  timestamp: 1583958906\n",
      "  timesteps_since_restore: 2438000\n",
      "  timesteps_this_iter: 34000\n",
      "  timesteps_total: 2438000\n",
      "  training_iteration: 72\n",
      "  trial_id: 00c00974\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 12.4/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8/8 CPUs, 1/1 GPUs, 0.0/7.76 GiB heap, 0.0/2.69 GiB objects<br>Result logdir: /home/qian/ray_results/pong-impala-fast<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                        </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>IMPALA_PongNoFrameskip-v4_00c00974</td><td>RUNNING </td><td>10.236.176.76:13004</td><td style=\"text-align: right;\">  -10.87</td><td style=\"text-align: right;\">         751.081</td><td style=\"text-align: right;\">2438000</td><td style=\"text-align: right;\">    72</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for IMPALA_PongNoFrameskip-v4_00c00974:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-03-11_16-35-16\n",
      "  done: false\n",
      "  episode_len_mean: 8744.77\n",
      "  episode_reward_max: 2.0\n",
      "  episode_reward_mean: -10.16\n",
      "  episode_reward_min: -18.0\n",
      "  episodes_this_iter: 14\n",
      "  episodes_total: 2247\n",
      "  experiment_id: 92f0827d37354e42be7025ff72050188\n",
      "  experiment_tag: '0'\n",
      "  hostname: qian-XPS-8920\n",
      "  info:\n",
      "    learner:\n",
      "      cur_lr: 0.0005000000237487257\n",
      "      entropy: 1421.533935546875\n",
      "      entropy_coeff: 0.009999999776482582\n",
      "      grad_gnorm: 40.0\n",
      "      model: {}\n",
      "      policy_loss: 61.8573112487793\n",
      "      var_gnorm: 21.61539649963379\n",
      "      vf_explained_var: 0.320583701133728\n",
      "      vf_loss: 65.47956085205078\n",
      "    learner_queue:\n",
      "      size_count: 2472\n",
      "      size_mean: 0.0\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      size_std: 0.0\n",
      "    num_steps_replayed: 0\n",
      "    num_steps_sampled: 2472000\n",
      "    num_steps_trained: 2472000\n",
      "    num_weight_syncs: 9889\n",
      "    sample_throughput: 3225.786\n",
      "    timing_breakdown:\n",
      "      learner_dequeue_time_ms: 4890.02\n",
      "      learner_grad_time_ms: 133.845\n",
      "      learner_load_time_ms: 18.06\n",
      "      learner_load_wait_time_ms: 160.699\n",
      "      optimizer_step_time_ms: 74.68\n",
      "    train_throughput: 3320.662\n",
      "  iterations_since_restore: 73\n",
      "  node_ip: 10.236.176.76\n",
      "  num_healthy_workers: 7\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.38666666666668\n",
      "    ram_util_percent: 79.68000000000002\n",
      "  pid: 13004\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 7.470159593328576\n",
      "    mean_inference_ms: 2.198228193824005\n",
      "    mean_processing_ms: 0.44801984410510115\n",
      "  time_since_restore: 761.6089816093445\n",
      "  time_this_iter_s: 10.527567625045776\n",
      "  time_total_s: 761.6089816093445\n",
      "  timestamp: 1583958916\n",
      "  timesteps_since_restore: 2472000\n",
      "  timesteps_this_iter: 34000\n",
      "  timesteps_total: 2472000\n",
      "  training_iteration: 73\n",
      "  trial_id: 00c00974\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 12.4/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8/8 CPUs, 1/1 GPUs, 0.0/7.76 GiB heap, 0.0/2.69 GiB objects<br>Result logdir: /home/qian/ray_results/pong-impala-fast<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                        </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>IMPALA_PongNoFrameskip-v4_00c00974</td><td>RUNNING </td><td>10.236.176.76:13004</td><td style=\"text-align: right;\">  -10.16</td><td style=\"text-align: right;\">         761.609</td><td style=\"text-align: right;\">2472000</td><td style=\"text-align: right;\">    73</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for IMPALA_PongNoFrameskip-v4_00c00974:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-03-11_16-35-27\n",
      "  done: false\n",
      "  episode_len_mean: 9109.88\n",
      "  episode_reward_max: 6.0\n",
      "  episode_reward_mean: -9.03\n",
      "  episode_reward_min: -18.0\n",
      "  episodes_this_iter: 12\n",
      "  episodes_total: 2259\n",
      "  experiment_id: 92f0827d37354e42be7025ff72050188\n",
      "  experiment_tag: '0'\n",
      "  hostname: qian-XPS-8920\n",
      "  info:\n",
      "    learner:\n",
      "      cur_lr: 0.0005000000237487257\n",
      "      entropy: 1509.931396484375\n",
      "      entropy_coeff: 0.009999999776482582\n",
      "      grad_gnorm: 39.999996185302734\n",
      "      model: {}\n",
      "      policy_loss: -4.244772434234619\n",
      "      var_gnorm: 21.84074592590332\n",
      "      vf_explained_var: 0.5316722989082336\n",
      "      vf_loss: 49.547584533691406\n",
      "    learner_queue:\n",
      "      size_count: 2506\n",
      "      size_mean: 0.0\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      size_std: 0.0\n",
      "    num_steps_replayed: 0\n",
      "    num_steps_sampled: 2506000\n",
      "    num_steps_trained: 2505000\n",
      "    num_weight_syncs: 10025\n",
      "    sample_throughput: 3261.172\n",
      "    timing_breakdown:\n",
      "      learner_dequeue_time_ms: 4892.224\n",
      "      learner_grad_time_ms: 135.557\n",
      "      learner_load_time_ms: 18.914\n",
      "      learner_load_wait_time_ms: 176.417\n",
      "      optimizer_step_time_ms: 68.957\n",
      "    train_throughput: 3165.255\n",
      "  iterations_since_restore: 74\n",
      "  node_ip: 10.236.176.76\n",
      "  num_healthy_workers: 7\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.36666666666666\n",
      "    ram_util_percent: 79.72000000000003\n",
      "  pid: 13004\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 7.471477574592909\n",
      "    mean_inference_ms: 2.1991555014453876\n",
      "    mean_processing_ms: 0.44752605954665553\n",
      "  time_since_restore: 772.0205037593842\n",
      "  time_this_iter_s: 10.411522150039673\n",
      "  time_total_s: 772.0205037593842\n",
      "  timestamp: 1583958927\n",
      "  timesteps_since_restore: 2506000\n",
      "  timesteps_this_iter: 34000\n",
      "  timesteps_total: 2506000\n",
      "  training_iteration: 74\n",
      "  trial_id: 00c00974\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 12.4/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8/8 CPUs, 1/1 GPUs, 0.0/7.76 GiB heap, 0.0/2.69 GiB objects<br>Result logdir: /home/qian/ray_results/pong-impala-fast<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                        </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>IMPALA_PongNoFrameskip-v4_00c00974</td><td>RUNNING </td><td>10.236.176.76:13004</td><td style=\"text-align: right;\">   -9.03</td><td style=\"text-align: right;\">         772.021</td><td style=\"text-align: right;\">2506000</td><td style=\"text-align: right;\">    74</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for IMPALA_PongNoFrameskip-v4_00c00974:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-03-11_16-35-37\n",
      "  done: false\n",
      "  episode_len_mean: 9337.5\n",
      "  episode_reward_max: 17.0\n",
      "  episode_reward_mean: -7.62\n",
      "  episode_reward_min: -18.0\n",
      "  episodes_this_iter: 11\n",
      "  episodes_total: 2270\n",
      "  experiment_id: 92f0827d37354e42be7025ff72050188\n",
      "  experiment_tag: '0'\n",
      "  hostname: qian-XPS-8920\n",
      "  info:\n",
      "    learner:\n",
      "      cur_lr: 0.0005000000237487257\n",
      "      entropy: 1469.125732421875\n",
      "      entropy_coeff: 0.009999999776482582\n",
      "      grad_gnorm: 39.999996185302734\n",
      "      model: {}\n",
      "      policy_loss: 13.994120597839355\n",
      "      var_gnorm: 22.10020637512207\n",
      "      vf_explained_var: 0.5342446565628052\n",
      "      vf_loss: 47.779354095458984\n",
      "    learner_queue:\n",
      "      size_count: 2540\n",
      "      size_mean: 0.0\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      size_std: 0.0\n",
      "    num_steps_replayed: 0\n",
      "    num_steps_sampled: 2540000\n",
      "    num_steps_trained: 2539000\n",
      "    num_weight_syncs: 10161\n",
      "    sample_throughput: 3249.283\n",
      "    timing_breakdown:\n",
      "      learner_dequeue_time_ms: 4912.904\n",
      "      learner_grad_time_ms: 133.465\n",
      "      learner_load_time_ms: 18.414\n",
      "      learner_load_wait_time_ms: 162.545\n",
      "      optimizer_step_time_ms: 101.148\n",
      "    train_throughput: 3249.283\n",
      "  iterations_since_restore: 75\n",
      "  node_ip: 10.236.176.76\n",
      "  num_healthy_workers: 7\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.73333333333335\n",
      "    ram_util_percent: 79.73333333333335\n",
      "  pid: 13004\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 7.470282908740819\n",
      "    mean_inference_ms: 2.197371362820911\n",
      "    mean_processing_ms: 0.44686215093095855\n",
      "  time_since_restore: 782.4698529243469\n",
      "  time_this_iter_s: 10.449349164962769\n",
      "  time_total_s: 782.4698529243469\n",
      "  timestamp: 1583958937\n",
      "  timesteps_since_restore: 2540000\n",
      "  timesteps_this_iter: 34000\n",
      "  timesteps_total: 2540000\n",
      "  training_iteration: 75\n",
      "  trial_id: 00c00974\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 12.4/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8/8 CPUs, 1/1 GPUs, 0.0/7.76 GiB heap, 0.0/2.69 GiB objects<br>Result logdir: /home/qian/ray_results/pong-impala-fast<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                        </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>IMPALA_PongNoFrameskip-v4_00c00974</td><td>RUNNING </td><td>10.236.176.76:13004</td><td style=\"text-align: right;\">   -7.62</td><td style=\"text-align: right;\">          782.47</td><td style=\"text-align: right;\">2540000</td><td style=\"text-align: right;\">    75</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for IMPALA_PongNoFrameskip-v4_00c00974:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-03-11_16-35-47\n",
      "  done: false\n",
      "  episode_len_mean: 9846.58\n",
      "  episode_reward_max: 19.0\n",
      "  episode_reward_mean: -5.01\n",
      "  episode_reward_min: -18.0\n",
      "  episodes_this_iter: 17\n",
      "  episodes_total: 2287\n",
      "  experiment_id: 92f0827d37354e42be7025ff72050188\n",
      "  experiment_tag: '0'\n",
      "  hostname: qian-XPS-8920\n",
      "  info:\n",
      "    learner:\n",
      "      cur_lr: 0.0005000000237487257\n",
      "      entropy: 1513.082275390625\n",
      "      entropy_coeff: 0.009999999776482582\n",
      "      grad_gnorm: 40.0\n",
      "      model: {}\n",
      "      policy_loss: -16.564289093017578\n",
      "      var_gnorm: 22.278217315673828\n",
      "      vf_explained_var: 0.6975598335266113\n",
      "      vf_loss: 25.972492218017578\n",
      "    learner_queue:\n",
      "      size_count: 2574\n",
      "      size_mean: 0.0\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      size_std: 0.0\n",
      "    num_steps_replayed: 0\n",
      "    num_steps_sampled: 2574000\n",
      "    num_steps_trained: 2573000\n",
      "    num_weight_syncs: 10297\n",
      "    sample_throughput: 3250.803\n",
      "    timing_breakdown:\n",
      "      learner_dequeue_time_ms: 4890.769\n",
      "      learner_grad_time_ms: 133.954\n",
      "      learner_load_time_ms: 22.855\n",
      "      learner_load_wait_time_ms: 170.79\n",
      "      optimizer_step_time_ms: 78.55\n",
      "    train_throughput: 3250.803\n",
      "  iterations_since_restore: 76\n",
      "  node_ip: 10.236.176.76\n",
      "  num_healthy_workers: 7\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.77333333333334\n",
      "    ram_util_percent: 79.70000000000002\n",
      "  pid: 13004\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 7.471523182933038\n",
      "    mean_inference_ms: 2.198640775141137\n",
      "    mean_processing_ms: 0.44628317599612116\n",
      "  time_since_restore: 792.913477897644\n",
      "  time_this_iter_s: 10.44362497329712\n",
      "  time_total_s: 792.913477897644\n",
      "  timestamp: 1583958947\n",
      "  timesteps_since_restore: 2574000\n",
      "  timesteps_this_iter: 34000\n",
      "  timesteps_total: 2574000\n",
      "  training_iteration: 76\n",
      "  trial_id: 00c00974\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 12.4/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8/8 CPUs, 1/1 GPUs, 0.0/7.76 GiB heap, 0.0/2.69 GiB objects<br>Result logdir: /home/qian/ray_results/pong-impala-fast<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                        </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>IMPALA_PongNoFrameskip-v4_00c00974</td><td>RUNNING </td><td>10.236.176.76:13004</td><td style=\"text-align: right;\">   -5.01</td><td style=\"text-align: right;\">         792.913</td><td style=\"text-align: right;\">2574000</td><td style=\"text-align: right;\">    76</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for IMPALA_PongNoFrameskip-v4_00c00974:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-03-11_16-35-58\n",
      "  done: false\n",
      "  episode_len_mean: 10070.18\n",
      "  episode_reward_max: 19.0\n",
      "  episode_reward_mean: -3.01\n",
      "  episode_reward_min: -18.0\n",
      "  episodes_this_iter: 9\n",
      "  episodes_total: 2296\n",
      "  experiment_id: 92f0827d37354e42be7025ff72050188\n",
      "  experiment_tag: '0'\n",
      "  hostname: qian-XPS-8920\n",
      "  info:\n",
      "    learner:\n",
      "      cur_lr: 0.0005000000237487257\n",
      "      entropy: 1480.385009765625\n",
      "      entropy_coeff: 0.009999999776482582\n",
      "      grad_gnorm: 39.999996185302734\n",
      "      model: {}\n",
      "      policy_loss: 89.63395690917969\n",
      "      var_gnorm: 22.56336212158203\n",
      "      vf_explained_var: 0.7728463411331177\n",
      "      vf_loss: 16.829126358032227\n",
      "    learner_queue:\n",
      "      size_count: 2608\n",
      "      size_mean: 0.0\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      size_std: 0.0\n",
      "    num_steps_replayed: 0\n",
      "    num_steps_sampled: 2608000\n",
      "    num_steps_trained: 2607000\n",
      "    num_weight_syncs: 10433\n",
      "    sample_throughput: 3249.058\n",
      "    timing_breakdown:\n",
      "      learner_dequeue_time_ms: 4899.888\n",
      "      learner_grad_time_ms: 131.684\n",
      "      learner_load_time_ms: 22.937\n",
      "      learner_load_wait_time_ms: 170.586\n",
      "      optimizer_step_time_ms: 88.231\n",
      "    train_throughput: 3249.058\n",
      "  iterations_since_restore: 77\n",
      "  node_ip: 10.236.176.76\n",
      "  num_healthy_workers: 7\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.66000000000001\n",
      "    ram_util_percent: 79.72000000000001\n",
      "  pid: 13004\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 7.471599508608358\n",
      "    mean_inference_ms: 2.198241554490632\n",
      "    mean_processing_ms: 0.44561138904602865\n",
      "  time_since_restore: 803.3637731075287\n",
      "  time_this_iter_s: 10.450295209884644\n",
      "  time_total_s: 803.3637731075287\n",
      "  timestamp: 1583958958\n",
      "  timesteps_since_restore: 2608000\n",
      "  timesteps_this_iter: 34000\n",
      "  timesteps_total: 2608000\n",
      "  training_iteration: 77\n",
      "  trial_id: 00c00974\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 12.4/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8/8 CPUs, 1/1 GPUs, 0.0/7.76 GiB heap, 0.0/2.69 GiB objects<br>Result logdir: /home/qian/ray_results/pong-impala-fast<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                        </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>IMPALA_PongNoFrameskip-v4_00c00974</td><td>RUNNING </td><td>10.236.176.76:13004</td><td style=\"text-align: right;\">   -3.01</td><td style=\"text-align: right;\">         803.364</td><td style=\"text-align: right;\">2608000</td><td style=\"text-align: right;\">    77</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for IMPALA_PongNoFrameskip-v4_00c00974:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-03-11_16-36-08\n",
      "  done: false\n",
      "  episode_len_mean: 10220.15\n",
      "  episode_reward_max: 19.0\n",
      "  episode_reward_mean: 0.03\n",
      "  episode_reward_min: -17.0\n",
      "  episodes_this_iter: 15\n",
      "  episodes_total: 2311\n",
      "  experiment_id: 92f0827d37354e42be7025ff72050188\n",
      "  experiment_tag: '0'\n",
      "  hostname: qian-XPS-8920\n",
      "  info:\n",
      "    learner:\n",
      "      cur_lr: 0.0005000000237487257\n",
      "      entropy: 1530.484130859375\n",
      "      entropy_coeff: 0.009999999776482582\n",
      "      grad_gnorm: 39.99999237060547\n",
      "      model: {}\n",
      "      policy_loss: -30.031715393066406\n",
      "      var_gnorm: 22.78763771057129\n",
      "      vf_explained_var: 0.8096965551376343\n",
      "      vf_loss: 22.15227508544922\n",
      "    learner_queue:\n",
      "      size_count: 2642\n",
      "      size_mean: 0.0\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      size_std: 0.0\n",
      "    num_steps_replayed: 0\n",
      "    num_steps_sampled: 2642000\n",
      "    num_steps_trained: 2641000\n",
      "    num_weight_syncs: 10569\n",
      "    sample_throughput: 3247.165\n",
      "    timing_breakdown:\n",
      "      learner_dequeue_time_ms: 4894.076\n",
      "      learner_grad_time_ms: 135.468\n",
      "      learner_load_time_ms: 25.435\n",
      "      learner_load_wait_time_ms: 166.893\n",
      "      optimizer_step_time_ms: 80.47\n",
      "    train_throughput: 3247.165\n",
      "  iterations_since_restore: 78\n",
      "  node_ip: 10.236.176.76\n",
      "  num_healthy_workers: 7\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.37333333333332\n",
      "    ram_util_percent: 79.71333333333335\n",
      "  pid: 13004\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 7.47188999813667\n",
      "    mean_inference_ms: 2.1991332489268762\n",
      "    mean_processing_ms: 0.44521926163374104\n",
      "  time_since_restore: 813.820271730423\n",
      "  time_this_iter_s: 10.456498622894287\n",
      "  time_total_s: 813.820271730423\n",
      "  timestamp: 1583958968\n",
      "  timesteps_since_restore: 2642000\n",
      "  timesteps_this_iter: 34000\n",
      "  timesteps_total: 2642000\n",
      "  training_iteration: 78\n",
      "  trial_id: 00c00974\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 12.4/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8/8 CPUs, 1/1 GPUs, 0.0/7.76 GiB heap, 0.0/2.69 GiB objects<br>Result logdir: /home/qian/ray_results/pong-impala-fast<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                        </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>IMPALA_PongNoFrameskip-v4_00c00974</td><td>RUNNING </td><td>10.236.176.76:13004</td><td style=\"text-align: right;\">    0.03</td><td style=\"text-align: right;\">          813.82</td><td style=\"text-align: right;\">2642000</td><td style=\"text-align: right;\">    78</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for IMPALA_PongNoFrameskip-v4_00c00974:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-03-11_16-36-19\n",
      "  done: false\n",
      "  episode_len_mean: 10285.63\n",
      "  episode_reward_max: 20.0\n",
      "  episode_reward_mean: 3.94\n",
      "  episode_reward_min: -17.0\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 2332\n",
      "  experiment_id: 92f0827d37354e42be7025ff72050188\n",
      "  experiment_tag: '0'\n",
      "  hostname: qian-XPS-8920\n",
      "  info:\n",
      "    learner:\n",
      "      cur_lr: 0.0005000000237487257\n",
      "      entropy: 1446.756591796875\n",
      "      entropy_coeff: 0.009999999776482582\n",
      "      grad_gnorm: 40.000003814697266\n",
      "      model: {}\n",
      "      policy_loss: 64.6482925415039\n",
      "      var_gnorm: 22.999252319335938\n",
      "      vf_explained_var: 0.8108500838279724\n",
      "      vf_loss: 14.989867210388184\n",
      "    learner_queue:\n",
      "      size_count: 2676\n",
      "      size_mean: 0.0\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      size_std: 0.0\n",
      "    num_steps_replayed: 0\n",
      "    num_steps_sampled: 2676000\n",
      "    num_steps_trained: 2675000\n",
      "    num_weight_syncs: 10705\n",
      "    sample_throughput: 3257.65\n",
      "    timing_breakdown:\n",
      "      learner_dequeue_time_ms: 4890.834\n",
      "      learner_grad_time_ms: 134.793\n",
      "      learner_load_time_ms: 25.874\n",
      "      learner_load_wait_time_ms: 167.076\n",
      "      optimizer_step_time_ms: 69.542\n",
      "    train_throughput: 3257.65\n",
      "  iterations_since_restore: 79\n",
      "  node_ip: 10.236.176.76\n",
      "  num_healthy_workers: 7\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.52666666666667\n",
      "    ram_util_percent: 79.71333333333335\n",
      "  pid: 13004\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 7.473659411684545\n",
      "    mean_inference_ms: 2.200239607889508\n",
      "    mean_processing_ms: 0.4444563882102559\n",
      "  time_since_restore: 824.2428865432739\n",
      "  time_this_iter_s: 10.422614812850952\n",
      "  time_total_s: 824.2428865432739\n",
      "  timestamp: 1583958979\n",
      "  timesteps_since_restore: 2676000\n",
      "  timesteps_this_iter: 34000\n",
      "  timesteps_total: 2676000\n",
      "  training_iteration: 79\n",
      "  trial_id: 00c00974\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 12.4/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8/8 CPUs, 1/1 GPUs, 0.0/7.76 GiB heap, 0.0/2.69 GiB objects<br>Result logdir: /home/qian/ray_results/pong-impala-fast<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                        </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>IMPALA_PongNoFrameskip-v4_00c00974</td><td>RUNNING </td><td>10.236.176.76:13004</td><td style=\"text-align: right;\">    3.94</td><td style=\"text-align: right;\">         824.243</td><td style=\"text-align: right;\">2676000</td><td style=\"text-align: right;\">    79</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for IMPALA_PongNoFrameskip-v4_00c00974:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-03-11_16-36-29\n",
      "  done: false\n",
      "  episode_len_mean: 10186.76\n",
      "  episode_reward_max: 21.0\n",
      "  episode_reward_mean: 6.28\n",
      "  episode_reward_min: -13.0\n",
      "  episodes_this_iter: 10\n",
      "  episodes_total: 2342\n",
      "  experiment_id: 92f0827d37354e42be7025ff72050188\n",
      "  experiment_tag: '0'\n",
      "  hostname: qian-XPS-8920\n",
      "  info:\n",
      "    learner:\n",
      "      cur_lr: 0.0005000000237487257\n",
      "      entropy: 1461.978515625\n",
      "      entropy_coeff: 0.009999999776482582\n",
      "      grad_gnorm: 40.0\n",
      "      model: {}\n",
      "      policy_loss: 49.851898193359375\n",
      "      var_gnorm: 23.16576385498047\n",
      "      vf_explained_var: 0.701384425163269\n",
      "      vf_loss: 21.131362915039062\n",
      "    learner_queue:\n",
      "      size_count: 2710\n",
      "      size_mean: 0.0\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      size_std: 0.0\n",
      "    num_steps_replayed: 0\n",
      "    num_steps_sampled: 2710000\n",
      "    num_steps_trained: 2709000\n",
      "    num_weight_syncs: 10841\n",
      "    sample_throughput: 3265.151\n",
      "    timing_breakdown:\n",
      "      learner_dequeue_time_ms: 4887.278\n",
      "      learner_grad_time_ms: 133.366\n",
      "      learner_load_time_ms: 21.831\n",
      "      learner_load_wait_time_ms: 166.987\n",
      "      optimizer_step_time_ms: 84.916\n",
      "    train_throughput: 3265.151\n",
      "  iterations_since_restore: 80\n",
      "  node_ip: 10.236.176.76\n",
      "  num_healthy_workers: 7\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.12000000000002\n",
      "    ram_util_percent: 79.70000000000002\n",
      "  pid: 13004\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 7.472512108342478\n",
      "    mean_inference_ms: 2.1993549947720963\n",
      "    mean_processing_ms: 0.4439680844399638\n",
      "  time_since_restore: 834.6410672664642\n",
      "  time_this_iter_s: 10.398180723190308\n",
      "  time_total_s: 834.6410672664642\n",
      "  timestamp: 1583958989\n",
      "  timesteps_since_restore: 2710000\n",
      "  timesteps_this_iter: 34000\n",
      "  timesteps_total: 2710000\n",
      "  training_iteration: 80\n",
      "  trial_id: 00c00974\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 12.4/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8/8 CPUs, 1/1 GPUs, 0.0/7.76 GiB heap, 0.0/2.69 GiB objects<br>Result logdir: /home/qian/ray_results/pong-impala-fast<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                        </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>IMPALA_PongNoFrameskip-v4_00c00974</td><td>RUNNING </td><td>10.236.176.76:13004</td><td style=\"text-align: right;\">    6.28</td><td style=\"text-align: right;\">         834.641</td><td style=\"text-align: right;\">2710000</td><td style=\"text-align: right;\">    80</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for IMPALA_PongNoFrameskip-v4_00c00974:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-03-11_16-36-40\n",
      "  done: false\n",
      "  episode_len_mean: 9803.5\n",
      "  episode_reward_max: 21.0\n",
      "  episode_reward_mean: 10.21\n",
      "  episode_reward_min: -12.0\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 2360\n",
      "  experiment_id: 92f0827d37354e42be7025ff72050188\n",
      "  experiment_tag: '0'\n",
      "  hostname: qian-XPS-8920\n",
      "  info:\n",
      "    learner:\n",
      "      cur_lr: 0.0005000000237487257\n",
      "      entropy: 1487.2177734375\n",
      "      entropy_coeff: 0.009999999776482582\n",
      "      grad_gnorm: 40.0\n",
      "      model: {}\n",
      "      policy_loss: 0.7032967805862427\n",
      "      var_gnorm: 23.34427261352539\n",
      "      vf_explained_var: 0.8204511404037476\n",
      "      vf_loss: 21.084558486938477\n",
      "    learner_queue:\n",
      "      size_count: 2743\n",
      "      size_mean: 0.0\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      size_std: 0.0\n",
      "    num_steps_replayed: 0\n",
      "    num_steps_sampled: 2743000\n",
      "    num_steps_trained: 2743000\n",
      "    num_weight_syncs: 10975\n",
      "    sample_throughput: 3170.538\n",
      "    timing_breakdown:\n",
      "      learner_dequeue_time_ms: 4899.322\n",
      "      learner_grad_time_ms: 133.993\n",
      "      learner_load_time_ms: 21.543\n",
      "      learner_load_wait_time_ms: 172.842\n",
      "      optimizer_step_time_ms: 100.679\n",
      "    train_throughput: 3266.615\n",
      "  iterations_since_restore: 81\n",
      "  node_ip: 10.236.176.76\n",
      "  num_healthy_workers: 7\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.63571428571429\n",
      "    ram_util_percent: 79.72857142857144\n",
      "  pid: 13004\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 7.47459245355799\n",
      "    mean_inference_ms: 2.201725913612236\n",
      "    mean_processing_ms: 0.4435935866142738\n",
      "  time_since_restore: 845.0352928638458\n",
      "  time_this_iter_s: 10.394225597381592\n",
      "  time_total_s: 845.0352928638458\n",
      "  timestamp: 1583959000\n",
      "  timesteps_since_restore: 2743000\n",
      "  timesteps_this_iter: 33000\n",
      "  timesteps_total: 2743000\n",
      "  training_iteration: 81\n",
      "  trial_id: 00c00974\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 12.4/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8/8 CPUs, 1/1 GPUs, 0.0/7.76 GiB heap, 0.0/2.69 GiB objects<br>Result logdir: /home/qian/ray_results/pong-impala-fast<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                        </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>IMPALA_PongNoFrameskip-v4_00c00974</td><td>RUNNING </td><td>10.236.176.76:13004</td><td style=\"text-align: right;\">   10.21</td><td style=\"text-align: right;\">         845.035</td><td style=\"text-align: right;\">2743000</td><td style=\"text-align: right;\">    81</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for IMPALA_PongNoFrameskip-v4_00c00974:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-03-11_16-36-50\n",
      "  done: false\n",
      "  episode_len_mean: 9536.26\n",
      "  episode_reward_max: 21.0\n",
      "  episode_reward_mean: 11.95\n",
      "  episode_reward_min: -11.0\n",
      "  episodes_this_iter: 16\n",
      "  episodes_total: 2376\n",
      "  experiment_id: 92f0827d37354e42be7025ff72050188\n",
      "  experiment_tag: '0'\n",
      "  hostname: qian-XPS-8920\n",
      "  info:\n",
      "    learner:\n",
      "      cur_lr: 0.0005000000237487257\n",
      "      entropy: 1514.135986328125\n",
      "      entropy_coeff: 0.009999999776482582\n",
      "      grad_gnorm: 40.000003814697266\n",
      "      model: {}\n",
      "      policy_loss: 6.184528350830078\n",
      "      var_gnorm: 23.506481170654297\n",
      "      vf_explained_var: 0.83053058385849\n",
      "      vf_loss: 13.234180450439453\n",
      "    learner_queue:\n",
      "      size_count: 2778\n",
      "      size_mean: 0.0\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      size_std: 0.0\n",
      "    num_steps_replayed: 0\n",
      "    num_steps_sampled: 2778000\n",
      "    num_steps_trained: 2777000\n",
      "    num_weight_syncs: 11112\n",
      "    sample_throughput: 3340.262\n",
      "    timing_breakdown:\n",
      "      learner_dequeue_time_ms: 4885.673\n",
      "      learner_grad_time_ms: 133.864\n",
      "      learner_load_time_ms: 19.407\n",
      "      learner_load_wait_time_ms: 169.323\n",
      "      optimizer_step_time_ms: 76.622\n",
      "    train_throughput: 3244.826\n",
      "  iterations_since_restore: 82\n",
      "  node_ip: 10.236.176.76\n",
      "  num_healthy_workers: 7\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.56666666666666\n",
      "    ram_util_percent: 79.70000000000002\n",
      "  pid: 13004\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 7.471884574917854\n",
      "    mean_inference_ms: 2.1998547079166\n",
      "    mean_processing_ms: 0.44275332627555253\n",
      "  time_since_restore: 855.4990782737732\n",
      "  time_this_iter_s: 10.463785409927368\n",
      "  time_total_s: 855.4990782737732\n",
      "  timestamp: 1583959010\n",
      "  timesteps_since_restore: 2778000\n",
      "  timesteps_this_iter: 35000\n",
      "  timesteps_total: 2778000\n",
      "  training_iteration: 82\n",
      "  trial_id: 00c00974\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 12.4/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8/8 CPUs, 1/1 GPUs, 0.0/7.76 GiB heap, 0.0/2.69 GiB objects<br>Result logdir: /home/qian/ray_results/pong-impala-fast<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                        </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>IMPALA_PongNoFrameskip-v4_00c00974</td><td>RUNNING </td><td>10.236.176.76:13004</td><td style=\"text-align: right;\">   11.95</td><td style=\"text-align: right;\">         855.499</td><td style=\"text-align: right;\">2778000</td><td style=\"text-align: right;\">    82</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for IMPALA_PongNoFrameskip-v4_00c00974:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-03-11_16-37-01\n",
      "  done: false\n",
      "  episode_len_mean: 9047.82\n",
      "  episode_reward_max: 21.0\n",
      "  episode_reward_mean: 13.89\n",
      "  episode_reward_min: -11.0\n",
      "  episodes_this_iter: 15\n",
      "  episodes_total: 2391\n",
      "  experiment_id: 92f0827d37354e42be7025ff72050188\n",
      "  experiment_tag: '0'\n",
      "  hostname: qian-XPS-8920\n",
      "  info:\n",
      "    learner:\n",
      "      cur_lr: 0.0005000000237487257\n",
      "      entropy: 1473.5335693359375\n",
      "      entropy_coeff: 0.009999999776482582\n",
      "      grad_gnorm: 40.0\n",
      "      model: {}\n",
      "      policy_loss: 36.69145965576172\n",
      "      var_gnorm: 23.617570877075195\n",
      "      vf_explained_var: 0.8510736227035522\n",
      "      vf_loss: 11.523072242736816\n",
      "    learner_queue:\n",
      "      size_count: 2811\n",
      "      size_mean: 0.0\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      size_std: 0.0\n",
      "    num_steps_replayed: 0\n",
      "    num_steps_sampled: 2811000\n",
      "    num_steps_trained: 2811000\n",
      "    num_weight_syncs: 11247\n",
      "    sample_throughput: 3168.535\n",
      "    timing_breakdown:\n",
      "      learner_dequeue_time_ms: 4898.927\n",
      "      learner_grad_time_ms: 134.511\n",
      "      learner_load_time_ms: 18.564\n",
      "      learner_load_wait_time_ms: 174.848\n",
      "      optimizer_step_time_ms: 77.294\n",
      "    train_throughput: 3264.551\n",
      "  iterations_since_restore: 83\n",
      "  node_ip: 10.236.176.76\n",
      "  num_healthy_workers: 7\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.38666666666668\n",
      "    ram_util_percent: 79.70000000000002\n",
      "  pid: 13004\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 7.4735074393492935\n",
      "    mean_inference_ms: 2.2006839308318225\n",
      "    mean_processing_ms: 0.4425827966130308\n",
      "  time_since_restore: 865.8995468616486\n",
      "  time_this_iter_s: 10.400468587875366\n",
      "  time_total_s: 865.8995468616486\n",
      "  timestamp: 1583959021\n",
      "  timesteps_since_restore: 2811000\n",
      "  timesteps_this_iter: 33000\n",
      "  timesteps_total: 2811000\n",
      "  training_iteration: 83\n",
      "  trial_id: 00c00974\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 12.4/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8/8 CPUs, 1/1 GPUs, 0.0/7.76 GiB heap, 0.0/2.69 GiB objects<br>Result logdir: /home/qian/ray_results/pong-impala-fast<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                        </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>IMPALA_PongNoFrameskip-v4_00c00974</td><td>RUNNING </td><td>10.236.176.76:13004</td><td style=\"text-align: right;\">   13.89</td><td style=\"text-align: right;\">           865.9</td><td style=\"text-align: right;\">2811000</td><td style=\"text-align: right;\">    83</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for IMPALA_PongNoFrameskip-v4_00c00974:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-03-11_16-37-11\n",
      "  done: false\n",
      "  episode_len_mean: 8809.74\n",
      "  episode_reward_max: 21.0\n",
      "  episode_reward_mean: 14.73\n",
      "  episode_reward_min: -11.0\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 2409\n",
      "  experiment_id: 92f0827d37354e42be7025ff72050188\n",
      "  experiment_tag: '0'\n",
      "  hostname: qian-XPS-8920\n",
      "  info:\n",
      "    learner:\n",
      "      cur_lr: 0.0005000000237487257\n",
      "      entropy: 1517.971435546875\n",
      "      entropy_coeff: 0.009999999776482582\n",
      "      grad_gnorm: 40.0\n",
      "      model: {}\n",
      "      policy_loss: 23.07825469970703\n",
      "      var_gnorm: 23.749942779541016\n",
      "      vf_explained_var: 0.8453332185745239\n",
      "      vf_loss: 10.912941932678223\n",
      "    learner_queue:\n",
      "      size_count: 2846\n",
      "      size_mean: 0.0\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      size_std: 0.0\n",
      "    num_steps_replayed: 0\n",
      "    num_steps_sampled: 2846000\n",
      "    num_steps_trained: 2845000\n",
      "    num_weight_syncs: 11384\n",
      "    sample_throughput: 3337.591\n",
      "    timing_breakdown:\n",
      "      learner_dequeue_time_ms: 4908.845\n",
      "      learner_grad_time_ms: 136.162\n",
      "      learner_load_time_ms: 17.895\n",
      "      learner_load_wait_time_ms: 157.361\n",
      "      optimizer_step_time_ms: 60.759\n",
      "    train_throughput: 3242.231\n",
      "  iterations_since_restore: 84\n",
      "  node_ip: 10.236.176.76\n",
      "  num_healthy_workers: 7\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.98\n",
      "    ram_util_percent: 79.70000000000002\n",
      "  pid: 13004\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 7.474104174166589\n",
      "    mean_inference_ms: 2.2005250401254317\n",
      "    mean_processing_ms: 0.4419733329853092\n",
      "  time_since_restore: 876.3717396259308\n",
      "  time_this_iter_s: 10.472192764282227\n",
      "  time_total_s: 876.3717396259308\n",
      "  timestamp: 1583959031\n",
      "  timesteps_since_restore: 2846000\n",
      "  timesteps_this_iter: 35000\n",
      "  timesteps_total: 2846000\n",
      "  training_iteration: 84\n",
      "  trial_id: 00c00974\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 12.4/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8/8 CPUs, 1/1 GPUs, 0.0/7.76 GiB heap, 0.0/2.69 GiB objects<br>Result logdir: /home/qian/ray_results/pong-impala-fast<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                        </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>IMPALA_PongNoFrameskip-v4_00c00974</td><td>RUNNING </td><td>10.236.176.76:13004</td><td style=\"text-align: right;\">   14.73</td><td style=\"text-align: right;\">         876.372</td><td style=\"text-align: right;\">2846000</td><td style=\"text-align: right;\">    84</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for IMPALA_PongNoFrameskip-v4_00c00974:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-03-11_16-37-21\n",
      "  done: false\n",
      "  episode_len_mean: 8567.01\n",
      "  episode_reward_max: 21.0\n",
      "  episode_reward_mean: 15.87\n",
      "  episode_reward_min: -11.0\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 2427\n",
      "  experiment_id: 92f0827d37354e42be7025ff72050188\n",
      "  experiment_tag: '0'\n",
      "  hostname: qian-XPS-8920\n",
      "  info:\n",
      "    learner:\n",
      "      cur_lr: 0.0005000000237487257\n",
      "      entropy: 1566.11181640625\n",
      "      entropy_coeff: 0.009999999776482582\n",
      "      grad_gnorm: 40.0\n",
      "      model: {}\n",
      "      policy_loss: 83.84220886230469\n",
      "      var_gnorm: 23.847614288330078\n",
      "      vf_explained_var: 0.8566300868988037\n",
      "      vf_loss: 11.467315673828125\n",
      "    learner_queue:\n",
      "      size_count: 2879\n",
      "      size_mean: 0.0\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      size_std: 0.0\n",
      "    num_steps_replayed: 0\n",
      "    num_steps_sampled: 2879000\n",
      "    num_steps_trained: 2879000\n",
      "    num_weight_syncs: 11519\n",
      "    sample_throughput: 3155.019\n",
      "    timing_breakdown:\n",
      "      learner_dequeue_time_ms: 4901.352\n",
      "      learner_grad_time_ms: 133.903\n",
      "      learner_load_time_ms: 28.198\n",
      "      learner_load_wait_time_ms: 154.926\n",
      "      optimizer_step_time_ms: 83.859\n",
      "    train_throughput: 3250.625\n",
      "  iterations_since_restore: 85\n",
      "  node_ip: 10.236.176.76\n",
      "  num_healthy_workers: 7\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.34666666666666\n",
      "    ram_util_percent: 79.87333333333335\n",
      "  pid: 13004\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 7.473796168160336\n",
      "    mean_inference_ms: 2.2015283976941893\n",
      "    mean_processing_ms: 0.4416848174341536\n",
      "  time_since_restore: 886.8174376487732\n",
      "  time_this_iter_s: 10.445698022842407\n",
      "  time_total_s: 886.8174376487732\n",
      "  timestamp: 1583959041\n",
      "  timesteps_since_restore: 2879000\n",
      "  timesteps_this_iter: 33000\n",
      "  timesteps_total: 2879000\n",
      "  training_iteration: 85\n",
      "  trial_id: 00c00974\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 12.5/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8/8 CPUs, 1/1 GPUs, 0.0/7.76 GiB heap, 0.0/2.69 GiB objects<br>Result logdir: /home/qian/ray_results/pong-impala-fast<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                        </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>IMPALA_PongNoFrameskip-v4_00c00974</td><td>RUNNING </td><td>10.236.176.76:13004</td><td style=\"text-align: right;\">   15.87</td><td style=\"text-align: right;\">         886.817</td><td style=\"text-align: right;\">2879000</td><td style=\"text-align: right;\">    85</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for IMPALA_PongNoFrameskip-v4_00c00974:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-03-11_16-37-32\n",
      "  done: false\n",
      "  episode_len_mean: 8401.45\n",
      "  episode_reward_max: 20.0\n",
      "  episode_reward_mean: 16.18\n",
      "  episode_reward_min: -11.0\n",
      "  episodes_this_iter: 14\n",
      "  episodes_total: 2441\n",
      "  experiment_id: 92f0827d37354e42be7025ff72050188\n",
      "  experiment_tag: '0'\n",
      "  hostname: qian-XPS-8920\n",
      "  info:\n",
      "    learner:\n",
      "      cur_lr: 0.0005000000237487257\n",
      "      entropy: 1469.389892578125\n",
      "      entropy_coeff: 0.009999999776482582\n",
      "      grad_gnorm: 40.0\n",
      "      model: {}\n",
      "      policy_loss: -6.792727470397949\n",
      "      var_gnorm: 23.986248016357422\n",
      "      vf_explained_var: 0.7560669779777527\n",
      "      vf_loss: 14.159992218017578\n",
      "    learner_queue:\n",
      "      size_count: 2913\n",
      "      size_mean: 0.0\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      size_std: 0.0\n",
      "    num_steps_replayed: 0\n",
      "    num_steps_sampled: 2913000\n",
      "    num_steps_trained: 2913000\n",
      "    num_weight_syncs: 11653\n",
      "    sample_throughput: 3228.809\n",
      "    timing_breakdown:\n",
      "      learner_dequeue_time_ms: 4888.254\n",
      "      learner_grad_time_ms: 134.735\n",
      "      learner_load_time_ms: 30.882\n",
      "      learner_load_wait_time_ms: 150.026\n",
      "      optimizer_step_time_ms: 79.781\n",
      "    train_throughput: 3228.809\n",
      "  iterations_since_restore: 86\n",
      "  node_ip: 10.236.176.76\n",
      "  num_healthy_workers: 7\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.16\n",
      "    ram_util_percent: 80.13333333333331\n",
      "  pid: 13004\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 7.474924314192711\n",
      "    mean_inference_ms: 2.2011664653919882\n",
      "    mean_processing_ms: 0.4412800933952246\n",
      "  time_since_restore: 897.3327054977417\n",
      "  time_this_iter_s: 10.515267848968506\n",
      "  time_total_s: 897.3327054977417\n",
      "  timestamp: 1583959052\n",
      "  timesteps_since_restore: 2913000\n",
      "  timesteps_this_iter: 34000\n",
      "  timesteps_total: 2913000\n",
      "  training_iteration: 86\n",
      "  trial_id: 00c00974\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 12.5/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8/8 CPUs, 1/1 GPUs, 0.0/7.76 GiB heap, 0.0/2.69 GiB objects<br>Result logdir: /home/qian/ray_results/pong-impala-fast<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                        </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>IMPALA_PongNoFrameskip-v4_00c00974</td><td>RUNNING </td><td>10.236.176.76:13004</td><td style=\"text-align: right;\">   16.18</td><td style=\"text-align: right;\">         897.333</td><td style=\"text-align: right;\">2913000</td><td style=\"text-align: right;\">    86</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for IMPALA_PongNoFrameskip-v4_00c00974:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-03-11_16-37-42\n",
      "  done: false\n",
      "  episode_len_mean: 8369.8\n",
      "  episode_reward_max: 20.0\n",
      "  episode_reward_mean: 16.23\n",
      "  episode_reward_min: -11.0\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 2459\n",
      "  experiment_id: 92f0827d37354e42be7025ff72050188\n",
      "  experiment_tag: '0'\n",
      "  hostname: qian-XPS-8920\n",
      "  info:\n",
      "    learner:\n",
      "      cur_lr: 0.0005000000237487257\n",
      "      entropy: 1561.93896484375\n",
      "      entropy_coeff: 0.009999999776482582\n",
      "      grad_gnorm: 40.0\n",
      "      model: {}\n",
      "      policy_loss: 8.547067642211914\n",
      "      var_gnorm: 24.092771530151367\n",
      "      vf_explained_var: 0.8324878811836243\n",
      "      vf_loss: 22.544416427612305\n",
      "    learner_queue:\n",
      "      size_count: 2947\n",
      "      size_mean: 0.0\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      size_std: 0.0\n",
      "    num_steps_replayed: 0\n",
      "    num_steps_sampled: 2947000\n",
      "    num_steps_trained: 2946000\n",
      "    num_weight_syncs: 11788\n",
      "    sample_throughput: 3269.955\n",
      "    timing_breakdown:\n",
      "      learner_dequeue_time_ms: 4916.437\n",
      "      learner_grad_time_ms: 133.291\n",
      "      learner_load_time_ms: 30.739\n",
      "      learner_load_wait_time_ms: 170.72\n",
      "      optimizer_step_time_ms: 74.633\n",
      "    train_throughput: 3173.78\n",
      "  iterations_since_restore: 87\n",
      "  node_ip: 10.236.176.76\n",
      "  num_healthy_workers: 7\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.36666666666669\n",
      "    ram_util_percent: 80.09999999999998\n",
      "  pid: 13004\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 7.47517615455194\n",
      "    mean_inference_ms: 2.200183945913748\n",
      "    mean_processing_ms: 0.44068610883232284\n",
      "  time_since_restore: 907.7162218093872\n",
      "  time_this_iter_s: 10.383516311645508\n",
      "  time_total_s: 907.7162218093872\n",
      "  timestamp: 1583959062\n",
      "  timesteps_since_restore: 2947000\n",
      "  timesteps_this_iter: 34000\n",
      "  timesteps_total: 2947000\n",
      "  training_iteration: 87\n",
      "  trial_id: 00c00974\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 12.5/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8/8 CPUs, 1/1 GPUs, 0.0/7.76 GiB heap, 0.0/2.69 GiB objects<br>Result logdir: /home/qian/ray_results/pong-impala-fast<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                        </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>IMPALA_PongNoFrameskip-v4_00c00974</td><td>RUNNING </td><td>10.236.176.76:13004</td><td style=\"text-align: right;\">   16.23</td><td style=\"text-align: right;\">         907.716</td><td style=\"text-align: right;\">2947000</td><td style=\"text-align: right;\">    87</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for IMPALA_PongNoFrameskip-v4_00c00974:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-03-11_16-37-53\n",
      "  done: false\n",
      "  episode_len_mean: 8261.01\n",
      "  episode_reward_max: 21.0\n",
      "  episode_reward_mean: 16.69\n",
      "  episode_reward_min: -1.0\n",
      "  episodes_this_iter: 16\n",
      "  episodes_total: 2475\n",
      "  experiment_id: 92f0827d37354e42be7025ff72050188\n",
      "  experiment_tag: '0'\n",
      "  hostname: qian-XPS-8920\n",
      "  info:\n",
      "    learner:\n",
      "      cur_lr: 0.0005000000237487257\n",
      "      entropy: 1591.002197265625\n",
      "      entropy_coeff: 0.009999999776482582\n",
      "      grad_gnorm: 40.00000762939453\n",
      "      model: {}\n",
      "      policy_loss: 77.11076354980469\n",
      "      var_gnorm: 24.15311622619629\n",
      "      vf_explained_var: 0.86365807056427\n",
      "      vf_loss: 7.802875518798828\n",
      "    learner_queue:\n",
      "      size_count: 2980\n",
      "      size_mean: 0.0\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      size_std: 0.0\n",
      "    num_steps_replayed: 0\n",
      "    num_steps_sampled: 2980000\n",
      "    num_steps_trained: 2980000\n",
      "    num_weight_syncs: 11923\n",
      "    sample_throughput: 3166.961\n",
      "    timing_breakdown:\n",
      "      learner_dequeue_time_ms: 4915.222\n",
      "      learner_grad_time_ms: 135.988\n",
      "      learner_load_time_ms: 31.243\n",
      "      learner_load_wait_time_ms: 168.768\n",
      "      optimizer_step_time_ms: 76.223\n",
      "    train_throughput: 3262.929\n",
      "  iterations_since_restore: 88\n",
      "  node_ip: 10.236.176.76\n",
      "  num_healthy_workers: 7\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.03999999999999\n",
      "    ram_util_percent: 80.12666666666665\n",
      "  pid: 13004\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 7.475480733487744\n",
      "    mean_inference_ms: 2.2004042944135924\n",
      "    mean_processing_ms: 0.4404485382620213\n",
      "  time_since_restore: 918.1218421459198\n",
      "  time_this_iter_s: 10.405620336532593\n",
      "  time_total_s: 918.1218421459198\n",
      "  timestamp: 1583959073\n",
      "  timesteps_since_restore: 2980000\n",
      "  timesteps_this_iter: 33000\n",
      "  timesteps_total: 2980000\n",
      "  training_iteration: 88\n",
      "  trial_id: 00c00974\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 12.5/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8/8 CPUs, 1/1 GPUs, 0.0/7.76 GiB heap, 0.0/2.69 GiB objects<br>Result logdir: /home/qian/ray_results/pong-impala-fast<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                        </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>IMPALA_PongNoFrameskip-v4_00c00974</td><td>RUNNING </td><td>10.236.176.76:13004</td><td style=\"text-align: right;\">   16.69</td><td style=\"text-align: right;\">         918.122</td><td style=\"text-align: right;\">2980000</td><td style=\"text-align: right;\">    88</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for IMPALA_PongNoFrameskip-v4_00c00974:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-03-11_16-38-03\n",
      "  done: false\n",
      "  episode_len_mean: 8323.41\n",
      "  episode_reward_max: 21.0\n",
      "  episode_reward_mean: 16.35\n",
      "  episode_reward_min: -1.0\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 2493\n",
      "  experiment_id: 92f0827d37354e42be7025ff72050188\n",
      "  experiment_tag: '0'\n",
      "  hostname: qian-XPS-8920\n",
      "  info:\n",
      "    learner:\n",
      "      cur_lr: 0.0005000000237487257\n",
      "      entropy: 1525.027587890625\n",
      "      entropy_coeff: 0.009999999776482582\n",
      "      grad_gnorm: 40.0\n",
      "      model: {}\n",
      "      policy_loss: 6.618081569671631\n",
      "      var_gnorm: 24.219743728637695\n",
      "      vf_explained_var: 0.8781623840332031\n",
      "      vf_loss: 15.151223182678223\n",
      "    learner_queue:\n",
      "      size_count: 3014\n",
      "      size_mean: 0.0\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      size_std: 0.0\n",
      "    num_steps_replayed: 0\n",
      "    num_steps_sampled: 3014000\n",
      "    num_steps_trained: 3014000\n",
      "    num_weight_syncs: 12059\n",
      "    sample_throughput: 3248.684\n",
      "    timing_breakdown:\n",
      "      learner_dequeue_time_ms: 4924.877\n",
      "      learner_grad_time_ms: 133.849\n",
      "      learner_load_time_ms: 21.036\n",
      "      learner_load_wait_time_ms: 166.002\n",
      "      optimizer_step_time_ms: 78.029\n",
      "    train_throughput: 3248.684\n",
      "  iterations_since_restore: 89\n",
      "  node_ip: 10.236.176.76\n",
      "  num_healthy_workers: 7\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.18\n",
      "    ram_util_percent: 80.10666666666665\n",
      "  pid: 13004\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 7.4762827846216044\n",
      "    mean_inference_ms: 2.2007545005409512\n",
      "    mean_processing_ms: 0.4399504874759952\n",
      "  time_since_restore: 928.5730872154236\n",
      "  time_this_iter_s: 10.451245069503784\n",
      "  time_total_s: 928.5730872154236\n",
      "  timestamp: 1583959083\n",
      "  timesteps_since_restore: 3014000\n",
      "  timesteps_this_iter: 34000\n",
      "  timesteps_total: 3014000\n",
      "  training_iteration: 89\n",
      "  trial_id: 00c00974\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 12.5/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8/8 CPUs, 1/1 GPUs, 0.0/7.76 GiB heap, 0.0/2.69 GiB objects<br>Result logdir: /home/qian/ray_results/pong-impala-fast<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                        </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>IMPALA_PongNoFrameskip-v4_00c00974</td><td>RUNNING </td><td>10.236.176.76:13004</td><td style=\"text-align: right;\">   16.35</td><td style=\"text-align: right;\">         928.573</td><td style=\"text-align: right;\">3014000</td><td style=\"text-align: right;\">    89</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for IMPALA_PongNoFrameskip-v4_00c00974:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-03-11_16-38-14\n",
      "  done: false\n",
      "  episode_len_mean: 8223.7\n",
      "  episode_reward_max: 21.0\n",
      "  episode_reward_mean: 16.53\n",
      "  episode_reward_min: 2.0\n",
      "  episodes_this_iter: 17\n",
      "  episodes_total: 2510\n",
      "  experiment_id: 92f0827d37354e42be7025ff72050188\n",
      "  experiment_tag: '0'\n",
      "  hostname: qian-XPS-8920\n",
      "  info:\n",
      "    learner:\n",
      "      cur_lr: 0.0005000000237487257\n",
      "      entropy: 1539.1475830078125\n",
      "      entropy_coeff: 0.009999999776482582\n",
      "      grad_gnorm: 39.99999237060547\n",
      "      model: {}\n",
      "      policy_loss: 49.752925872802734\n",
      "      var_gnorm: 24.320905685424805\n",
      "      vf_explained_var: 0.8952925205230713\n",
      "      vf_loss: 14.454394340515137\n",
      "    learner_queue:\n",
      "      size_count: 3048\n",
      "      size_mean: 0.0\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      size_std: 0.0\n",
      "    num_steps_replayed: 0\n",
      "    num_steps_sampled: 3048000\n",
      "    num_steps_trained: 3048000\n",
      "    num_weight_syncs: 12195\n",
      "    sample_throughput: 3248.242\n",
      "    timing_breakdown:\n",
      "      learner_dequeue_time_ms: 4919.681\n",
      "      learner_grad_time_ms: 132.692\n",
      "      learner_load_time_ms: 20.576\n",
      "      learner_load_wait_time_ms: 159.616\n",
      "      optimizer_step_time_ms: 90.968\n",
      "    train_throughput: 3248.243\n",
      "  iterations_since_restore: 90\n",
      "  node_ip: 10.236.176.76\n",
      "  num_healthy_workers: 7\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.29333333333332\n",
      "    ram_util_percent: 80.11333333333332\n",
      "  pid: 13004\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 7.47611219114753\n",
      "    mean_inference_ms: 2.200056345707736\n",
      "    mean_processing_ms: 0.4396334240389698\n",
      "  time_since_restore: 939.0259299278259\n",
      "  time_this_iter_s: 10.452842712402344\n",
      "  time_total_s: 939.0259299278259\n",
      "  timestamp: 1583959094\n",
      "  timesteps_since_restore: 3048000\n",
      "  timesteps_this_iter: 34000\n",
      "  timesteps_total: 3048000\n",
      "  training_iteration: 90\n",
      "  trial_id: 00c00974\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 12.5/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8/8 CPUs, 1/1 GPUs, 0.0/7.76 GiB heap, 0.0/2.69 GiB objects<br>Result logdir: /home/qian/ray_results/pong-impala-fast<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                        </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>IMPALA_PongNoFrameskip-v4_00c00974</td><td>RUNNING </td><td>10.236.176.76:13004</td><td style=\"text-align: right;\">   16.53</td><td style=\"text-align: right;\">         939.026</td><td style=\"text-align: right;\">3048000</td><td style=\"text-align: right;\">    90</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for IMPALA_PongNoFrameskip-v4_00c00974:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-03-11_16-38-24\n",
      "  done: false\n",
      "  episode_len_mean: 8137.28\n",
      "  episode_reward_max: 21.0\n",
      "  episode_reward_mean: 16.8\n",
      "  episode_reward_min: 2.0\n",
      "  episodes_this_iter: 14\n",
      "  episodes_total: 2524\n",
      "  experiment_id: 92f0827d37354e42be7025ff72050188\n",
      "  experiment_tag: '0'\n",
      "  hostname: qian-XPS-8920\n",
      "  info:\n",
      "    learner:\n",
      "      cur_lr: 0.0005000000237487257\n",
      "      entropy: 1564.6558837890625\n",
      "      entropy_coeff: 0.009999999776482582\n",
      "      grad_gnorm: 40.0\n",
      "      model: {}\n",
      "      policy_loss: 50.011470794677734\n",
      "      var_gnorm: 24.412708282470703\n",
      "      vf_explained_var: 0.8761122226715088\n",
      "      vf_loss: 7.98298978805542\n",
      "    learner_queue:\n",
      "      size_count: 3082\n",
      "      size_mean: 0.0\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      size_std: 0.0\n",
      "    num_steps_replayed: 0\n",
      "    num_steps_sampled: 3082000\n",
      "    num_steps_trained: 3082000\n",
      "    num_weight_syncs: 12330\n",
      "    sample_throughput: 3273.135\n",
      "    timing_breakdown:\n",
      "      learner_dequeue_time_ms: 4925.35\n",
      "      learner_grad_time_ms: 135.371\n",
      "      learner_load_time_ms: 17.538\n",
      "      learner_load_wait_time_ms: 161.321\n",
      "      optimizer_step_time_ms: 77.726\n",
      "    train_throughput: 3273.135\n",
      "  iterations_since_restore: 91\n",
      "  node_ip: 10.236.176.76\n",
      "  num_healthy_workers: 7\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.66666666666667\n",
      "    ram_util_percent: 80.11333333333332\n",
      "  pid: 13004\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 7.477619498575863\n",
      "    mean_inference_ms: 2.202439948878841\n",
      "    mean_processing_ms: 0.43975951259359014\n",
      "  time_since_restore: 949.4007165431976\n",
      "  time_this_iter_s: 10.374786615371704\n",
      "  time_total_s: 949.4007165431976\n",
      "  timestamp: 1583959104\n",
      "  timesteps_since_restore: 3082000\n",
      "  timesteps_this_iter: 34000\n",
      "  timesteps_total: 3082000\n",
      "  training_iteration: 91\n",
      "  trial_id: 00c00974\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 12.5/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8/8 CPUs, 1/1 GPUs, 0.0/7.76 GiB heap, 0.0/2.69 GiB objects<br>Result logdir: /home/qian/ray_results/pong-impala-fast<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                        </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>IMPALA_PongNoFrameskip-v4_00c00974</td><td>RUNNING </td><td>10.236.176.76:13004</td><td style=\"text-align: right;\">    16.8</td><td style=\"text-align: right;\">         949.401</td><td style=\"text-align: right;\">3082000</td><td style=\"text-align: right;\">    91</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for IMPALA_PongNoFrameskip-v4_00c00974:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-03-11_16-38-35\n",
      "  done: false\n",
      "  episode_len_mean: 8149.07\n",
      "  episode_reward_max: 21.0\n",
      "  episode_reward_mean: 16.81\n",
      "  episode_reward_min: 2.0\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 2545\n",
      "  experiment_id: 92f0827d37354e42be7025ff72050188\n",
      "  experiment_tag: '0'\n",
      "  hostname: qian-XPS-8920\n",
      "  info:\n",
      "    learner:\n",
      "      cur_lr: 0.0005000000237487257\n",
      "      entropy: 1539.48486328125\n",
      "      entropy_coeff: 0.009999999776482582\n",
      "      grad_gnorm: 39.999996185302734\n",
      "      model: {}\n",
      "      policy_loss: -34.80784606933594\n",
      "      var_gnorm: 24.493396759033203\n",
      "      vf_explained_var: 0.8608946800231934\n",
      "      vf_loss: 21.386823654174805\n",
      "    learner_queue:\n",
      "      size_count: 3116\n",
      "      size_mean: 0.0\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      size_std: 0.0\n",
      "    num_steps_replayed: 0\n",
      "    num_steps_sampled: 3116000\n",
      "    num_steps_trained: 3115000\n",
      "    num_weight_syncs: 12466\n",
      "    sample_throughput: 3268.975\n",
      "    timing_breakdown:\n",
      "      learner_dequeue_time_ms: 4912.088\n",
      "      learner_grad_time_ms: 133.27\n",
      "      learner_load_time_ms: 18.681\n",
      "      learner_load_wait_time_ms: 167.402\n",
      "      optimizer_step_time_ms: 71.97\n",
      "    train_throughput: 3172.829\n",
      "  iterations_since_restore: 92\n",
      "  node_ip: 10.236.176.76\n",
      "  num_healthy_workers: 7\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 93.04285714285716\n",
      "    ram_util_percent: 80.1\n",
      "  pid: 13004\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 7.4765138480700015\n",
      "    mean_inference_ms: 2.200356714380419\n",
      "    mean_processing_ms: 0.43903115641992935\n",
      "  time_since_restore: 959.7884585857391\n",
      "  time_this_iter_s: 10.387742042541504\n",
      "  time_total_s: 959.7884585857391\n",
      "  timestamp: 1583959115\n",
      "  timesteps_since_restore: 3116000\n",
      "  timesteps_this_iter: 34000\n",
      "  timesteps_total: 3116000\n",
      "  training_iteration: 92\n",
      "  trial_id: 00c00974\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 12.5/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8/8 CPUs, 1/1 GPUs, 0.0/7.76 GiB heap, 0.0/2.69 GiB objects<br>Result logdir: /home/qian/ray_results/pong-impala-fast<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                        </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>IMPALA_PongNoFrameskip-v4_00c00974</td><td>RUNNING </td><td>10.236.176.76:13004</td><td style=\"text-align: right;\">   16.81</td><td style=\"text-align: right;\">         959.788</td><td style=\"text-align: right;\">3116000</td><td style=\"text-align: right;\">    92</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for IMPALA_PongNoFrameskip-v4_00c00974:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-03-11_16-38-45\n",
      "  done: false\n",
      "  episode_len_mean: 8109.07\n",
      "  episode_reward_max: 21.0\n",
      "  episode_reward_mean: 17.07\n",
      "  episode_reward_min: 2.0\n",
      "  episodes_this_iter: 14\n",
      "  episodes_total: 2559\n",
      "  experiment_id: 92f0827d37354e42be7025ff72050188\n",
      "  experiment_tag: '0'\n",
      "  hostname: qian-XPS-8920\n",
      "  info:\n",
      "    learner:\n",
      "      cur_lr: 0.0005000000237487257\n",
      "      entropy: 1533.9566650390625\n",
      "      entropy_coeff: 0.009999999776482582\n",
      "      grad_gnorm: 40.000003814697266\n",
      "      model: {}\n",
      "      policy_loss: 17.922990798950195\n",
      "      var_gnorm: 24.561710357666016\n",
      "      vf_explained_var: 0.8764496445655823\n",
      "      vf_loss: 14.743266105651855\n",
      "    learner_queue:\n",
      "      size_count: 3150\n",
      "      size_mean: 0.0\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      size_std: 0.0\n",
      "    num_steps_replayed: 0\n",
      "    num_steps_sampled: 3150000\n",
      "    num_steps_trained: 3149000\n",
      "    num_weight_syncs: 12601\n",
      "    sample_throughput: 3244.127\n",
      "    timing_breakdown:\n",
      "      learner_dequeue_time_ms: 4904.472\n",
      "      learner_grad_time_ms: 133.875\n",
      "      learner_load_time_ms: 18.382\n",
      "      learner_load_wait_time_ms: 177.174\n",
      "      optimizer_step_time_ms: 91.437\n",
      "    train_throughput: 3244.127\n",
      "  iterations_since_restore: 93\n",
      "  node_ip: 10.236.176.76\n",
      "  num_healthy_workers: 7\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.64000000000001\n",
      "    ram_util_percent: 80.12666666666665\n",
      "  pid: 13004\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 7.477964936822781\n",
      "    mean_inference_ms: 2.2023002813803774\n",
      "    mean_processing_ms: 0.4391842558315275\n",
      "  time_since_restore: 970.2562038898468\n",
      "  time_this_iter_s: 10.467745304107666\n",
      "  time_total_s: 970.2562038898468\n",
      "  timestamp: 1583959125\n",
      "  timesteps_since_restore: 3150000\n",
      "  timesteps_this_iter: 34000\n",
      "  timesteps_total: 3150000\n",
      "  training_iteration: 93\n",
      "  trial_id: 00c00974\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 12.5/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8/8 CPUs, 1/1 GPUs, 0.0/7.76 GiB heap, 0.0/2.69 GiB objects<br>Result logdir: /home/qian/ray_results/pong-impala-fast<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                        </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>IMPALA_PongNoFrameskip-v4_00c00974</td><td>RUNNING </td><td>10.236.176.76:13004</td><td style=\"text-align: right;\">   17.07</td><td style=\"text-align: right;\">         970.256</td><td style=\"text-align: right;\">3150000</td><td style=\"text-align: right;\">    93</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for IMPALA_PongNoFrameskip-v4_00c00974:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-03-11_16-38-55\n",
      "  done: false\n",
      "  episode_len_mean: 8160.93\n",
      "  episode_reward_max: 21.0\n",
      "  episode_reward_mean: 16.84\n",
      "  episode_reward_min: -9.0\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 2577\n",
      "  experiment_id: 92f0827d37354e42be7025ff72050188\n",
      "  experiment_tag: '0'\n",
      "  hostname: qian-XPS-8920\n",
      "  info:\n",
      "    learner:\n",
      "      cur_lr: 0.0005000000237487257\n",
      "      entropy: 1555.805908203125\n",
      "      entropy_coeff: 0.009999999776482582\n",
      "      grad_gnorm: 40.0\n",
      "      model: {}\n",
      "      policy_loss: 22.33987808227539\n",
      "      var_gnorm: 24.623632431030273\n",
      "      vf_explained_var: 0.73470538854599\n",
      "      vf_loss: 26.251461029052734\n",
      "    learner_queue:\n",
      "      size_count: 3184\n",
      "      size_mean: 0.0\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      size_std: 0.0\n",
      "    num_steps_replayed: 0\n",
      "    num_steps_sampled: 3184000\n",
      "    num_steps_trained: 3183000\n",
      "    num_weight_syncs: 12737\n",
      "    sample_throughput: 3251.432\n",
      "    timing_breakdown:\n",
      "      learner_dequeue_time_ms: 4905.194\n",
      "      learner_grad_time_ms: 134.748\n",
      "      learner_load_time_ms: 18.707\n",
      "      learner_load_wait_time_ms: 167.283\n",
      "      optimizer_step_time_ms: 74.663\n",
      "    train_throughput: 3251.432\n",
      "  iterations_since_restore: 94\n",
      "  node_ip: 10.236.176.76\n",
      "  num_healthy_workers: 7\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.42666666666668\n",
      "    ram_util_percent: 80.09999999999998\n",
      "  pid: 13004\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 7.478185790625633\n",
      "    mean_inference_ms: 2.201596106134305\n",
      "    mean_processing_ms: 0.4386975726838913\n",
      "  time_since_restore: 980.7006177902222\n",
      "  time_this_iter_s: 10.444413900375366\n",
      "  time_total_s: 980.7006177902222\n",
      "  timestamp: 1583959135\n",
      "  timesteps_since_restore: 3184000\n",
      "  timesteps_this_iter: 34000\n",
      "  timesteps_total: 3184000\n",
      "  training_iteration: 94\n",
      "  trial_id: 00c00974\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 12.5/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8/8 CPUs, 1/1 GPUs, 0.0/7.76 GiB heap, 0.0/2.69 GiB objects<br>Result logdir: /home/qian/ray_results/pong-impala-fast<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                        </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>IMPALA_PongNoFrameskip-v4_00c00974</td><td>RUNNING </td><td>10.236.176.76:13004</td><td style=\"text-align: right;\">   16.84</td><td style=\"text-align: right;\">         980.701</td><td style=\"text-align: right;\">3184000</td><td style=\"text-align: right;\">    94</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for IMPALA_PongNoFrameskip-v4_00c00974:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-03-11_16-39-06\n",
      "  done: false\n",
      "  episode_len_mean: 8206.63\n",
      "  episode_reward_max: 21.0\n",
      "  episode_reward_mean: 16.89\n",
      "  episode_reward_min: -9.0\n",
      "  episodes_this_iter: 13\n",
      "  episodes_total: 2590\n",
      "  experiment_id: 92f0827d37354e42be7025ff72050188\n",
      "  experiment_tag: '0'\n",
      "  hostname: qian-XPS-8920\n",
      "  info:\n",
      "    learner:\n",
      "      cur_lr: 0.0005000000237487257\n",
      "      entropy: 1539.8414306640625\n",
      "      entropy_coeff: 0.009999999776482582\n",
      "      grad_gnorm: 40.000003814697266\n",
      "      model: {}\n",
      "      policy_loss: 26.772371292114258\n",
      "      var_gnorm: 24.679847717285156\n",
      "      vf_explained_var: 0.8579164147377014\n",
      "      vf_loss: 5.828644752502441\n",
      "    learner_queue:\n",
      "      size_count: 3218\n",
      "      size_mean: 0.0\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      size_std: 0.0\n",
      "    num_steps_replayed: 0\n",
      "    num_steps_sampled: 3218000\n",
      "    num_steps_trained: 3217000\n",
      "    num_weight_syncs: 12873\n",
      "    sample_throughput: 3247.783\n",
      "    timing_breakdown:\n",
      "      learner_dequeue_time_ms: 4888.016\n",
      "      learner_grad_time_ms: 134.347\n",
      "      learner_load_time_ms: 21.448\n",
      "      learner_load_wait_time_ms: 171.734\n",
      "      optimizer_step_time_ms: 81.558\n",
      "    train_throughput: 3247.783\n",
      "  iterations_since_restore: 95\n",
      "  node_ip: 10.236.176.76\n",
      "  num_healthy_workers: 7\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.61333333333333\n",
      "    ram_util_percent: 80.12666666666665\n",
      "  pid: 13004\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 7.477837430268671\n",
      "    mean_inference_ms: 2.202262218360913\n",
      "    mean_processing_ms: 0.4386194945189102\n",
      "  time_since_restore: 991.154620885849\n",
      "  time_this_iter_s: 10.454003095626831\n",
      "  time_total_s: 991.154620885849\n",
      "  timestamp: 1583959146\n",
      "  timesteps_since_restore: 3218000\n",
      "  timesteps_this_iter: 34000\n",
      "  timesteps_total: 3218000\n",
      "  training_iteration: 95\n",
      "  trial_id: 00c00974\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 12.5/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8/8 CPUs, 1/1 GPUs, 0.0/7.76 GiB heap, 0.0/2.69 GiB objects<br>Result logdir: /home/qian/ray_results/pong-impala-fast<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                        </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>IMPALA_PongNoFrameskip-v4_00c00974</td><td>RUNNING </td><td>10.236.176.76:13004</td><td style=\"text-align: right;\">   16.89</td><td style=\"text-align: right;\">         991.155</td><td style=\"text-align: right;\">3218000</td><td style=\"text-align: right;\">    95</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for IMPALA_PongNoFrameskip-v4_00c00974:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-03-11_16-39-16\n",
      "  done: false\n",
      "  episode_len_mean: 8054.62\n",
      "  episode_reward_max: 21.0\n",
      "  episode_reward_mean: 17.09\n",
      "  episode_reward_min: -9.0\n",
      "  episodes_this_iter: 25\n",
      "  episodes_total: 2615\n",
      "  experiment_id: 92f0827d37354e42be7025ff72050188\n",
      "  experiment_tag: '0'\n",
      "  hostname: qian-XPS-8920\n",
      "  info:\n",
      "    learner:\n",
      "      cur_lr: 0.0005000000237487257\n",
      "      entropy: 1555.4310302734375\n",
      "      entropy_coeff: 0.009999999776482582\n",
      "      grad_gnorm: 40.0\n",
      "      model: {}\n",
      "      policy_loss: -39.586708068847656\n",
      "      var_gnorm: 24.74167251586914\n",
      "      vf_explained_var: 0.8292884230613708\n",
      "      vf_loss: 11.168242454528809\n",
      "    learner_queue:\n",
      "      size_count: 3252\n",
      "      size_mean: 0.0\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      size_std: 0.0\n",
      "    num_steps_replayed: 0\n",
      "    num_steps_sampled: 3252000\n",
      "    num_steps_trained: 3251000\n",
      "    num_weight_syncs: 13009\n",
      "    sample_throughput: 3245.668\n",
      "    timing_breakdown:\n",
      "      learner_dequeue_time_ms: 4895.619\n",
      "      learner_grad_time_ms: 134.162\n",
      "      learner_load_time_ms: 21.332\n",
      "      learner_load_wait_time_ms: 163.431\n",
      "      optimizer_step_time_ms: 82.945\n",
      "    train_throughput: 3245.669\n",
      "  iterations_since_restore: 96\n",
      "  node_ip: 10.236.176.76\n",
      "  num_healthy_workers: 7\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.38666666666667\n",
      "    ram_util_percent: 80.09999999999998\n",
      "  pid: 13004\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 7.477296950598254\n",
      "    mean_inference_ms: 2.200990027419553\n",
      "    mean_processing_ms: 0.4380362770881577\n",
      "  time_since_restore: 1001.6158616542816\n",
      "  time_this_iter_s: 10.461240768432617\n",
      "  time_total_s: 1001.6158616542816\n",
      "  timestamp: 1583959156\n",
      "  timesteps_since_restore: 3252000\n",
      "  timesteps_this_iter: 34000\n",
      "  timesteps_total: 3252000\n",
      "  training_iteration: 96\n",
      "  trial_id: 00c00974\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 12.5/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8/8 CPUs, 1/1 GPUs, 0.0/7.76 GiB heap, 0.0/2.69 GiB objects<br>Result logdir: /home/qian/ray_results/pong-impala-fast<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                        </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>IMPALA_PongNoFrameskip-v4_00c00974</td><td>RUNNING </td><td>10.236.176.76:13004</td><td style=\"text-align: right;\">   17.09</td><td style=\"text-align: right;\">         1001.62</td><td style=\"text-align: right;\">3252000</td><td style=\"text-align: right;\">    96</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for IMPALA_PongNoFrameskip-v4_00c00974:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-03-11_16-39-27\n",
      "  done: false\n",
      "  episode_len_mean: 8019.38\n",
      "  episode_reward_max: 21.0\n",
      "  episode_reward_mean: 17.15\n",
      "  episode_reward_min: -9.0\n",
      "  episodes_this_iter: 14\n",
      "  episodes_total: 2629\n",
      "  experiment_id: 92f0827d37354e42be7025ff72050188\n",
      "  experiment_tag: '0'\n",
      "  hostname: qian-XPS-8920\n",
      "  info:\n",
      "    learner:\n",
      "      cur_lr: 0.0005000000237487257\n",
      "      entropy: 1595.4432373046875\n",
      "      entropy_coeff: 0.009999999776482582\n",
      "      grad_gnorm: 40.000003814697266\n",
      "      model: {}\n",
      "      policy_loss: 8.79126262664795\n",
      "      var_gnorm: 24.78957176208496\n",
      "      vf_explained_var: 0.7067273855209351\n",
      "      vf_loss: 35.09746170043945\n",
      "    learner_queue:\n",
      "      size_count: 3286\n",
      "      size_mean: 0.0\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      size_std: 0.0\n",
      "    num_steps_replayed: 0\n",
      "    num_steps_sampled: 3286000\n",
      "    num_steps_trained: 3286000\n",
      "    num_weight_syncs: 13146\n",
      "    sample_throughput: 3244.349\n",
      "    timing_breakdown:\n",
      "      learner_dequeue_time_ms: 4898.575\n",
      "      learner_grad_time_ms: 133.905\n",
      "      learner_load_time_ms: 21.158\n",
      "      learner_load_wait_time_ms: 172.883\n",
      "      optimizer_step_time_ms: 73.057\n",
      "    train_throughput: 3339.771\n",
      "  iterations_since_restore: 97\n",
      "  node_ip: 10.236.176.76\n",
      "  num_healthy_workers: 7\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.38666666666667\n",
      "    ram_util_percent: 80.09999999999998\n",
      "  pid: 13004\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 7.47730468446397\n",
      "    mean_inference_ms: 2.2002506621491995\n",
      "    mean_processing_ms: 0.43771174279110864\n",
      "  time_since_restore: 1012.0802159309387\n",
      "  time_this_iter_s: 10.464354276657104\n",
      "  time_total_s: 1012.0802159309387\n",
      "  timestamp: 1583959167\n",
      "  timesteps_since_restore: 3286000\n",
      "  timesteps_this_iter: 34000\n",
      "  timesteps_total: 3286000\n",
      "  training_iteration: 97\n",
      "  trial_id: 00c00974\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 12.5/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8/8 CPUs, 1/1 GPUs, 0.0/7.76 GiB heap, 0.0/2.69 GiB objects<br>Result logdir: /home/qian/ray_results/pong-impala-fast<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                        </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>IMPALA_PongNoFrameskip-v4_00c00974</td><td>RUNNING </td><td>10.236.176.76:13004</td><td style=\"text-align: right;\">   17.15</td><td style=\"text-align: right;\">         1012.08</td><td style=\"text-align: right;\">3286000</td><td style=\"text-align: right;\">    97</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for IMPALA_PongNoFrameskip-v4_00c00974:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-03-11_16-39-37\n",
      "  done: false\n",
      "  episode_len_mean: 7916.68\n",
      "  episode_reward_max: 21.0\n",
      "  episode_reward_mean: 17.45\n",
      "  episode_reward_min: -9.0\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 2647\n",
      "  experiment_id: 92f0827d37354e42be7025ff72050188\n",
      "  experiment_tag: '0'\n",
      "  hostname: qian-XPS-8920\n",
      "  info:\n",
      "    learner:\n",
      "      cur_lr: 0.0005000000237487257\n",
      "      entropy: 1564.1295166015625\n",
      "      entropy_coeff: 0.009999999776482582\n",
      "      grad_gnorm: 40.000003814697266\n",
      "      model: {}\n",
      "      policy_loss: 11.379935264587402\n",
      "      var_gnorm: 24.84830665588379\n",
      "      vf_explained_var: 0.8611220121383667\n",
      "      vf_loss: 14.622897148132324\n",
      "    learner_queue:\n",
      "      size_count: 3320\n",
      "      size_mean: 0.0\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      size_std: 0.0\n",
      "    num_steps_replayed: 0\n",
      "    num_steps_sampled: 3320000\n",
      "    num_steps_trained: 3319000\n",
      "    num_weight_syncs: 13282\n",
      "    sample_throughput: 3261.396\n",
      "    timing_breakdown:\n",
      "      learner_dequeue_time_ms: 4894.222\n",
      "      learner_grad_time_ms: 135.036\n",
      "      learner_load_time_ms: 21.771\n",
      "      learner_load_wait_time_ms: 169.451\n",
      "      optimizer_step_time_ms: 77.269\n",
      "    train_throughput: 3165.473\n",
      "  iterations_since_restore: 98\n",
      "  node_ip: 10.236.176.76\n",
      "  num_healthy_workers: 7\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.40666666666667\n",
      "    ram_util_percent: 80.09999999999998\n",
      "  pid: 13004\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 7.478250346381948\n",
      "    mean_inference_ms: 2.2015380862328775\n",
      "    mean_processing_ms: 0.4375982487310418\n",
      "  time_since_restore: 1022.4907650947571\n",
      "  time_this_iter_s: 10.41054916381836\n",
      "  time_total_s: 1022.4907650947571\n",
      "  timestamp: 1583959177\n",
      "  timesteps_since_restore: 3320000\n",
      "  timesteps_this_iter: 34000\n",
      "  timesteps_total: 3320000\n",
      "  training_iteration: 98\n",
      "  trial_id: 00c00974\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 12.5/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8/8 CPUs, 1/1 GPUs, 0.0/7.76 GiB heap, 0.0/2.69 GiB objects<br>Result logdir: /home/qian/ray_results/pong-impala-fast<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                        </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>IMPALA_PongNoFrameskip-v4_00c00974</td><td>RUNNING </td><td>10.236.176.76:13004</td><td style=\"text-align: right;\">   17.45</td><td style=\"text-align: right;\">         1022.49</td><td style=\"text-align: right;\">3320000</td><td style=\"text-align: right;\">    98</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for IMPALA_PongNoFrameskip-v4_00c00974:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-03-11_16-39-48\n",
      "  done: false\n",
      "  episode_len_mean: 7901.08\n",
      "  episode_reward_max: 21.0\n",
      "  episode_reward_mean: 17.46\n",
      "  episode_reward_min: -9.0\n",
      "  episodes_this_iter: 16\n",
      "  episodes_total: 2663\n",
      "  experiment_id: 92f0827d37354e42be7025ff72050188\n",
      "  experiment_tag: '0'\n",
      "  hostname: qian-XPS-8920\n",
      "  info:\n",
      "    learner:\n",
      "      cur_lr: 0.0005000000237487257\n",
      "      entropy: 1573.404296875\n",
      "      entropy_coeff: 0.009999999776482582\n",
      "      grad_gnorm: 40.0\n",
      "      model: {}\n",
      "      policy_loss: -24.118114471435547\n",
      "      var_gnorm: 24.947298049926758\n",
      "      vf_explained_var: 0.8037666082382202\n",
      "      vf_loss: 24.812156677246094\n",
      "    learner_queue:\n",
      "      size_count: 3354\n",
      "      size_mean: 0.0\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      size_std: 0.0\n",
      "    num_steps_replayed: 0\n",
      "    num_steps_sampled: 3354000\n",
      "    num_steps_trained: 3353000\n",
      "    num_weight_syncs: 13418\n",
      "    sample_throughput: 3257.837\n",
      "    timing_breakdown:\n",
      "      learner_dequeue_time_ms: 4870.576\n",
      "      learner_grad_time_ms: 134.727\n",
      "      learner_load_time_ms: 18.644\n",
      "      learner_load_wait_time_ms: 179.385\n",
      "      optimizer_step_time_ms: 87.181\n",
      "    train_throughput: 3257.837\n",
      "  iterations_since_restore: 99\n",
      "  node_ip: 10.236.176.76\n",
      "  num_healthy_workers: 7\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.28666666666666\n",
      "    ram_util_percent: 80.11333333333332\n",
      "  pid: 13004\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 7.4779600587052935\n",
      "    mean_inference_ms: 2.2004044578502335\n",
      "    mean_processing_ms: 0.4372266487380267\n",
      "  time_since_restore: 1032.9128313064575\n",
      "  time_this_iter_s: 10.42206621170044\n",
      "  time_total_s: 1032.9128313064575\n",
      "  timestamp: 1583959188\n",
      "  timesteps_since_restore: 3354000\n",
      "  timesteps_this_iter: 34000\n",
      "  timesteps_total: 3354000\n",
      "  training_iteration: 99\n",
      "  trial_id: 00c00974\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 12.5/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8/8 CPUs, 1/1 GPUs, 0.0/7.76 GiB heap, 0.0/2.69 GiB objects<br>Result logdir: /home/qian/ray_results/pong-impala-fast<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                        </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>IMPALA_PongNoFrameskip-v4_00c00974</td><td>RUNNING </td><td>10.236.176.76:13004</td><td style=\"text-align: right;\">   17.46</td><td style=\"text-align: right;\">         1032.91</td><td style=\"text-align: right;\">3354000</td><td style=\"text-align: right;\">    99</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for IMPALA_PongNoFrameskip-v4_00c00974:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-03-11_16-39-58\n",
      "  done: false\n",
      "  episode_len_mean: 7774.01\n",
      "  episode_reward_max: 21.0\n",
      "  episode_reward_mean: 18.16\n",
      "  episode_reward_min: -1.0\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 2681\n",
      "  experiment_id: 92f0827d37354e42be7025ff72050188\n",
      "  experiment_tag: '0'\n",
      "  hostname: qian-XPS-8920\n",
      "  info:\n",
      "    learner:\n",
      "      cur_lr: 0.0005000000237487257\n",
      "      entropy: 1573.328369140625\n",
      "      entropy_coeff: 0.009999999776482582\n",
      "      grad_gnorm: 40.0\n",
      "      model: {}\n",
      "      policy_loss: 22.625267028808594\n",
      "      var_gnorm: 25.05236053466797\n",
      "      vf_explained_var: 0.8543018698692322\n",
      "      vf_loss: 17.371620178222656\n",
      "    learner_queue:\n",
      "      size_count: 3388\n",
      "      size_mean: 0.0\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      size_std: 0.0\n",
      "    num_steps_replayed: 0\n",
      "    num_steps_sampled: 3388000\n",
      "    num_steps_trained: 3388000\n",
      "    num_weight_syncs: 13554\n",
      "    sample_throughput: 3249.009\n",
      "    timing_breakdown:\n",
      "      learner_dequeue_time_ms: 4894.713\n",
      "      learner_grad_time_ms: 134.746\n",
      "      learner_load_time_ms: 22.787\n",
      "      learner_load_wait_time_ms: 165.902\n",
      "      optimizer_step_time_ms: 86.45\n",
      "    train_throughput: 3344.568\n",
      "  iterations_since_restore: 100\n",
      "  node_ip: 10.236.176.76\n",
      "  num_healthy_workers: 7\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.26\n",
      "    ram_util_percent: 80.09999999999998\n",
      "  pid: 13004\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 7.478209558819699\n",
      "    mean_inference_ms: 2.201544885012021\n",
      "    mean_processing_ms: 0.43719710265119177\n",
      "  time_since_restore: 1043.3592441082\n",
      "  time_this_iter_s: 10.446412801742554\n",
      "  time_total_s: 1043.3592441082\n",
      "  timestamp: 1583959198\n",
      "  timesteps_since_restore: 3388000\n",
      "  timesteps_this_iter: 34000\n",
      "  timesteps_total: 3388000\n",
      "  training_iteration: 100\n",
      "  trial_id: 00c00974\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 12.5/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8/8 CPUs, 1/1 GPUs, 0.0/7.76 GiB heap, 0.0/2.69 GiB objects<br>Result logdir: /home/qian/ray_results/pong-impala-fast<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                        </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>IMPALA_PongNoFrameskip-v4_00c00974</td><td>RUNNING </td><td>10.236.176.76:13004</td><td style=\"text-align: right;\">   18.16</td><td style=\"text-align: right;\">         1043.36</td><td style=\"text-align: right;\">3388000</td><td style=\"text-align: right;\">   100</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for IMPALA_PongNoFrameskip-v4_00c00974:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-03-11_16-40-09\n",
      "  done: false\n",
      "  episode_len_mean: 7831.58\n",
      "  episode_reward_max: 21.0\n",
      "  episode_reward_mean: 18.06\n",
      "  episode_reward_min: -1.0\n",
      "  episodes_this_iter: 17\n",
      "  episodes_total: 2698\n",
      "  experiment_id: 92f0827d37354e42be7025ff72050188\n",
      "  experiment_tag: '0'\n",
      "  hostname: qian-XPS-8920\n",
      "  info:\n",
      "    learner:\n",
      "      cur_lr: 0.0005000000237487257\n",
      "      entropy: 1565.1171875\n",
      "      entropy_coeff: 0.009999999776482582\n",
      "      grad_gnorm: 40.0\n",
      "      model: {}\n",
      "      policy_loss: 30.857864379882812\n",
      "      var_gnorm: 25.154813766479492\n",
      "      vf_explained_var: 0.8694189190864563\n",
      "      vf_loss: 12.41098690032959\n",
      "    learner_queue:\n",
      "      size_count: 3422\n",
      "      size_mean: 0.0\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      size_std: 0.0\n",
      "    num_steps_replayed: 0\n",
      "    num_steps_sampled: 3422000\n",
      "    num_steps_trained: 3421000\n",
      "    num_weight_syncs: 13688\n",
      "    sample_throughput: 3255.149\n",
      "    timing_breakdown:\n",
      "      learner_dequeue_time_ms: 4902.674\n",
      "      learner_grad_time_ms: 134.379\n",
      "      learner_load_time_ms: 22.531\n",
      "      learner_load_wait_time_ms: 188.154\n",
      "      optimizer_step_time_ms: 86.025\n",
      "    train_throughput: 3159.409\n",
      "  iterations_since_restore: 101\n",
      "  node_ip: 10.236.176.76\n",
      "  num_healthy_workers: 7\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.11333333333333\n",
      "    ram_util_percent: 80.14666666666669\n",
      "  pid: 13004\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 7.477912495265729\n",
      "    mean_inference_ms: 2.200575335308076\n",
      "    mean_processing_ms: 0.4367620807998843\n",
      "  time_since_restore: 1053.7898545265198\n",
      "  time_this_iter_s: 10.430610418319702\n",
      "  time_total_s: 1053.7898545265198\n",
      "  timestamp: 1583959209\n",
      "  timesteps_since_restore: 3422000\n",
      "  timesteps_this_iter: 34000\n",
      "  timesteps_total: 3422000\n",
      "  training_iteration: 101\n",
      "  trial_id: 00c00974\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 12.5/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8/8 CPUs, 1/1 GPUs, 0.0/7.76 GiB heap, 0.0/2.69 GiB objects<br>Result logdir: /home/qian/ray_results/pong-impala-fast<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                        </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>IMPALA_PongNoFrameskip-v4_00c00974</td><td>RUNNING </td><td>10.236.176.76:13004</td><td style=\"text-align: right;\">   18.06</td><td style=\"text-align: right;\">         1053.79</td><td style=\"text-align: right;\">3422000</td><td style=\"text-align: right;\">   101</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for IMPALA_PongNoFrameskip-v4_00c00974:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-03-11_16-40-19\n",
      "  done: false\n",
      "  episode_len_mean: 7874.2\n",
      "  episode_reward_max: 21.0\n",
      "  episode_reward_mean: 18.13\n",
      "  episode_reward_min: 10.0\n",
      "  episodes_this_iter: 16\n",
      "  episodes_total: 2714\n",
      "  experiment_id: 92f0827d37354e42be7025ff72050188\n",
      "  experiment_tag: '0'\n",
      "  hostname: qian-XPS-8920\n",
      "  info:\n",
      "    learner:\n",
      "      cur_lr: 0.0005000000237487257\n",
      "      entropy: 1576.54296875\n",
      "      entropy_coeff: 0.009999999776482582\n",
      "      grad_gnorm: 39.999996185302734\n",
      "      model: {}\n",
      "      policy_loss: -86.56085968017578\n",
      "      var_gnorm: 25.247520446777344\n",
      "      vf_explained_var: 0.7759487628936768\n",
      "      vf_loss: 37.563262939453125\n",
      "    learner_queue:\n",
      "      size_count: 3456\n",
      "      size_mean: 0.0\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      size_std: 0.0\n",
      "    num_steps_replayed: 0\n",
      "    num_steps_sampled: 3456000\n",
      "    num_steps_trained: 3455000\n",
      "    num_weight_syncs: 13824\n",
      "    sample_throughput: 3254.401\n",
      "    timing_breakdown:\n",
      "      learner_dequeue_time_ms: 4896.756\n",
      "      learner_grad_time_ms: 134.895\n",
      "      learner_load_time_ms: 28.949\n",
      "      learner_load_wait_time_ms: 170.528\n",
      "      optimizer_step_time_ms: 79.221\n",
      "    train_throughput: 3254.401\n",
      "  iterations_since_restore: 102\n",
      "  node_ip: 10.236.176.76\n",
      "  num_healthy_workers: 7\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.47142857142856\n",
      "    ram_util_percent: 80.20000000000002\n",
      "  pid: 13004\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 7.479254138280083\n",
      "    mean_inference_ms: 2.203242957208584\n",
      "    mean_processing_ms: 0.4368697760611228\n",
      "  time_since_restore: 1064.222839832306\n",
      "  time_this_iter_s: 10.432985305786133\n",
      "  time_total_s: 1064.222839832306\n",
      "  timestamp: 1583959219\n",
      "  timesteps_since_restore: 3456000\n",
      "  timesteps_this_iter: 34000\n",
      "  timesteps_total: 3456000\n",
      "  training_iteration: 102\n",
      "  trial_id: 00c00974\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 12.5/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8/8 CPUs, 1/1 GPUs, 0.0/7.76 GiB heap, 0.0/2.69 GiB objects<br>Result logdir: /home/qian/ray_results/pong-impala-fast<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                        </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>IMPALA_PongNoFrameskip-v4_00c00974</td><td>RUNNING </td><td>10.236.176.76:13004</td><td style=\"text-align: right;\">   18.13</td><td style=\"text-align: right;\">         1064.22</td><td style=\"text-align: right;\">3456000</td><td style=\"text-align: right;\">   102</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for IMPALA_PongNoFrameskip-v4_00c00974:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-03-11_16-40-30\n",
      "  done: false\n",
      "  episode_len_mean: 7904.06\n",
      "  episode_reward_max: 21.0\n",
      "  episode_reward_mean: 18.13\n",
      "  episode_reward_min: 10.0\n",
      "  episodes_this_iter: 12\n",
      "  episodes_total: 2726\n",
      "  experiment_id: 92f0827d37354e42be7025ff72050188\n",
      "  experiment_tag: '0'\n",
      "  hostname: qian-XPS-8920\n",
      "  info:\n",
      "    learner:\n",
      "      cur_lr: 0.0005000000237487257\n",
      "      entropy: 1574.3037109375\n",
      "      entropy_coeff: 0.009999999776482582\n",
      "      grad_gnorm: 40.0\n",
      "      model: {}\n",
      "      policy_loss: -96.2557601928711\n",
      "      var_gnorm: 25.34061622619629\n",
      "      vf_explained_var: 0.7575061917304993\n",
      "      vf_loss: 25.59572410583496\n",
      "    learner_queue:\n",
      "      size_count: 3490\n",
      "      size_mean: 0.0\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      size_std: 0.0\n",
      "    num_steps_replayed: 0\n",
      "    num_steps_sampled: 3490000\n",
      "    num_steps_trained: 3489000\n",
      "    num_weight_syncs: 13960\n",
      "    sample_throughput: 3257.142\n",
      "    timing_breakdown:\n",
      "      learner_dequeue_time_ms: 4896.723\n",
      "      learner_grad_time_ms: 134.753\n",
      "      learner_load_time_ms: 27.632\n",
      "      learner_load_wait_time_ms: 170.058\n",
      "      optimizer_step_time_ms: 76.025\n",
      "    train_throughput: 3257.142\n",
      "  iterations_since_restore: 103\n",
      "  node_ip: 10.236.176.76\n",
      "  num_healthy_workers: 7\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.70666666666668\n",
      "    ram_util_percent: 80.20000000000002\n",
      "  pid: 13004\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 7.47926954649681\n",
      "    mean_inference_ms: 2.2040230950254878\n",
      "    mean_processing_ms: 0.43690760626490754\n",
      "  time_since_restore: 1074.6488726139069\n",
      "  time_this_iter_s: 10.426032781600952\n",
      "  time_total_s: 1074.6488726139069\n",
      "  timestamp: 1583959230\n",
      "  timesteps_since_restore: 3490000\n",
      "  timesteps_this_iter: 34000\n",
      "  timesteps_total: 3490000\n",
      "  training_iteration: 103\n",
      "  trial_id: 00c00974\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 12.5/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8/8 CPUs, 1/1 GPUs, 0.0/7.76 GiB heap, 0.0/2.69 GiB objects<br>Result logdir: /home/qian/ray_results/pong-impala-fast<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                        </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>IMPALA_PongNoFrameskip-v4_00c00974</td><td>RUNNING </td><td>10.236.176.76:13004</td><td style=\"text-align: right;\">   18.13</td><td style=\"text-align: right;\">         1074.65</td><td style=\"text-align: right;\">3490000</td><td style=\"text-align: right;\">   103</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for IMPALA_PongNoFrameskip-v4_00c00974:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-03-11_16-40-40\n",
      "  done: false\n",
      "  episode_len_mean: 8187.38\n",
      "  episode_reward_max: 21.0\n",
      "  episode_reward_mean: 17.5\n",
      "  episode_reward_min: 7.0\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 2745\n",
      "  experiment_id: 92f0827d37354e42be7025ff72050188\n",
      "  experiment_tag: '0'\n",
      "  hostname: qian-XPS-8920\n",
      "  info:\n",
      "    learner:\n",
      "      cur_lr: 0.0005000000237487257\n",
      "      entropy: 1547.82763671875\n",
      "      entropy_coeff: 0.009999999776482582\n",
      "      grad_gnorm: 40.0\n",
      "      model: {}\n",
      "      policy_loss: -18.617475509643555\n",
      "      var_gnorm: 25.399368286132812\n",
      "      vf_explained_var: 0.9003641605377197\n",
      "      vf_loss: 11.962221145629883\n",
      "    learner_queue:\n",
      "      size_count: 3523\n",
      "      size_mean: 0.0\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      size_std: 0.0\n",
      "    num_steps_replayed: 0\n",
      "    num_steps_sampled: 3523000\n",
      "    num_steps_trained: 3523000\n",
      "    num_weight_syncs: 14095\n",
      "    sample_throughput: 3160.325\n",
      "    timing_breakdown:\n",
      "      learner_dequeue_time_ms: 4899.369\n",
      "      learner_grad_time_ms: 134.445\n",
      "      learner_load_time_ms: 24.814\n",
      "      learner_load_wait_time_ms: 164.332\n",
      "      optimizer_step_time_ms: 88.517\n",
      "    train_throughput: 3256.092\n",
      "  iterations_since_restore: 104\n",
      "  node_ip: 10.236.176.76\n",
      "  num_healthy_workers: 7\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.53333333333333\n",
      "    ram_util_percent: 80.20000000000002\n",
      "  pid: 13004\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 7.478643437920044\n",
      "    mean_inference_ms: 2.2029070186344595\n",
      "    mean_processing_ms: 0.436373347212517\n",
      "  time_since_restore: 1085.078167438507\n",
      "  time_this_iter_s: 10.42929482460022\n",
      "  time_total_s: 1085.078167438507\n",
      "  timestamp: 1583959240\n",
      "  timesteps_since_restore: 3523000\n",
      "  timesteps_this_iter: 33000\n",
      "  timesteps_total: 3523000\n",
      "  training_iteration: 104\n",
      "  trial_id: 00c00974\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 12.5/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8/8 CPUs, 1/1 GPUs, 0.0/7.76 GiB heap, 0.0/2.69 GiB objects<br>Result logdir: /home/qian/ray_results/pong-impala-fast<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                        </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>IMPALA_PongNoFrameskip-v4_00c00974</td><td>RUNNING </td><td>10.236.176.76:13004</td><td style=\"text-align: right;\">    17.5</td><td style=\"text-align: right;\">         1085.08</td><td style=\"text-align: right;\">3523000</td><td style=\"text-align: right;\">   104</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for IMPALA_PongNoFrameskip-v4_00c00974:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-03-11_16-40-50\n",
      "  done: false\n",
      "  episode_len_mean: 8290.37\n",
      "  episode_reward_max: 20.0\n",
      "  episode_reward_mean: 17.29\n",
      "  episode_reward_min: 7.0\n",
      "  episodes_this_iter: 15\n",
      "  episodes_total: 2760\n",
      "  experiment_id: 92f0827d37354e42be7025ff72050188\n",
      "  experiment_tag: '0'\n",
      "  hostname: qian-XPS-8920\n",
      "  info:\n",
      "    learner:\n",
      "      cur_lr: 0.0005000000237487257\n",
      "      entropy: 1575.7357177734375\n",
      "      entropy_coeff: 0.009999999776482582\n",
      "      grad_gnorm: 40.0\n",
      "      model: {}\n",
      "      policy_loss: -38.39287567138672\n",
      "      var_gnorm: 25.462942123413086\n",
      "      vf_explained_var: 0.8871598243713379\n",
      "      vf_loss: 11.542889595031738\n",
      "    learner_queue:\n",
      "      size_count: 3557\n",
      "      size_mean: 0.0\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      size_std: 0.0\n",
      "    num_steps_replayed: 0\n",
      "    num_steps_sampled: 3557000\n",
      "    num_steps_trained: 3557000\n",
      "    num_weight_syncs: 14231\n",
      "    sample_throughput: 3262.512\n",
      "    timing_breakdown:\n",
      "      learner_dequeue_time_ms: 4904.49\n",
      "      learner_grad_time_ms: 137.018\n",
      "      learner_load_time_ms: 25.245\n",
      "      learner_load_wait_time_ms: 161.751\n",
      "      optimizer_step_time_ms: 71.17\n",
      "    train_throughput: 3262.512\n",
      "  iterations_since_restore: 105\n",
      "  node_ip: 10.236.176.76\n",
      "  num_healthy_workers: 7\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.36666666666666\n",
      "    ram_util_percent: 80.22000000000001\n",
      "  pid: 13004\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 7.478276423590869\n",
      "    mean_inference_ms: 2.2027267820842833\n",
      "    mean_processing_ms: 0.4359711423160671\n",
      "  time_since_restore: 1095.4873535633087\n",
      "  time_this_iter_s: 10.409186124801636\n",
      "  time_total_s: 1095.4873535633087\n",
      "  timestamp: 1583959250\n",
      "  timesteps_since_restore: 3557000\n",
      "  timesteps_this_iter: 34000\n",
      "  timesteps_total: 3557000\n",
      "  training_iteration: 105\n",
      "  trial_id: 00c00974\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 12.5/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8/8 CPUs, 1/1 GPUs, 0.0/7.76 GiB heap, 0.0/2.69 GiB objects<br>Result logdir: /home/qian/ray_results/pong-impala-fast<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                        </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>IMPALA_PongNoFrameskip-v4_00c00974</td><td>RUNNING </td><td>10.236.176.76:13004</td><td style=\"text-align: right;\">   17.29</td><td style=\"text-align: right;\">         1095.49</td><td style=\"text-align: right;\">3557000</td><td style=\"text-align: right;\">   105</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for IMPALA_PongNoFrameskip-v4_00c00974:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-03-11_16-41-01\n",
      "  done: false\n",
      "  episode_len_mean: 8292.6\n",
      "  episode_reward_max: 20.0\n",
      "  episode_reward_mean: 17.19\n",
      "  episode_reward_min: 2.0\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 2779\n",
      "  experiment_id: 92f0827d37354e42be7025ff72050188\n",
      "  experiment_tag: '0'\n",
      "  hostname: qian-XPS-8920\n",
      "  info:\n",
      "    learner:\n",
      "      cur_lr: 0.0005000000237487257\n",
      "      entropy: 1550.382568359375\n",
      "      entropy_coeff: 0.009999999776482582\n",
      "      grad_gnorm: 40.0\n",
      "      model: {}\n",
      "      policy_loss: 44.5028076171875\n",
      "      var_gnorm: 25.526905059814453\n",
      "      vf_explained_var: 0.7628365159034729\n",
      "      vf_loss: 21.331533432006836\n",
      "    learner_queue:\n",
      "      size_count: 3591\n",
      "      size_mean: 0.0\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      size_std: 0.0\n",
      "    num_steps_replayed: 0\n",
      "    num_steps_sampled: 3591000\n",
      "    num_steps_trained: 3591000\n",
      "    num_weight_syncs: 14367\n",
      "    sample_throughput: 3265.472\n",
      "    timing_breakdown:\n",
      "      learner_dequeue_time_ms: 4891.962\n",
      "      learner_grad_time_ms: 133.367\n",
      "      learner_load_time_ms: 17.846\n",
      "      learner_load_wait_time_ms: 163.752\n",
      "      optimizer_step_time_ms: 80.518\n",
      "    train_throughput: 3265.472\n",
      "  iterations_since_restore: 106\n",
      "  node_ip: 10.236.176.76\n",
      "  num_healthy_workers: 7\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.24\n",
      "    ram_util_percent: 80.20666666666668\n",
      "  pid: 13004\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 7.478865976362531\n",
      "    mean_inference_ms: 2.2027997843845366\n",
      "    mean_processing_ms: 0.4358118229104397\n",
      "  time_since_restore: 1105.8863761425018\n",
      "  time_this_iter_s: 10.399022579193115\n",
      "  time_total_s: 1105.8863761425018\n",
      "  timestamp: 1583959261\n",
      "  timesteps_since_restore: 3591000\n",
      "  timesteps_this_iter: 34000\n",
      "  timesteps_total: 3591000\n",
      "  training_iteration: 106\n",
      "  trial_id: 00c00974\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 12.5/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8/8 CPUs, 1/1 GPUs, 0.0/7.76 GiB heap, 0.0/2.69 GiB objects<br>Result logdir: /home/qian/ray_results/pong-impala-fast<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                        </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>IMPALA_PongNoFrameskip-v4_00c00974</td><td>RUNNING </td><td>10.236.176.76:13004</td><td style=\"text-align: right;\">   17.19</td><td style=\"text-align: right;\">         1105.89</td><td style=\"text-align: right;\">3591000</td><td style=\"text-align: right;\">   106</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for IMPALA_PongNoFrameskip-v4_00c00974:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-03-11_16-41-11\n",
      "  done: false\n",
      "  episode_len_mean: 8325.66\n",
      "  episode_reward_max: 21.0\n",
      "  episode_reward_mean: 17.18\n",
      "  episode_reward_min: 2.0\n",
      "  episodes_this_iter: 17\n",
      "  episodes_total: 2796\n",
      "  experiment_id: 92f0827d37354e42be7025ff72050188\n",
      "  experiment_tag: '0'\n",
      "  hostname: qian-XPS-8920\n",
      "  info:\n",
      "    learner:\n",
      "      cur_lr: 0.0005000000237487257\n",
      "      entropy: 1579.4259033203125\n",
      "      entropy_coeff: 0.009999999776482582\n",
      "      grad_gnorm: 40.0\n",
      "      model: {}\n",
      "      policy_loss: -12.173490524291992\n",
      "      var_gnorm: 25.59031105041504\n",
      "      vf_explained_var: 0.7860223650932312\n",
      "      vf_loss: 19.124923706054688\n",
      "    learner_queue:\n",
      "      size_count: 3626\n",
      "      size_mean: 0.0\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      size_std: 0.0\n",
      "    num_steps_replayed: 0\n",
      "    num_steps_sampled: 3626000\n",
      "    num_steps_trained: 3624000\n",
      "    num_weight_syncs: 14504\n",
      "    sample_throughput: 3337.905\n",
      "    timing_breakdown:\n",
      "      learner_dequeue_time_ms: 4890.785\n",
      "      learner_grad_time_ms: 134.97\n",
      "      learner_load_time_ms: 18.477\n",
      "      learner_load_wait_time_ms: 154.203\n",
      "      optimizer_step_time_ms: 65.387\n",
      "    train_throughput: 3147.168\n",
      "  iterations_since_restore: 107\n",
      "  node_ip: 10.236.176.76\n",
      "  num_healthy_workers: 7\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.64666666666669\n",
      "    ram_util_percent: 80.22000000000003\n",
      "  pid: 13004\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 7.478430984747214\n",
      "    mean_inference_ms: 2.202642652890593\n",
      "    mean_processing_ms: 0.4354478430383828\n",
      "  time_since_restore: 1116.3592023849487\n",
      "  time_this_iter_s: 10.4728262424469\n",
      "  time_total_s: 1116.3592023849487\n",
      "  timestamp: 1583959271\n",
      "  timesteps_since_restore: 3626000\n",
      "  timesteps_this_iter: 35000\n",
      "  timesteps_total: 3626000\n",
      "  training_iteration: 107\n",
      "  trial_id: 00c00974\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 12.5/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8/8 CPUs, 1/1 GPUs, 0.0/7.76 GiB heap, 0.0/2.69 GiB objects<br>Result logdir: /home/qian/ray_results/pong-impala-fast<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                        </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>IMPALA_PongNoFrameskip-v4_00c00974</td><td>RUNNING </td><td>10.236.176.76:13004</td><td style=\"text-align: right;\">   17.18</td><td style=\"text-align: right;\">         1116.36</td><td style=\"text-align: right;\">3626000</td><td style=\"text-align: right;\">   107</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for IMPALA_PongNoFrameskip-v4_00c00974:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-03-11_16-41-22\n",
      "  done: false\n",
      "  episode_len_mean: 8270.78\n",
      "  episode_reward_max: 21.0\n",
      "  episode_reward_mean: 17.19\n",
      "  episode_reward_min: 2.0\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 2814\n",
      "  experiment_id: 92f0827d37354e42be7025ff72050188\n",
      "  experiment_tag: '0'\n",
      "  hostname: qian-XPS-8920\n",
      "  info:\n",
      "    learner:\n",
      "      cur_lr: 0.0005000000237487257\n",
      "      entropy: 1607.951171875\n",
      "      entropy_coeff: 0.009999999776482582\n",
      "      grad_gnorm: 40.0\n",
      "      model: {}\n",
      "      policy_loss: 43.05209732055664\n",
      "      var_gnorm: 25.63582420349121\n",
      "      vf_explained_var: 0.9428888559341431\n",
      "      vf_loss: 5.553742408752441\n",
      "    learner_queue:\n",
      "      size_count: 3660\n",
      "      size_mean: 0.0\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      size_std: 0.0\n",
      "    num_steps_replayed: 0\n",
      "    num_steps_sampled: 3660000\n",
      "    num_steps_trained: 3659000\n",
      "    num_weight_syncs: 14640\n",
      "    sample_throughput: 3251.888\n",
      "    timing_breakdown:\n",
      "      learner_dequeue_time_ms: 4904.054\n",
      "      learner_grad_time_ms: 133.31\n",
      "      learner_load_time_ms: 19.632\n",
      "      learner_load_wait_time_ms: 172.126\n",
      "      optimizer_step_time_ms: 91.23\n",
      "    train_throughput: 3347.531\n",
      "  iterations_since_restore: 108\n",
      "  node_ip: 10.236.176.76\n",
      "  num_healthy_workers: 7\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.38666666666664\n",
      "    ram_util_percent: 80.22000000000003\n",
      "  pid: 13004\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 7.478758584546549\n",
      "    mean_inference_ms: 2.201185813887188\n",
      "    mean_processing_ms: 0.4351225813423551\n",
      "  time_since_restore: 1126.8017210960388\n",
      "  time_this_iter_s: 10.442518711090088\n",
      "  time_total_s: 1126.8017210960388\n",
      "  timestamp: 1583959282\n",
      "  timesteps_since_restore: 3660000\n",
      "  timesteps_this_iter: 34000\n",
      "  timesteps_total: 3660000\n",
      "  training_iteration: 108\n",
      "  trial_id: 00c00974\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 12.5/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8/8 CPUs, 1/1 GPUs, 0.0/7.76 GiB heap, 0.0/2.69 GiB objects<br>Result logdir: /home/qian/ray_results/pong-impala-fast<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                        </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>IMPALA_PongNoFrameskip-v4_00c00974</td><td>RUNNING </td><td>10.236.176.76:13004</td><td style=\"text-align: right;\">   17.19</td><td style=\"text-align: right;\">          1126.8</td><td style=\"text-align: right;\">3660000</td><td style=\"text-align: right;\">   108</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for IMPALA_PongNoFrameskip-v4_00c00974:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-03-11_16-41-32\n",
      "  done: false\n",
      "  episode_len_mean: 8289.41\n",
      "  episode_reward_max: 21.0\n",
      "  episode_reward_mean: 17.36\n",
      "  episode_reward_min: 2.0\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 2832\n",
      "  experiment_id: 92f0827d37354e42be7025ff72050188\n",
      "  experiment_tag: '0'\n",
      "  hostname: qian-XPS-8920\n",
      "  info:\n",
      "    learner:\n",
      "      cur_lr: 0.0005000000237487257\n",
      "      entropy: 1616.4127197265625\n",
      "      entropy_coeff: 0.009999999776482582\n",
      "      grad_gnorm: 40.0\n",
      "      model: {}\n",
      "      policy_loss: -0.07190108299255371\n",
      "      var_gnorm: 25.696931838989258\n",
      "      vf_explained_var: 0.836137592792511\n",
      "      vf_loss: 12.742409706115723\n",
      "    learner_queue:\n",
      "      size_count: 3694\n",
      "      size_mean: 0.0\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      size_std: 0.0\n",
      "    num_steps_replayed: 0\n",
      "    num_steps_sampled: 3694000\n",
      "    num_steps_trained: 3693000\n",
      "    num_weight_syncs: 14776\n",
      "    sample_throughput: 3250.509\n",
      "    timing_breakdown:\n",
      "      learner_dequeue_time_ms: 4897.354\n",
      "      learner_grad_time_ms: 133.846\n",
      "      learner_load_time_ms: 18.593\n",
      "      learner_load_wait_time_ms: 174.032\n",
      "      optimizer_step_time_ms: 73.838\n",
      "    train_throughput: 3250.51\n",
      "  iterations_since_restore: 109\n",
      "  node_ip: 10.236.176.76\n",
      "  num_healthy_workers: 7\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.39333333333333\n",
      "    ram_util_percent: 80.20000000000002\n",
      "  pid: 13004\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 7.478562182232918\n",
      "    mean_inference_ms: 2.1998669211164916\n",
      "    mean_processing_ms: 0.4345607197065043\n",
      "  time_since_restore: 1137.249131679535\n",
      "  time_this_iter_s: 10.447410583496094\n",
      "  time_total_s: 1137.249131679535\n",
      "  timestamp: 1583959292\n",
      "  timesteps_since_restore: 3694000\n",
      "  timesteps_this_iter: 34000\n",
      "  timesteps_total: 3694000\n",
      "  training_iteration: 109\n",
      "  trial_id: 00c00974\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 12.5/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8/8 CPUs, 1/1 GPUs, 0.0/7.76 GiB heap, 0.0/2.69 GiB objects<br>Result logdir: /home/qian/ray_results/pong-impala-fast<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                        </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>IMPALA_PongNoFrameskip-v4_00c00974</td><td>RUNNING </td><td>10.236.176.76:13004</td><td style=\"text-align: right;\">   17.36</td><td style=\"text-align: right;\">         1137.25</td><td style=\"text-align: right;\">3694000</td><td style=\"text-align: right;\">   109</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for IMPALA_PongNoFrameskip-v4_00c00974:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-03-11_16-41-43\n",
      "  done: false\n",
      "  episode_len_mean: 8003.53\n",
      "  episode_reward_max: 21.0\n",
      "  episode_reward_mean: 17.93\n",
      "  episode_reward_min: 2.0\n",
      "  episodes_this_iter: 16\n",
      "  episodes_total: 2848\n",
      "  experiment_id: 92f0827d37354e42be7025ff72050188\n",
      "  experiment_tag: '0'\n",
      "  hostname: qian-XPS-8920\n",
      "  info:\n",
      "    learner:\n",
      "      cur_lr: 0.0005000000237487257\n",
      "      entropy: 1587.009521484375\n",
      "      entropy_coeff: 0.009999999776482582\n",
      "      grad_gnorm: 40.0\n",
      "      model: {}\n",
      "      policy_loss: 64.89132690429688\n",
      "      var_gnorm: 25.761009216308594\n",
      "      vf_explained_var: 0.7220186591148376\n",
      "      vf_loss: 29.13775634765625\n",
      "    learner_queue:\n",
      "      size_count: 3727\n",
      "      size_mean: 0.0\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      size_std: 0.0\n",
      "    num_steps_replayed: 0\n",
      "    num_steps_sampled: 3727000\n",
      "    num_steps_trained: 3727000\n",
      "    num_weight_syncs: 14911\n",
      "    sample_throughput: 3171.698\n",
      "    timing_breakdown:\n",
      "      learner_dequeue_time_ms: 4871.71\n",
      "      learner_grad_time_ms: 135.347\n",
      "      learner_load_time_ms: 29.208\n",
      "      learner_load_wait_time_ms: 158.655\n",
      "      optimizer_step_time_ms: 85.589\n",
      "    train_throughput: 3267.81\n",
      "  iterations_since_restore: 110\n",
      "  node_ip: 10.236.176.76\n",
      "  num_healthy_workers: 7\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.32666666666667\n",
      "    ram_util_percent: 80.21333333333335\n",
      "  pid: 13004\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 7.478824519665413\n",
      "    mean_inference_ms: 2.201133176090738\n",
      "    mean_processing_ms: 0.4346675993957001\n",
      "  time_since_restore: 1147.6413311958313\n",
      "  time_this_iter_s: 10.392199516296387\n",
      "  time_total_s: 1147.6413311958313\n",
      "  timestamp: 1583959303\n",
      "  timesteps_since_restore: 3727000\n",
      "  timesteps_this_iter: 33000\n",
      "  timesteps_total: 3727000\n",
      "  training_iteration: 110\n",
      "  trial_id: 00c00974\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 12.5/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8/8 CPUs, 1/1 GPUs, 0.0/7.76 GiB heap, 0.0/2.69 GiB objects<br>Result logdir: /home/qian/ray_results/pong-impala-fast<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                        </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>IMPALA_PongNoFrameskip-v4_00c00974</td><td>RUNNING </td><td>10.236.176.76:13004</td><td style=\"text-align: right;\">   17.93</td><td style=\"text-align: right;\">         1147.64</td><td style=\"text-align: right;\">3727000</td><td style=\"text-align: right;\">   110</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for IMPALA_PongNoFrameskip-v4_00c00974:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-03-11_16-41-53\n",
      "  done: false\n",
      "  episode_len_mean: 7903.93\n",
      "  episode_reward_max: 21.0\n",
      "  episode_reward_mean: 17.92\n",
      "  episode_reward_min: 2.0\n",
      "  episodes_this_iter: 17\n",
      "  episodes_total: 2865\n",
      "  experiment_id: 92f0827d37354e42be7025ff72050188\n",
      "  experiment_tag: '0'\n",
      "  hostname: qian-XPS-8920\n",
      "  info:\n",
      "    learner:\n",
      "      cur_lr: 0.0005000000237487257\n",
      "      entropy: 1551.361572265625\n",
      "      entropy_coeff: 0.009999999776482582\n",
      "      grad_gnorm: 40.0\n",
      "      model: {}\n",
      "      policy_loss: -1.2634692192077637\n",
      "      var_gnorm: 25.82744598388672\n",
      "      vf_explained_var: 0.7834889888763428\n",
      "      vf_loss: 15.093889236450195\n",
      "    learner_queue:\n",
      "      size_count: 3762\n",
      "      size_mean: 0.0\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      size_std: 0.0\n",
      "    num_steps_replayed: 0\n",
      "    num_steps_sampled: 3762000\n",
      "    num_steps_trained: 3761000\n",
      "    num_weight_syncs: 15048\n",
      "    sample_throughput: 3337.47\n",
      "    timing_breakdown:\n",
      "      learner_dequeue_time_ms: 4840.844\n",
      "      learner_grad_time_ms: 133.812\n",
      "      learner_load_time_ms: 29.521\n",
      "      learner_load_wait_time_ms: 161.154\n",
      "      optimizer_step_time_ms: 66.241\n",
      "    train_throughput: 3242.113\n",
      "  iterations_since_restore: 111\n",
      "  node_ip: 10.236.176.76\n",
      "  num_healthy_workers: 7\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.67142857142858\n",
      "    ram_util_percent: 80.25714285714287\n",
      "  pid: 13004\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 7.477542221322412\n",
      "    mean_inference_ms: 2.199788495473315\n",
      "    mean_processing_ms: 0.4341796217293816\n",
      "  time_since_restore: 1158.1148767471313\n",
      "  time_this_iter_s: 10.473545551300049\n",
      "  time_total_s: 1158.1148767471313\n",
      "  timestamp: 1583959313\n",
      "  timesteps_since_restore: 3762000\n",
      "  timesteps_this_iter: 35000\n",
      "  timesteps_total: 3762000\n",
      "  training_iteration: 111\n",
      "  trial_id: 00c00974\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 12.5/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8/8 CPUs, 1/1 GPUs, 0.0/7.76 GiB heap, 0.0/2.69 GiB objects<br>Result logdir: /home/qian/ray_results/pong-impala-fast<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                        </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>IMPALA_PongNoFrameskip-v4_00c00974</td><td>RUNNING </td><td>10.236.176.76:13004</td><td style=\"text-align: right;\">   17.92</td><td style=\"text-align: right;\">         1158.11</td><td style=\"text-align: right;\">3762000</td><td style=\"text-align: right;\">   111</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for IMPALA_PongNoFrameskip-v4_00c00974:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-03-11_16-42-04\n",
      "  done: false\n",
      "  episode_len_mean: 7933.28\n",
      "  episode_reward_max: 21.0\n",
      "  episode_reward_mean: 17.73\n",
      "  episode_reward_min: 6.0\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 2884\n",
      "  experiment_id: 92f0827d37354e42be7025ff72050188\n",
      "  experiment_tag: '0'\n",
      "  hostname: qian-XPS-8920\n",
      "  info:\n",
      "    learner:\n",
      "      cur_lr: 0.0005000000237487257\n",
      "      entropy: 1582.305419921875\n",
      "      entropy_coeff: 0.009999999776482582\n",
      "      grad_gnorm: 39.999996185302734\n",
      "      model: {}\n",
      "      policy_loss: -9.669739723205566\n",
      "      var_gnorm: 25.899728775024414\n",
      "      vf_explained_var: 0.9117655754089355\n",
      "      vf_loss: 8.264039039611816\n",
      "    learner_queue:\n",
      "      size_count: 3796\n",
      "      size_mean: 0.0\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      size_std: 0.0\n",
      "    num_steps_replayed: 0\n",
      "    num_steps_sampled: 3796000\n",
      "    num_steps_trained: 3796000\n",
      "    num_weight_syncs: 15185\n",
      "    sample_throughput: 3232.154\n",
      "    timing_breakdown:\n",
      "      learner_dequeue_time_ms: 4852.112\n",
      "      learner_grad_time_ms: 134.352\n",
      "      learner_load_time_ms: 29.504\n",
      "      learner_load_wait_time_ms: 162.623\n",
      "      optimizer_step_time_ms: 81.154\n",
      "    train_throughput: 3327.218\n",
      "  iterations_since_restore: 112\n",
      "  node_ip: 10.236.176.76\n",
      "  num_healthy_workers: 7\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.38000000000001\n",
      "    ram_util_percent: 80.21333333333335\n",
      "  pid: 13004\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 7.478154904283502\n",
      "    mean_inference_ms: 2.200462870631355\n",
      "    mean_processing_ms: 0.4342910323881303\n",
      "  time_since_restore: 1168.6214611530304\n",
      "  time_this_iter_s: 10.506584405899048\n",
      "  time_total_s: 1168.6214611530304\n",
      "  timestamp: 1583959324\n",
      "  timesteps_since_restore: 3796000\n",
      "  timesteps_this_iter: 34000\n",
      "  timesteps_total: 3796000\n",
      "  training_iteration: 112\n",
      "  trial_id: 00c00974\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 12.5/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8/8 CPUs, 1/1 GPUs, 0.0/7.76 GiB heap, 0.0/2.69 GiB objects<br>Result logdir: /home/qian/ray_results/pong-impala-fast<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                        </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>IMPALA_PongNoFrameskip-v4_00c00974</td><td>RUNNING </td><td>10.236.176.76:13004</td><td style=\"text-align: right;\">   17.73</td><td style=\"text-align: right;\">         1168.62</td><td style=\"text-align: right;\">3796000</td><td style=\"text-align: right;\">   112</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for IMPALA_PongNoFrameskip-v4_00c00974:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-03-11_16-42-14\n",
      "  done: false\n",
      "  episode_len_mean: 7858.02\n",
      "  episode_reward_max: 21.0\n",
      "  episode_reward_mean: 17.79\n",
      "  episode_reward_min: 6.0\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 2903\n",
      "  experiment_id: 92f0827d37354e42be7025ff72050188\n",
      "  experiment_tag: '0'\n",
      "  hostname: qian-XPS-8920\n",
      "  info:\n",
      "    learner:\n",
      "      cur_lr: 0.0005000000237487257\n",
      "      entropy: 1544.607177734375\n",
      "      entropy_coeff: 0.009999999776482582\n",
      "      grad_gnorm: 40.000003814697266\n",
      "      model: {}\n",
      "      policy_loss: 30.573394775390625\n",
      "      var_gnorm: 25.954710006713867\n",
      "      vf_explained_var: 0.7697440981864929\n",
      "      vf_loss: 15.10639762878418\n",
      "    learner_queue:\n",
      "      size_count: 3830\n",
      "      size_mean: 0.0\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      size_std: 0.0\n",
      "    num_steps_replayed: 0\n",
      "    num_steps_sampled: 3830000\n",
      "    num_steps_trained: 3829000\n",
      "    num_weight_syncs: 15320\n",
      "    sample_throughput: 3271.736\n",
      "    timing_breakdown:\n",
      "      learner_dequeue_time_ms: 4842.47\n",
      "      learner_grad_time_ms: 133.787\n",
      "      learner_load_time_ms: 29.379\n",
      "      learner_load_wait_time_ms: 181.474\n",
      "      optimizer_step_time_ms: 89.527\n",
      "    train_throughput: 3175.509\n",
      "  iterations_since_restore: 113\n",
      "  node_ip: 10.236.176.76\n",
      "  num_healthy_workers: 7\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.48666666666666\n",
      "    ram_util_percent: 80.20000000000002\n",
      "  pid: 13004\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 7.478414943339747\n",
      "    mean_inference_ms: 2.2001115552966843\n",
      "    mean_processing_ms: 0.4339666564508885\n",
      "  time_since_restore: 1179.0006561279297\n",
      "  time_this_iter_s: 10.379194974899292\n",
      "  time_total_s: 1179.0006561279297\n",
      "  timestamp: 1583959334\n",
      "  timesteps_since_restore: 3830000\n",
      "  timesteps_this_iter: 34000\n",
      "  timesteps_total: 3830000\n",
      "  training_iteration: 113\n",
      "  trial_id: 00c00974\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 12.5/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8/8 CPUs, 1/1 GPUs, 0.0/7.76 GiB heap, 0.0/2.69 GiB objects<br>Result logdir: /home/qian/ray_results/pong-impala-fast<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                        </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>IMPALA_PongNoFrameskip-v4_00c00974</td><td>RUNNING </td><td>10.236.176.76:13004</td><td style=\"text-align: right;\">   17.79</td><td style=\"text-align: right;\">            1179</td><td style=\"text-align: right;\">3830000</td><td style=\"text-align: right;\">   113</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for IMPALA_PongNoFrameskip-v4_00c00974:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-03-11_16-42-25\n",
      "  done: false\n",
      "  episode_len_mean: 7746.78\n",
      "  episode_reward_max: 21.0\n",
      "  episode_reward_mean: 17.95\n",
      "  episode_reward_min: 6.0\n",
      "  episodes_this_iter: 17\n",
      "  episodes_total: 2920\n",
      "  experiment_id: 92f0827d37354e42be7025ff72050188\n",
      "  experiment_tag: '0'\n",
      "  hostname: qian-XPS-8920\n",
      "  info:\n",
      "    learner:\n",
      "      cur_lr: 0.0005000000237487257\n",
      "      entropy: 1606.7474365234375\n",
      "      entropy_coeff: 0.009999999776482582\n",
      "      grad_gnorm: 39.999996185302734\n",
      "      model: {}\n",
      "      policy_loss: 4.676316738128662\n",
      "      var_gnorm: 25.995365142822266\n",
      "      vf_explained_var: 0.6728576421737671\n",
      "      vf_loss: 50.45157241821289\n",
      "    learner_queue:\n",
      "      size_count: 3864\n",
      "      size_mean: 0.0\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      size_std: 0.0\n",
      "    num_steps_replayed: 0\n",
      "    num_steps_sampled: 3864000\n",
      "    num_steps_trained: 3863000\n",
      "    num_weight_syncs: 15456\n",
      "    sample_throughput: 3251.535\n",
      "    timing_breakdown:\n",
      "      learner_dequeue_time_ms: 4862.582\n",
      "      learner_grad_time_ms: 134.04\n",
      "      learner_load_time_ms: 18.423\n",
      "      learner_load_wait_time_ms: 171.036\n",
      "      optimizer_step_time_ms: 80.566\n",
      "    train_throughput: 3251.535\n",
      "  iterations_since_restore: 114\n",
      "  node_ip: 10.236.176.76\n",
      "  num_healthy_workers: 7\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.15333333333335\n",
      "    ram_util_percent: 80.21333333333334\n",
      "  pid: 13004\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 7.478527115945266\n",
      "    mean_inference_ms: 2.200938640659262\n",
      "    mean_processing_ms: 0.43387202021006405\n",
      "  time_since_restore: 1189.4444510936737\n",
      "  time_this_iter_s: 10.443794965744019\n",
      "  time_total_s: 1189.4444510936737\n",
      "  timestamp: 1583959345\n",
      "  timesteps_since_restore: 3864000\n",
      "  timesteps_this_iter: 34000\n",
      "  timesteps_total: 3864000\n",
      "  training_iteration: 114\n",
      "  trial_id: 00c00974\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 12.5/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8/8 CPUs, 1/1 GPUs, 0.0/7.76 GiB heap, 0.0/2.69 GiB objects<br>Result logdir: /home/qian/ray_results/pong-impala-fast<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                        </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>IMPALA_PongNoFrameskip-v4_00c00974</td><td>RUNNING </td><td>10.236.176.76:13004</td><td style=\"text-align: right;\">   17.95</td><td style=\"text-align: right;\">         1189.44</td><td style=\"text-align: right;\">3864000</td><td style=\"text-align: right;\">   114</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for IMPALA_PongNoFrameskip-v4_00c00974:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-03-11_16-42-35\n",
      "  done: false\n",
      "  episode_len_mean: 7722.71\n",
      "  episode_reward_max: 21.0\n",
      "  episode_reward_mean: 17.95\n",
      "  episode_reward_min: 6.0\n",
      "  episodes_this_iter: 15\n",
      "  episodes_total: 2935\n",
      "  experiment_id: 92f0827d37354e42be7025ff72050188\n",
      "  experiment_tag: '0'\n",
      "  hostname: qian-XPS-8920\n",
      "  info:\n",
      "    learner:\n",
      "      cur_lr: 0.0005000000237487257\n",
      "      entropy: 1570.44580078125\n",
      "      entropy_coeff: 0.009999999776482582\n",
      "      grad_gnorm: 40.0\n",
      "      model: {}\n",
      "      policy_loss: 39.83400344848633\n",
      "      var_gnorm: 26.07832908630371\n",
      "      vf_explained_var: 0.8812410831451416\n",
      "      vf_loss: 12.167023658752441\n",
      "    learner_queue:\n",
      "      size_count: 3898\n",
      "      size_mean: 0.0\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      size_std: 0.0\n",
      "    num_steps_replayed: 0\n",
      "    num_steps_sampled: 3898000\n",
      "    num_steps_trained: 3897000\n",
      "    num_weight_syncs: 15592\n",
      "    sample_throughput: 3263.208\n",
      "    timing_breakdown:\n",
      "      learner_dequeue_time_ms: 4865.594\n",
      "      learner_grad_time_ms: 133.984\n",
      "      learner_load_time_ms: 17.951\n",
      "      learner_load_wait_time_ms: 171.301\n",
      "      optimizer_step_time_ms: 76.584\n",
      "    train_throughput: 3263.208\n",
      "  iterations_since_restore: 115\n",
      "  node_ip: 10.236.176.76\n",
      "  num_healthy_workers: 7\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.59333333333333\n",
      "    ram_util_percent: 80.22666666666667\n",
      "  pid: 13004\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 7.478669811702661\n",
      "    mean_inference_ms: 2.2011415358645223\n",
      "    mean_processing_ms: 0.43382397594271405\n",
      "  time_since_restore: 1199.851026058197\n",
      "  time_this_iter_s: 10.406574964523315\n",
      "  time_total_s: 1199.851026058197\n",
      "  timestamp: 1583959355\n",
      "  timesteps_since_restore: 3898000\n",
      "  timesteps_this_iter: 34000\n",
      "  timesteps_total: 3898000\n",
      "  training_iteration: 115\n",
      "  trial_id: 00c00974\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 12.4/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8/8 CPUs, 1/1 GPUs, 0.0/7.76 GiB heap, 0.0/2.69 GiB objects<br>Result logdir: /home/qian/ray_results/pong-impala-fast<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                        </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>IMPALA_PongNoFrameskip-v4_00c00974</td><td>RUNNING </td><td>10.236.176.76:13004</td><td style=\"text-align: right;\">   17.95</td><td style=\"text-align: right;\">         1199.85</td><td style=\"text-align: right;\">3898000</td><td style=\"text-align: right;\">   115</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for IMPALA_PongNoFrameskip-v4_00c00974:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-03-11_16-42-45\n",
      "  done: false\n",
      "  episode_len_mean: 7776.05\n",
      "  episode_reward_max: 21.0\n",
      "  episode_reward_mean: 17.94\n",
      "  episode_reward_min: 6.0\n",
      "  episodes_this_iter: 17\n",
      "  episodes_total: 2952\n",
      "  experiment_id: 92f0827d37354e42be7025ff72050188\n",
      "  experiment_tag: '0'\n",
      "  hostname: qian-XPS-8920\n",
      "  info:\n",
      "    learner:\n",
      "      cur_lr: 0.0005000000237487257\n",
      "      entropy: 1604.064453125\n",
      "      entropy_coeff: 0.009999999776482582\n",
      "      grad_gnorm: 40.0\n",
      "      model: {}\n",
      "      policy_loss: -60.77638244628906\n",
      "      var_gnorm: 26.132966995239258\n",
      "      vf_explained_var: 0.7883585691452026\n",
      "      vf_loss: 23.070707321166992\n",
      "    learner_queue:\n",
      "      size_count: 3931\n",
      "      size_mean: 0.0\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      size_std: 0.0\n",
      "    num_steps_replayed: 0\n",
      "    num_steps_sampled: 3931000\n",
      "    num_steps_trained: 3931000\n",
      "    num_weight_syncs: 15727\n",
      "    sample_throughput: 3180.105\n",
      "    timing_breakdown:\n",
      "      learner_dequeue_time_ms: 4901.664\n",
      "      learner_grad_time_ms: 136.243\n",
      "      learner_load_time_ms: 18.191\n",
      "      learner_load_wait_time_ms: 162.37\n",
      "      optimizer_step_time_ms: 84.004\n",
      "    train_throughput: 3276.472\n",
      "  iterations_since_restore: 116\n",
      "  node_ip: 10.236.176.76\n",
      "  num_healthy_workers: 7\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.99333333333334\n",
      "    ram_util_percent: 79.90000000000002\n",
      "  pid: 13004\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 7.479155026315613\n",
      "    mean_inference_ms: 2.2004890496252387\n",
      "    mean_processing_ms: 0.43366382115009705\n",
      "  time_since_restore: 1210.2152020931244\n",
      "  time_this_iter_s: 10.364176034927368\n",
      "  time_total_s: 1210.2152020931244\n",
      "  timestamp: 1583959365\n",
      "  timesteps_since_restore: 3931000\n",
      "  timesteps_this_iter: 33000\n",
      "  timesteps_total: 3931000\n",
      "  training_iteration: 116\n",
      "  trial_id: 00c00974\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 12.4/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8/8 CPUs, 1/1 GPUs, 0.0/7.76 GiB heap, 0.0/2.69 GiB objects<br>Result logdir: /home/qian/ray_results/pong-impala-fast<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                        </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>IMPALA_PongNoFrameskip-v4_00c00974</td><td>RUNNING </td><td>10.236.176.76:13004</td><td style=\"text-align: right;\">   17.94</td><td style=\"text-align: right;\">         1210.22</td><td style=\"text-align: right;\">3931000</td><td style=\"text-align: right;\">   116</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for IMPALA_PongNoFrameskip-v4_00c00974:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-03-11_16-42-56\n",
      "  done: false\n",
      "  episode_len_mean: 7863.66\n",
      "  episode_reward_max: 21.0\n",
      "  episode_reward_mean: 17.82\n",
      "  episode_reward_min: 1.0\n",
      "  episodes_this_iter: 17\n",
      "  episodes_total: 2969\n",
      "  experiment_id: 92f0827d37354e42be7025ff72050188\n",
      "  experiment_tag: '0'\n",
      "  hostname: qian-XPS-8920\n",
      "  info:\n",
      "    learner:\n",
      "      cur_lr: 0.0005000000237487257\n",
      "      entropy: 1578.5794677734375\n",
      "      entropy_coeff: 0.009999999776482582\n",
      "      grad_gnorm: 40.0\n",
      "      model: {}\n",
      "      policy_loss: -11.511517524719238\n",
      "      var_gnorm: 26.215757369995117\n",
      "      vf_explained_var: 0.8955371379852295\n",
      "      vf_loss: 13.111041069030762\n",
      "    learner_queue:\n",
      "      size_count: 3965\n",
      "      size_mean: 0.0\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      size_std: 0.0\n",
      "    num_steps_replayed: 0\n",
      "    num_steps_sampled: 3965000\n",
      "    num_steps_trained: 3965000\n",
      "    num_weight_syncs: 15863\n",
      "    sample_throughput: 3249.801\n",
      "    timing_breakdown:\n",
      "      learner_dequeue_time_ms: 4906.453\n",
      "      learner_grad_time_ms: 133.088\n",
      "      learner_load_time_ms: 18.786\n",
      "      learner_load_wait_time_ms: 170.445\n",
      "      optimizer_step_time_ms: 75.358\n",
      "    train_throughput: 3249.801\n",
      "  iterations_since_restore: 117\n",
      "  node_ip: 10.236.176.76\n",
      "  num_healthy_workers: 7\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.16666666666669\n",
      "    ram_util_percent: 79.90000000000002\n",
      "  pid: 13004\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 7.478765687841206\n",
      "    mean_inference_ms: 2.2000830833042855\n",
      "    mean_processing_ms: 0.4332703407722026\n",
      "  time_since_restore: 1220.665046453476\n",
      "  time_this_iter_s: 10.449844360351562\n",
      "  time_total_s: 1220.665046453476\n",
      "  timestamp: 1583959376\n",
      "  timesteps_since_restore: 3965000\n",
      "  timesteps_this_iter: 34000\n",
      "  timesteps_total: 3965000\n",
      "  training_iteration: 117\n",
      "  trial_id: 00c00974\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 12.4/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8/8 CPUs, 1/1 GPUs, 0.0/7.76 GiB heap, 0.0/2.69 GiB objects<br>Result logdir: /home/qian/ray_results/pong-impala-fast<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                        </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>IMPALA_PongNoFrameskip-v4_00c00974</td><td>RUNNING </td><td>10.236.176.76:13004</td><td style=\"text-align: right;\">   17.82</td><td style=\"text-align: right;\">         1220.67</td><td style=\"text-align: right;\">3965000</td><td style=\"text-align: right;\">   117</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for IMPALA_PongNoFrameskip-v4_00c00974:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-03-11_16-43-06\n",
      "  done: false\n",
      "  episode_len_mean: 7930.19\n",
      "  episode_reward_max: 21.0\n",
      "  episode_reward_mean: 17.79\n",
      "  episode_reward_min: 1.0\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 2987\n",
      "  experiment_id: 92f0827d37354e42be7025ff72050188\n",
      "  experiment_tag: '0'\n",
      "  hostname: qian-XPS-8920\n",
      "  info:\n",
      "    learner:\n",
      "      cur_lr: 0.0005000000237487257\n",
      "      entropy: 1601.7476806640625\n",
      "      entropy_coeff: 0.009999999776482582\n",
      "      grad_gnorm: 40.0\n",
      "      model: {}\n",
      "      policy_loss: -59.19575119018555\n",
      "      var_gnorm: 26.259977340698242\n",
      "      vf_explained_var: 0.8710124492645264\n",
      "      vf_loss: 20.026805877685547\n",
      "    learner_queue:\n",
      "      size_count: 3999\n",
      "      size_mean: 0.0\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      size_std: 0.0\n",
      "    num_steps_replayed: 0\n",
      "    num_steps_sampled: 3999000\n",
      "    num_steps_trained: 3999000\n",
      "    num_weight_syncs: 15999\n",
      "    sample_throughput: 3248.629\n",
      "    timing_breakdown:\n",
      "      learner_dequeue_time_ms: 4922.736\n",
      "      learner_grad_time_ms: 134.898\n",
      "      learner_load_time_ms: 18.458\n",
      "      learner_load_wait_time_ms: 163.81\n",
      "      optimizer_step_time_ms: 78.879\n",
      "    train_throughput: 3248.629\n",
      "  iterations_since_restore: 118\n",
      "  node_ip: 10.236.176.76\n",
      "  num_healthy_workers: 7\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.83333333333333\n",
      "    ram_util_percent: 79.94\n",
      "  pid: 13004\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 7.47952412557922\n",
      "    mean_inference_ms: 2.2007874965823553\n",
      "    mean_processing_ms: 0.4331604408793275\n",
      "  time_since_restore: 1231.1180012226105\n",
      "  time_this_iter_s: 10.452954769134521\n",
      "  time_total_s: 1231.1180012226105\n",
      "  timestamp: 1583959386\n",
      "  timesteps_since_restore: 3999000\n",
      "  timesteps_this_iter: 34000\n",
      "  timesteps_total: 3999000\n",
      "  training_iteration: 118\n",
      "  trial_id: 00c00974\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 12.4/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8/8 CPUs, 1/1 GPUs, 0.0/7.76 GiB heap, 0.0/2.69 GiB objects<br>Result logdir: /home/qian/ray_results/pong-impala-fast<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                        </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>IMPALA_PongNoFrameskip-v4_00c00974</td><td>RUNNING </td><td>10.236.176.76:13004</td><td style=\"text-align: right;\">   17.79</td><td style=\"text-align: right;\">         1231.12</td><td style=\"text-align: right;\">3999000</td><td style=\"text-align: right;\">   118</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for IMPALA_PongNoFrameskip-v4_00c00974:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-03-11_16-43-17\n",
      "  done: false\n",
      "  episode_len_mean: 7945.54\n",
      "  episode_reward_max: 21.0\n",
      "  episode_reward_mean: 17.73\n",
      "  episode_reward_min: 1.0\n",
      "  episodes_this_iter: 15\n",
      "  episodes_total: 3002\n",
      "  experiment_id: 92f0827d37354e42be7025ff72050188\n",
      "  experiment_tag: '0'\n",
      "  hostname: qian-XPS-8920\n",
      "  info:\n",
      "    learner:\n",
      "      cur_lr: 0.0005000000237487257\n",
      "      entropy: 1538.544189453125\n",
      "      entropy_coeff: 0.009999999776482582\n",
      "      grad_gnorm: 40.0\n",
      "      model: {}\n",
      "      policy_loss: -5.324801445007324\n",
      "      var_gnorm: 26.324628829956055\n",
      "      vf_explained_var: 0.8674399256706238\n",
      "      vf_loss: 11.353498458862305\n",
      "    learner_queue:\n",
      "      size_count: 4033\n",
      "      size_mean: 0.0\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      size_std: 0.0\n",
      "    num_steps_replayed: 0\n",
      "    num_steps_sampled: 4033000\n",
      "    num_steps_trained: 4033000\n",
      "    num_weight_syncs: 16135\n",
      "    sample_throughput: 3253.74\n",
      "    timing_breakdown:\n",
      "      learner_dequeue_time_ms: 4889.093\n",
      "      learner_grad_time_ms: 132.876\n",
      "      learner_load_time_ms: 20.182\n",
      "      learner_load_wait_time_ms: 172.327\n",
      "      optimizer_step_time_ms: 73.227\n",
      "    train_throughput: 3253.74\n",
      "  iterations_since_restore: 119\n",
      "  node_ip: 10.236.176.76\n",
      "  num_healthy_workers: 7\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.39333333333333\n",
      "    ram_util_percent: 79.95333333333335\n",
      "  pid: 13004\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 7.479329491639033\n",
      "    mean_inference_ms: 2.200840498339049\n",
      "    mean_processing_ms: 0.4331317425841501\n",
      "  time_since_restore: 1241.555155992508\n",
      "  time_this_iter_s: 10.437154769897461\n",
      "  time_total_s: 1241.555155992508\n",
      "  timestamp: 1583959397\n",
      "  timesteps_since_restore: 4033000\n",
      "  timesteps_this_iter: 34000\n",
      "  timesteps_total: 4033000\n",
      "  training_iteration: 119\n",
      "  trial_id: 00c00974\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 12.4/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8/8 CPUs, 1/1 GPUs, 0.0/7.76 GiB heap, 0.0/2.69 GiB objects<br>Result logdir: /home/qian/ray_results/pong-impala-fast<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                        </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>IMPALA_PongNoFrameskip-v4_00c00974</td><td>RUNNING </td><td>10.236.176.76:13004</td><td style=\"text-align: right;\">   17.73</td><td style=\"text-align: right;\">         1241.56</td><td style=\"text-align: right;\">4033000</td><td style=\"text-align: right;\">   119</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for IMPALA_PongNoFrameskip-v4_00c00974:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-03-11_16-43-27\n",
      "  done: false\n",
      "  episode_len_mean: 7973.76\n",
      "  episode_reward_max: 21.0\n",
      "  episode_reward_mean: 17.77\n",
      "  episode_reward_min: 1.0\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 3023\n",
      "  experiment_id: 92f0827d37354e42be7025ff72050188\n",
      "  experiment_tag: '0'\n",
      "  hostname: qian-XPS-8920\n",
      "  info:\n",
      "    learner:\n",
      "      cur_lr: 0.0005000000237487257\n",
      "      entropy: 1601.5054931640625\n",
      "      entropy_coeff: 0.009999999776482582\n",
      "      grad_gnorm: 40.0\n",
      "      model: {}\n",
      "      policy_loss: 62.17485046386719\n",
      "      var_gnorm: 26.3966007232666\n",
      "      vf_explained_var: 0.8346121311187744\n",
      "      vf_loss: 15.56307601928711\n",
      "    learner_queue:\n",
      "      size_count: 4068\n",
      "      size_mean: 0.0\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      size_std: 0.0\n",
      "    num_steps_replayed: 0\n",
      "    num_steps_sampled: 4068000\n",
      "    num_steps_trained: 4067000\n",
      "    num_weight_syncs: 16272\n",
      "    sample_throughput: 3341.37\n",
      "    timing_breakdown:\n",
      "      learner_dequeue_time_ms: 4881.004\n",
      "      learner_grad_time_ms: 133.265\n",
      "      learner_load_time_ms: 20.624\n",
      "      learner_load_wait_time_ms: 172.167\n",
      "      optimizer_step_time_ms: 67.324\n",
      "    train_throughput: 3245.903\n",
      "  iterations_since_restore: 120\n",
      "  node_ip: 10.236.176.76\n",
      "  num_healthy_workers: 7\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.46000000000001\n",
      "    ram_util_percent: 80.02666666666667\n",
      "  pid: 13004\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 7.47872828927299\n",
      "    mean_inference_ms: 2.1998807408318335\n",
      "    mean_processing_ms: 0.43270846991250755\n",
      "  time_since_restore: 1252.0174767971039\n",
      "  time_this_iter_s: 10.462320804595947\n",
      "  time_total_s: 1252.0174767971039\n",
      "  timestamp: 1583959407\n",
      "  timesteps_since_restore: 4068000\n",
      "  timesteps_this_iter: 35000\n",
      "  timesteps_total: 4068000\n",
      "  training_iteration: 120\n",
      "  trial_id: 00c00974\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 12.4/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8/8 CPUs, 1/1 GPUs, 0.0/7.76 GiB heap, 0.0/2.69 GiB objects<br>Result logdir: /home/qian/ray_results/pong-impala-fast<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                        </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>IMPALA_PongNoFrameskip-v4_00c00974</td><td>RUNNING </td><td>10.236.176.76:13004</td><td style=\"text-align: right;\">   17.77</td><td style=\"text-align: right;\">         1252.02</td><td style=\"text-align: right;\">4068000</td><td style=\"text-align: right;\">   120</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-98b9637e8725>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtune\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_experiments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtune_config_example\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/ray/lib/python3.7/site-packages/ray/tune/tune.py\u001b[0m in \u001b[0;36mrun_experiments\u001b[0;34m(experiments, search_alg, scheduler, with_server, server_port, verbose, progress_reporter, resume, queue_trials, reuse_actors, trial_executor, raise_on_failed_trial, concurrent)\u001b[0m\n\u001b[1;32m    410\u001b[0m             \u001b[0mtrial_executor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrial_executor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m             \u001b[0mraise_on_failed_trial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraise_on_failed_trial\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 412\u001b[0;31m             return_trials=True)\n\u001b[0m\u001b[1;32m    413\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0mtrials\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ray/lib/python3.7/site-packages/ray/tune/tune.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(run_or_experiment, name, stop, config, resources_per_trial, num_samples, local_dir, upload_dir, trial_name_creator, loggers, sync_to_cloud, sync_to_driver, checkpoint_freq, checkpoint_at_end, sync_on_checkpoint, keep_checkpoints_num, checkpoint_score_attr, global_checkpoint_period, export_formats, max_failures, restore, search_alg, scheduler, with_server, server_port, verbose, progress_reporter, resume, queue_trials, reuse_actors, trial_executor, raise_on_failed_trial, return_trials, ray_auto_init, sync_function)\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_finished\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m         \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m             \u001b[0m_report_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrunner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprogress_reporter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ray/lib/python3.7/site-packages/ray/tune/trial_runner.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    333\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrial_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_trial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrial_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_running_trials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# blocking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrial_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_no_available_trials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ray/lib/python3.7/site-packages/ray/tune/trial_runner.py\u001b[0m in \u001b[0;36m_process_events\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    424\u001b[0m             \u001b[0;31m# TODO(ujvl): Consider combining get_next_available_trial and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m             \u001b[0;31m#  fetch_result functionality so that we don't timeout on fetch.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 426\u001b[0;31m             \u001b[0mtrial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrial_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_next_available_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# blocking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    427\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_restoring\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mwarn_if_slow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"process_trial_restore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ray/lib/python3.7/site-packages/ray/tune/ray_trial_executor.py\u001b[0m in \u001b[0;36mget_next_available_trial\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    350\u001b[0m         \u001b[0;31m# See https://github.com/ray-project/ray/issues/4211 for details.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m         \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m         \u001b[0;34m[\u001b[0m\u001b[0mresult_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshuffled_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m         \u001b[0mwait_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait_time\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mNONTRIVIAL_WAIT_TIME_THRESHOLD_S\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ray/lib/python3.7/site-packages/ray/worker.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_ids, num_returns, timeout)\u001b[0m\n\u001b[1;32m   1637\u001b[0m             \u001b[0mnum_returns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1638\u001b[0m             \u001b[0mtimeout_milliseconds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1639\u001b[0;31m             \u001b[0mworker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_task_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1640\u001b[0m         )\n\u001b[1;32m   1641\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mready_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremaining_ids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpython/ray/_raylet.pyx\u001b[0m in \u001b[0;36mray._raylet.CoreWorker.wait\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpython/ray/_raylet.pyx\u001b[0m in \u001b[0;36mray._raylet.check_status\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ray.tune.run_experiments(tune_config_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting status and stopping ray\n",
    "* https://ray.readthedocs.io/en/latest/package-ref.html#ray-package-reference\n",
    "* https://ray.readthedocs.io/en/latest/package-ref.html#ray.init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.is_initialized()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'NodeID': '41c26152d8eecc51f1a4fec2eec4a79eb681081f',\n",
       "  'Alive': True,\n",
       "  'NodeManagerAddress': '10.236.176.76',\n",
       "  'NodeManagerHostname': 'qian-XPS-8920',\n",
       "  'NodeManagerPort': 54719,\n",
       "  'ObjectManagerPort': 46637,\n",
       "  'ObjectStoreSocketName': '/tmp/ray/session_2020-02-23_17-44-43_860531_30552/sockets/plasma_store',\n",
       "  'RayletSocketName': '/tmp/ray/session_2020-02-23_17-44-43_860531_30552/sockets/raylet',\n",
       "  'Resources': {'node:10.236.176.76': 1.0,\n",
       "   'object_store_memory': 25.0,\n",
       "   'CPU': 8.0,\n",
       "   'memory': 74.0,\n",
       "   'GPU': 1.0},\n",
       "  'alive': True}]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'node:10.236.176.76': 1.0,\n",
       " 'object_store_memory': 25.0,\n",
       " 'CPU': 8.0,\n",
       " 'memory': 74.0,\n",
       " 'GPU': 1.0}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.cluster_resources()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.is_initialized()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
